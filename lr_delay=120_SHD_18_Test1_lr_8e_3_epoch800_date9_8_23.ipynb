{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a81f3c8e",
      "metadata": {
        "id": "a81f3c8e"
      },
      "source": [
        "# DF: My experiments with sorting and edge sampling\n",
        "\n",
        "### These include data visualization and other experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "6bf9efc0",
      "metadata": {
        "id": "6bf9efc0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Sequential, LeakyReLU, Dropout, BatchNorm1d\n",
        "from torch.nn.functional import gumbel_softmax\n",
        "import pickle\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from torch.utils.data.dataset import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "8f461c7d",
      "metadata": {
        "id": "8f461c7d",
        "outputId": "05bba8bb-9054-418c-b0e5-14b9822a7598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "30a09776",
      "metadata": {
        "id": "30a09776",
        "outputId": "12e60844-304e-4e83-edc0-7e4d26d692e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "#DF18-01: add device for GPU\n",
        "device = 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff49e715",
      "metadata": {
        "id": "ff49e715"
      },
      "source": [
        "## Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
        "* [Global variables](#variables)\n",
        "* [Model](#model)\n",
        "    * [Discriminator](#discriminator)\n",
        "    * [Generator](#generator)\n",
        "    * [DAG](#dag)\n",
        "* [Dataset](#data)\n",
        "* [Visualization](#visualization)\n",
        "* [Instantiation](#instantiation)\n",
        "* [Training](#training)\n",
        "* [End](#end)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217a3f51",
      "metadata": {
        "id": "217a3f51"
      },
      "source": [
        "## Global variables <a class=\"anchor\" id=\"variables\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "204863d3",
      "metadata": {
        "id": "204863d3"
      },
      "outputs": [],
      "source": [
        "data_sample_size = 5000\n",
        "data_variable_size = 10\n",
        "x_dims =1\n",
        "z_dims =1\n",
        "code_dims =1\n",
        "graph_type = 'erdos-renyi'\n",
        "graph_degree = 3\n",
        "graph_sem_type = 'linear-gauss'\n",
        "graph_linear_type = 'nonlinear_1'\n",
        "graph_threshold =0.3\n",
        "\n",
        "batch_size=200                     #40\n",
        "lr = 8e-3                          #3e-3: tried 6e-3, 4e-3 ######AM_11/8 8e-3 shows loss almost better\n",
        "es = 30                            #DF11_01: add es to control the lr scale , was 30, tried 50\n",
        "negative_slope = 0.2\n",
        "dropout_rate = 0.4                 #was 0.5 ####AM 0.4\n",
        "\n",
        "seed=42\n",
        "epochs =800\n",
        "discriminator_steps = 4             #5,10 and 5 was really good\n",
        "ScaleA=10                           #DF08-01: set this to 1 for debug, was 40\n",
        "\n",
        "synthesize=0\n",
        "####fname1=f\"data/train_loader2023-01-10 10=13.pkl\"   #DF10-1: from 12=45, we do not save this anymore\n",
        "\n",
        "#fname2=f\"data/ground_truth_G2023-01-10 12=45.pkl\"\n",
        "#fname3=f\"data/X_data_exp2023-01-10 12=45.csv\"\n",
        "fname2=f\"/content/results/data/ground_truth_G2023-08-09 22=15.pkl\"\n",
        "fname3=f\"/content/results/data/X_data_exp2023-08-09 22=15.csv\"\n",
        "\n",
        "disp_order_within_epoch=0           #DF06-01:control whether to display the node order within an epoch\n",
        "\n",
        "#DF16-01: add schedulers parameters\n",
        "lr_decay = 120 #####\n",
        "gamma=0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194e1779",
      "metadata": {
        "id": "194e1779"
      },
      "source": [
        "## The Model <a class=\"anchor\" id=\"model\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19c804e9",
      "metadata": {
        "id": "19c804e9"
      },
      "source": [
        "* [Back to ToC](#toc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da5af54c",
      "metadata": {
        "id": "da5af54c"
      },
      "source": [
        "### The discriminator <a class=\"anchor\" id=\"discriminator\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "c3f1ee50",
      "metadata": {
        "id": "c3f1ee50"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Discriminator module.\"\"\"\n",
        "    def __init__(self, input_dim, discriminator_dim, negative_slope, dropout_rate, pac=10):\n",
        "        super(Discriminator, self).__init__()\n",
        "        dim = input_dim * pac\n",
        "        self.pac = pac\n",
        "        self.pacdim = dim\n",
        "\n",
        "        seq = []\n",
        "        for item in list(discriminator_dim):\n",
        "            seq += [Linear(dim, item), LeakyReLU(negative_slope), Dropout(dropout_rate)]\n",
        "            dim = item\n",
        "\n",
        "        seq += [Linear(dim, 1)]\n",
        "        self.seq = Sequential(*seq)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.0)\n",
        "            elif isinstance(m, BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def calc_gradient_penalty(self, real_data, fake_data, device='cpu', pac=10, lambda_=10):\n",
        "\n",
        "        # reshape data\n",
        "        real_data = real_data.squeeze()\n",
        "        fake_data = fake_data.squeeze()\n",
        "\n",
        "        alpha = torch.rand(real_data.size(0) // pac, 1, 1, device=device)\n",
        "        alpha = alpha.repeat(1, pac, real_data.size(1))\n",
        "        alpha = alpha.view(-1, real_data.size(1))\n",
        "\n",
        "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
        "\n",
        "        disc_interpolates = self(interpolates)\n",
        "\n",
        "        gradients = torch.autograd.grad(\n",
        "            outputs=disc_interpolates, inputs=interpolates,\n",
        "            grad_outputs=torch.ones(disc_interpolates.size(), device=device),\n",
        "            create_graph=True, retain_graph=True, only_inputs=True\n",
        "        )[0]\n",
        "\n",
        "        gradient_penalty = ((\n",
        "            gradients.view(-1, pac * real_data.size(1)).norm(2, dim=1) - 1\n",
        "        ) ** 2).mean() * lambda_\n",
        "\n",
        "        return gradient_penalty\n",
        "\n",
        "    def forward(self, input):\n",
        "        assert input.size()[0] % self.pac == 0\n",
        "        return self.seq(input.view(-1, self.pacdim))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7ac7299",
      "metadata": {
        "id": "f7ac7299"
      },
      "source": [
        "### The Generator <a class=\"anchor\" id=\"generator\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13467c8e",
      "metadata": {
        "id": "13467c8e"
      },
      "source": [
        "* [Back to ToC](#toc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "ebe3e3b7",
      "metadata": {
        "id": "ebe3e3b7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def order_nodes(P_inv):   #This is the code from Hristo\n",
        "\n",
        "    P_inv = P_inv.clone().detach().cpu().numpy() # might be here\n",
        "\n",
        "    m = np.arange(1, P_inv.shape[0] + 1)\n",
        "    m = np.array(m)\n",
        "\n",
        "    #array for ordering\n",
        "    order = np.zeros_like(P_inv)\n",
        "\n",
        "    for num in reversed(range(P_inv.shape[0])):\n",
        "        order[num] = P_inv[:,num] * m\n",
        "    order = order[order != 0][::-1] #gives a list of ordered nodes in reversed order\n",
        "    return order\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Generator module (based on DAG-NotearsMLP)\"\"\"\n",
        "    def __init__(self, m, k, dims, bias=True):\n",
        "        super(Generator, self).__init__()\n",
        "        assert len(dims) >= 2\n",
        "        assert dims[-1] == 1\n",
        "\n",
        "        self.input_dims = dims[0]\n",
        "        self.hidden_dims = dims[1:-1]\n",
        "        self.output_dim = dims[-1]\n",
        "\n",
        "\n",
        "        # fc1: local linear layers\n",
        "        #DF08-01: this is used by additive noise model as well\n",
        "        #\"\"\"\n",
        "        #DF: reconstrucntion (without z)\n",
        "        self.fc1 =  nn.ModuleList([self.linear_sequential(input_dims=self.input_dims,\n",
        "                                                          hidden_dims=self.hidden_dims,\n",
        "                                                          output_dim=self.output_dim) for i in range(data_variable_size)])\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.0)\n",
        "            elif isinstance(m, BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def linear_sequential(self, input_dims, hidden_dims, output_dim):\n",
        "        dims = [np.prod(input_dims)] + hidden_dims + [output_dim]\n",
        "        num_layers = len(dims) - 1\n",
        "\n",
        "        layers = []\n",
        "        for i in range(num_layers):\n",
        "            layers.append(nn.Linear(dims[i], dims[i + 1]))\n",
        "            if i < num_layers - 1:\n",
        "                layers.append(nn.ReLU())\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    #\"\"\"\n",
        "    #DF08-01: experiment with additive noise\n",
        "    def forward(self, z, n, d, A, P_inv):  # [n, d] -> [n, d]\n",
        "\n",
        "        #DF18-01: add device for GPU\n",
        "        pred_X = torch.zeros([n, d]).double().to(device) #x_dims = 1\n",
        "\n",
        "        ordered_vertices = order_nodes(P_inv)\n",
        "        assert len(ordered_vertices) == d\n",
        "\n",
        "        #DF expriment: try to use either order\n",
        "        #The nodes are 1,2,3, where 3 is the top parent,\n",
        "        # We get [3,2,1] in ordered_vertices,\n",
        "        for i in range(self.input_dims):             #for Approach 1\n",
        "\n",
        "            current_node = int(ordered_vertices[i])\n",
        "            masked_X = pred_X.clone() * A[current_node-1,:].unsqueeze(0) *ScaleA #DF try to scale up the mask\n",
        "            pred_X[:, current_node-1] = self.fc1[current_node - 1](masked_X).squeeze() +z[:, current_node-1, :].squeeze()\n",
        "\n",
        "        return pred_X\n",
        "    #\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b343e26d",
      "metadata": {
        "id": "b343e26d"
      },
      "source": [
        "### The DAG <a class=\"anchor\" id=\"dag\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9094086a",
      "metadata": {
        "id": "9094086a"
      },
      "source": [
        "* [Back to ToC](#toc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "b8b1b78d",
      "metadata": {
        "id": "b8b1b78d"
      },
      "outputs": [],
      "source": [
        "def sofsorting(X, nsize):\n",
        "\n",
        "    #get the data ready\n",
        "    X = X.unsqueeze(0)\n",
        "    X = X.unsqueeze(-1)\n",
        "\n",
        "    #soft sorting with pairwise diff\n",
        "    X_sorted = X.sort(descending=True, dim=1)[0]\n",
        "    X_id     = X.sort(descending=True, dim=1)[1]\n",
        "\n",
        "    pairwise_diff = (X.transpose(1, 2) - X_sorted).abs().neg() / 1.0\n",
        "    P_hat = pairwise_diff.softmax(-1)\n",
        "\n",
        "    #compute permutation matrix (P_hat) from softmax(pairwise_diff)\n",
        "    P = torch.zeros_like(P_hat)\n",
        "    P.scatter_(-1, P_hat.topk(1, -1)[1], value=1)\n",
        "    P_hat = (P - P_hat).detach() + P_hat\n",
        "\n",
        "    #compute Order from P_hat\n",
        "    m = np.arange(1, nsize + 1)\n",
        "    mt = torch.from_numpy(m)\n",
        "    order = torch.zeros(nsize)\n",
        "\n",
        "    P_hat = P_hat.squeeze()\n",
        "    for num in range(nsize):\n",
        "        order[num] = sum(P_hat[num,:]*mt) -1\n",
        "\n",
        "    return order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "fb91d42c",
      "metadata": {
        "id": "fb91d42c"
      },
      "outputs": [],
      "source": [
        "class SoftSort_p1(torch.nn.Module):\n",
        "    def __init__(self, tau=1.0, hard=False):\n",
        "        super(SoftSort_p1, self).__init__()\n",
        "        self.hard = hard\n",
        "        self.tau = tau\n",
        "\n",
        "    def forward(self, scores: Tensor):\n",
        "        \"\"\"\n",
        "        scores: elements to be sorted. Typical shape: batch_size x n\n",
        "        \"\"\"\n",
        "        scores = scores.unsqueeze(-1)\n",
        "        sorted = scores.sort(descending=True, dim=1)[0]\n",
        "        pairwise_diff = (scores.transpose(1, 2) - sorted).abs().neg() / self.tau\n",
        "        P_hat = pairwise_diff.softmax(-1)\n",
        "\n",
        "        if self.hard:\n",
        "            P = torch.zeros_like(P_hat, device=P_hat.device)\n",
        "            P.scatter_(-1, P_hat.topk(1, -1)[1], value=1)\n",
        "            P_hat = (P - P_hat).detach() + P_hat\n",
        "\n",
        "\n",
        "        return P_hat\n",
        "\n",
        "class ProbabilisticDAG(nn.Module):\n",
        "\n",
        "    def __init__(self, n_nodes, temperature=1.0, hard=True, order_type='sinkhorn', noise_factor=1.0, initial_adj=None, lr=1e-3, seed=42):\n",
        "        \"\"\"Base Class for Probabilistic DAG Generator based on topological order sampling\n",
        "\n",
        "        Args:\n",
        "            n_nodes (int): Number of nodes\n",
        "            temperature (float, optional): Temperature parameter for order sampling. Defaults to 1.0.\n",
        "            hard (bool, optional): If True output hard DAG. Defaults to True.\n",
        "            order_type (string, optional): Type of differentiable sorting. Defaults to 'sinkhorn'.\n",
        "            noise_factor (float, optional): Noise factor for Sinkhorn sorting. Defaults to 1.0.\n",
        "            initial_adj (torch.tensor, optional): Initial binary adjecency matrix from e.g. PNS.\n",
        "                Edges with value 0 will not be learnt in further process Defaults to None.\n",
        "            lr (float, optional): Learning rate. Defaults to 1e-3.\n",
        "            seed (int, optional): Random seed. Defaults to 0.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "\n",
        "        self.n_nodes = n_nodes\n",
        "        self.temperature = temperature\n",
        "        self.hard = hard\n",
        "        self.order_type = order_type\n",
        "\n",
        "        # Mask for ordering (a completed DAG)\n",
        "        self.mask = torch.triu(torch.ones(self.n_nodes, self.n_nodes, device=device), 1)\n",
        "\n",
        "        # define initial parameters\n",
        "        if self.order_type == 'sinkhorn':\n",
        "            self.noise_factor = noise_factor\n",
        "            p = torch.zeros(n_nodes, n_nodes, requires_grad=True, device=device)\n",
        "            self.perm_weights = torch.nn.Parameter(p)\n",
        "        elif self.order_type == 'topk':\n",
        "            p = torch.zeros(n_nodes, requires_grad=True, device=device)\n",
        "            self.perm_weights = torch.nn.Parameter(p)\n",
        "            self.sort = SoftSort_p1(hard=self.hard, tau=self.temperature)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        e = torch.zeros(n_nodes, n_nodes, requires_grad=True, device=device)\n",
        "        torch.nn.init.uniform_(e)\n",
        "        if initial_adj is not None:\n",
        "            initial_adj = initial_adj.to(device)\n",
        "            zero_indices = (1 - initial_adj).bool()\n",
        "            # set masked edges to zero probability\n",
        "            e.requires_grad = False\n",
        "            e[zero_indices] = -300\n",
        "            e.requires_grad = True\n",
        "\n",
        "        #DF change\n",
        "        #torch.diagonal(e).fill_(-300) #this line crashes, fix is below\n",
        "        torch.diagonal(e).data.fill_(-300)\n",
        "\n",
        "        self.edge_log_params = torch.nn.Parameter(e)\n",
        "\n",
        "        if initial_adj is not None:\n",
        "            self.edge_log_params.register_hook(lambda grad: grad * initial_adj.float())\n",
        "\n",
        "        #self.lr = lr\n",
        "        #self.optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.0)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def sample_edges(self):\n",
        "        p_log = F.logsigmoid(torch.stack((self.edge_log_params, -self.edge_log_params)))\n",
        "        dag = gumbel_softmax(p_log, hard=True, dim=0)[0]\n",
        "\n",
        "        return dag\n",
        "\n",
        "    def sample_permutation(self):\n",
        "        if self.order_type == 'sinkhorn':\n",
        "            log_alpha = F.logsigmoid(self.perm_weights)\n",
        "            P, _ = gumbel_sinkhorn(log_alpha, noise_factor=self.noise_factor, temp=self.temperature, hard=self.hard)\n",
        "            P = P.squeeze().to(device)\n",
        "        elif self.order_type == 'topk':\n",
        "            logits = F.log_softmax(self.perm_weights, dim=0).view(1, -1)\n",
        "            gumbels = -torch.empty_like(logits).exponential_().log()\n",
        "            gumbels = (logits + gumbels) / 1\n",
        "\n",
        "            P = self.sort(gumbels)\n",
        "            P = P.squeeze()\n",
        "\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        return P\n",
        "\n",
        "    def sample(self):\n",
        "        P = self.sample_permutation()\n",
        "        P_inv = P.transpose(0, 1)\n",
        "        dag_adj = self.sample_edges()\n",
        "        dag_adj = dag_adj * torch.matmul(torch.matmul(P_inv, self.mask), P)  # apply autoregressive masking\n",
        "        return dag_adj , P_inv\n",
        "\n",
        "    def log_prob(self, dag_adj):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def deterministic_permutation(self, hard=True):\n",
        "        if self.order_type == 'sinkhorn':\n",
        "            log_alpha = F.logsigmoid(self.perm_weights)\n",
        "            P, _ = gumbel_sinkhorn(log_alpha, temp=self.temperature, hard=hard, noise_factor=0)\n",
        "            P = P.squeeze().to(device)\n",
        "        elif self.order_type == 'topk':\n",
        "            sort = SoftSort_p1(hard=hard, tau=self.temperature)\n",
        "            P = sort(self.perm_weights.detach().view(1, -1))\n",
        "            P = P.squeeze()\n",
        "        return P\n",
        "\n",
        "    def get_threshold_mask(self, threshold):\n",
        "        P = self.deterministic_permutation()\n",
        "        P_inv = P.transpose(0, 1)\n",
        "        dag = (torch.sigmoid(self.edge_log_params.detach()) > threshold).float()\n",
        "        dag = dag * torch.matmul(torch.matmul(P_inv, self.mask), P)  # apply autoregressive masking\n",
        "        return dag\n",
        "\n",
        "    def get_prob_mask(self):\n",
        "        P = self.deterministic_permutation()\n",
        "        P_inv = P.transpose(0, 1)\n",
        "        e = torch.sigmoid(self.edge_log_params.detach())\n",
        "        e = e * torch.matmul(torch.matmul(P_inv, self.mask), P)  # apply autoregressive masking\n",
        "        return e\n",
        "\n",
        "    def print_parameters(self, prob=True):\n",
        "        print('Permutation Weights')\n",
        "        print(torch.sigmoid(self.perm_weights) if prob else self.perm_weights)\n",
        "        print('Edge Probs')\n",
        "        print(torch.sigmoid(self.edge_log_params) if prob else self.edge_log_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cec87a5",
      "metadata": {
        "id": "6cec87a5"
      },
      "source": [
        "## The Dataset <a class=\"anchor\" id=\"data\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54469b3c",
      "metadata": {
        "id": "54469b3c"
      },
      "source": [
        "* [Back to ToC](#toc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "6f16ecdf",
      "metadata": {
        "id": "6f16ecdf"
      },
      "outputs": [],
      "source": [
        "#A standard process to convert data to loaders\n",
        "def data_to_tensor_dataset(X, batch_size, G=None):\n",
        "\n",
        "    feat_train = torch.FloatTensor(X)\n",
        "    train_data = TensorDataset(feat_train, feat_train)\n",
        "    train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "\n",
        "    return train_data_loader, G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "61af06e1",
      "metadata": {
        "id": "61af06e1"
      },
      "outputs": [],
      "source": [
        "#A standard process to generate a random dag\n",
        "def simulate_random_dag(d: int,\n",
        "                        degree: float,\n",
        "                        graph_type: str,\n",
        "                        w_range: tuple = (0.5, 2.0)) -> nx.DiGraph:\n",
        "    \"\"\"Simulate random DAG with some expected degree.\n",
        "    Args:\n",
        "        d: number of nodes\n",
        "        degree: expected node degree, in + out\n",
        "        graph_type: {erdos-renyi, barabasi-albert, full}\n",
        "        w_range: weight range +/- (low, high)\n",
        "    Returns:\n",
        "        G: weighted DAG\n",
        "    \"\"\"\n",
        "    if graph_type == 'erdos-renyi':\n",
        "        prob = float(degree) / (d - 1)\n",
        "        B = np.tril((np.random.rand(d, d) < prob).astype(float), k=-1)\n",
        "    elif graph_type == 'barabasi-albert':\n",
        "        m = int(round(degree / 2))\n",
        "        B = np.zeros([d, d])\n",
        "        bag = [0]\n",
        "        for ii in range(1, d):\n",
        "            dest = np.random.choice(bag, size=m)\n",
        "            for jj in dest:\n",
        "                B[ii, jj] = 1\n",
        "            bag.append(ii)\n",
        "            bag.extend(dest)\n",
        "    elif graph_type == 'full':  # ignore degree, only for experimental use\n",
        "        B = np.tril(np.ones([d, d]), k=-1)\n",
        "    else:\n",
        "        raise ValueError('unknown graph type')\n",
        "    # random permutation\n",
        "    P = np.random.permutation(np.eye(d, d))  # permutes first axis only\n",
        "    B_perm = P.T.dot(B).dot(P)\n",
        "    U = np.random.uniform(low=w_range[0], high=w_range[1], size=[d, d])\n",
        "    U[np.random.rand(d, d) < 0.5] *= -1\n",
        "    W = (B_perm != 0).astype(float) * U\n",
        "    G = nx.DiGraph(W)\n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "645ba0ed",
      "metadata": {
        "id": "645ba0ed"
      },
      "outputs": [],
      "source": [
        "#DF: this is my version of synthetic data, which creates the data from A\n",
        "def simulate_sem_DF(G: nx.DiGraph,\n",
        "                 n: int, x_dims: int,\n",
        "                 sem_type: str,\n",
        "                 linear_type: str,\n",
        "                 noise_scale: float = 1.0) -> np.ndarray:\n",
        "    \"\"\"Simulate samples from SEM with specified type of noise.\n",
        "    Args:\n",
        "        G: weigthed DAG\n",
        "        n: number of samples\n",
        "        sem_type: {linear-gauss,linear-exp,linear-gumbel}\n",
        "        noise_scale: scale parameter of noise distribution in linear SEM\n",
        "    Returns:\n",
        "        X: [n,d] sample matrix\n",
        "    \"\"\"\n",
        "\n",
        "    ###masked_X = pred_X.clone() * A[current_node-1,:].unsqueeze(0)\n",
        "\n",
        "    W = nx.to_numpy_array(G)\n",
        "    W = np.abs(W.T)                          #DF: nx is colum based, hence we need to change it to row based, also remove negative\n",
        "    print(\"Ground truth: W\\n\", np.around(W,1))\n",
        "\n",
        "    d = W.shape[0]\n",
        "    X = np.zeros([n, d, x_dims])\n",
        "    ordered_vertices = list(nx.topological_sort(G))\n",
        "    assert len(ordered_vertices) == d\n",
        "    #print(\"ordered_vertices\",ordered_vertices)\n",
        "    for j in ordered_vertices:\n",
        "        parents = list(G.predecessors(j))\n",
        "        if linear_type == 'linear':\n",
        "            X[:,j,:] = np.sum(X * W[j,:]) + np.random.normal(scale=noise_scale, size=n)\n",
        "        elif linear_type == 'nonlinear_1':\n",
        "            weighted = np.cos(X+1).squeeze() * W[j,:]\n",
        "\n",
        "            sum1 = np.sum(weighted, axis=1)\n",
        "            sum2 = sum1+np.random.normal(scale=1.0, size=n)*1.0  #1e-01    #was 1.0\n",
        "\n",
        "            #######################################print(\"sum2+shape\",sum2[..., np.newaxis].shape)  #[5000,1]\n",
        "            X[:,j,:] = sum2[..., np.newaxis]\n",
        "\n",
        "            ######################X[:,j,:] = np.sum(np.cos(X+1).squeeze() * W[j,:],axis=1)\n",
        "            ######################X[:,j,:] = np.sum(np.cos(X+1) * W[j,:]) #+ np.random.normal(scale=noise_scale, size=n)\n",
        "        elif linear_type == 'nonlinear_2':\n",
        "            X[:,j,:] = np.sum(2*np.sin((X+0.5) * W[j,:]) + (X+0.5)*W[j,:]) + np.random.normal(scale=noise_scale, size=n)\n",
        "\n",
        "    return X, ordered_vertices   #DF06-01: add for visualizing the node order\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "1d7357e3",
      "metadata": {
        "id": "1d7357e3"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    ## configurations\n",
        "    n, d = data_sample_size, data_variable_size\n",
        "\n",
        "    G = simulate_random_dag(d, graph_degree, graph_type)\n",
        "\n",
        "    X, order = simulate_sem_DF(G, n, x_dims, graph_sem_type, graph_linear_type)\n",
        "\n",
        "    train_data_loader, G = data_to_tensor_dataset(X, batch_size, G)\n",
        "\n",
        "    return train_data_loader, G, X, order  #DF06-01: add X and order for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "902cd635",
      "metadata": {
        "id": "902cd635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf11735-7055-40f6-f0cd-8da7bde507dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_order [8, 6, 7, 3, 2, 5, 1, 0, 9, 4]\n"
          ]
        }
      ],
      "source": [
        "#DF10-01: Here we save/read the CSV and the graph files only (not the loader) to allow batch size change\n",
        "if synthesize:\n",
        "    #create and store synthetic data\n",
        "    train_loader, ground_truth_G, X_data, X_order = load_data()\n",
        "\n",
        "    #DF10-01: save them\n",
        "    #t = time.strftime('%Y-%m-%d %H=%M=%S', time.localtime())\n",
        "    t = time.strftime('%Y-%m-%d %H=%M', time.localtime())\n",
        "    fname2 = f\"data/ground_truth_G\" + str(t) + \".pkl\"\n",
        "    fname3 = f\"data/X_data_exp\"     + str(t) + \".csv\"  #DF10-01: add fname3\n",
        "    with open(fname2, \"wb\") as output_file_G:\n",
        "        pickle.dump(ground_truth_G, output_file_G)\n",
        "    pd.DataFrame(X_data.squeeze()).to_csv(fname3)\n",
        "\n",
        "else:\n",
        "    #DF10-01: read the graph data\n",
        "    with open(fname2, \"rb\") as input_file_G:\n",
        "        ground_truth_G = pickle.load(input_file_G)\n",
        "\n",
        "    #DF10-01: read the csv data\n",
        "    X_data = pd.read_csv(fname3, header=None)\n",
        "    X_data = X_data.to_numpy()\n",
        "    X_data = np.delete(X_data, np.s_[0], axis=0) #DF: remove first row\n",
        "    X_data = np.delete(X_data, np.s_[0], axis=1) #DF: remove first column\n",
        "    X_data = X_data[...,np.newaxis]\n",
        "    #print(\"X_data\", X_data.shape, \"\\n\", X_data)\n",
        "\n",
        "    #DF10-01: create the loader\n",
        "    train_loader, G = data_to_tensor_dataset(X_data, batch_size, ground_truth_G)\n",
        "\n",
        "    #DF10-01; create the order\n",
        "    X_order = list(nx.topological_sort(ground_truth_G))\n",
        "    assert len(X_order) == data_variable_size\n",
        "\n",
        "print(\"X_order\",X_order)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abeccef8",
      "metadata": {
        "id": "abeccef8"
      },
      "source": [
        "## Visualization function<a class=\"anchor\" id=\"visualization\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e41d4f",
      "metadata": {
        "id": "a7e41d4f"
      },
      "source": [
        "* [Back to ToC](#toc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "5ade45e8",
      "metadata": {
        "id": "5ade45e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e6ce0a-3a00-4447-a7fe-3537ee1b0fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the order of the nodes: [8, 6, 7, 3, 2, 5, 1, 0, 9, 4]\n"
          ]
        }
      ],
      "source": [
        "#DF06-01 added a visualization function\n",
        "def Visualize_data(X, variable_size, sampling=0, fname=\"data\"):\n",
        "\n",
        "    plt.ioff()  # Turn interactive plotting off\n",
        "\n",
        "    fig, axs = plt.subplots(variable_size)\n",
        "    fig.suptitle('Data distributions')\n",
        "    fig.set_figheight(5)\n",
        "    fig.set_figwidth(1)\n",
        "\n",
        "    if sampling==0: #visualize the entire dataset\n",
        "        for i in range(variable_size):\n",
        "            axs[i].hist(X[:,i,:], bins=50)\n",
        "            axs[i].set(ylabel='X'+str(i))\n",
        "    else:      #visualize sampled data\n",
        "        sample = np.random.uniform(size=5000)*data_sample_size\n",
        "        sample = sample.astype(int)\n",
        "\n",
        "        for i in range(data_variable_size):\n",
        "            axs[i].hist(X[sample,i,:], bins=50)\n",
        "            axs[i].set(ylabel='X'+str(i))\n",
        "\n",
        "    plt.close(fig) #don't display\n",
        "    #fig.show()\n",
        "    fig.savefig(fname, bbox_inches = 'tight')\n",
        "\n",
        "\n",
        "print(\"the order of the nodes:\",X_order)\n",
        "Visualize_data(X_data, data_variable_size, sampling=0, fname=\"results/data\") #DF10-01: save data to the result folder\n",
        "#Visualize_data(X_data, data_variable_size, sampling=1, fname=\"sampled_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "98193fb0",
      "metadata": {
        "id": "98193fb0"
      },
      "outputs": [],
      "source": [
        "#DF08-01 visualize conditional distributions\n",
        "def Visualize_conditional_distribution(X, variable_size, condition, target, bin_values, fname=\"condition_data\"):\n",
        "#DF: target is a single index in X[]; condition is a single index in X[]\n",
        "#    bin_values[] an array of bins\n",
        "\n",
        "    plt.ioff()  # Turn interactive plotting off\n",
        "    bin_size = len(bin_values)\n",
        "\n",
        "    fig, axs = plt.subplots(bin_size)\n",
        "    fig.suptitle('conditional distributions')\n",
        "    fig.set_figheight(5)\n",
        "    fig.set_figwidth(1)\n",
        "\n",
        "    for i in range(bin_size-1):\n",
        "        rows = np.where((bin_values[i]<X[:,condition,:]) & (X[:,condition,:]<bin_values[i+1]))[0]\n",
        "\n",
        "        axs[i].hist(X[rows,target,:], bins=10)\n",
        "        axs[i].set(ylabel='Bin'+str(i))\n",
        "\n",
        "    plt.close(fig) #don't display\n",
        "    #fig.show()\n",
        "    fig.savefig(fname, bbox_inches = 'tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "2fae27cd",
      "metadata": {
        "id": "2fae27cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f339554c-858c-45ea-9025-cb744a5f5317"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nbin_values = np.arange(-2,2,0.2)\\nfor j in range(data_variable_size):\\n    for i in range(j+1, data_variable_size):\\n        Visualize_conditional_distribution(X_data, data_variable_size, j,i, bin_values,\\n                                           fname=\"data_condition/condition_data\"+str(j+1)+str(i+1))\\n        Visualize_conditional_distribution(X_data, data_variable_size, i,j, bin_values,\\n                                           fname=\"data_condition/condition_data\"+str(i+1)+str(j+1))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "#DF09-01: visualise the conditional distribution\n",
        "\"\"\"\n",
        "bin_values = np.arange(-2,2,0.2)\n",
        "for j in range(data_variable_size):\n",
        "    for i in range(j+1, data_variable_size):\n",
        "        Visualize_conditional_distribution(X_data, data_variable_size, j,i, bin_values,\n",
        "                                           fname=\"data_condition/condition_data\"+str(j+1)+str(i+1))\n",
        "        Visualize_conditional_distribution(X_data, data_variable_size, i,j, bin_values,\n",
        "                                           fname=\"data_condition/condition_data\"+str(i+1)+str(j+1))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5bbd34e",
      "metadata": {
        "id": "e5bbd34e"
      },
      "source": [
        "## Instantiation <a class=\"anchor\" id=\"instantiation\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "965aeee2",
      "metadata": {
        "id": "965aeee2"
      },
      "source": [
        "* [Back to ToC](#toc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "c4e75cf7",
      "metadata": {
        "id": "c4e75cf7"
      },
      "outputs": [],
      "source": [
        "#DF18-01: add to device for GPU\n",
        "discriminator = Discriminator(data_variable_size, (256, 256), negative_slope, dropout_rate).double().to(device) #.to(self.device)\n",
        "#DF tried different Generator layers\n",
        "generator = Generator(z_dims, code_dims, dims=[data_variable_size, 10, 10, 10, 1], bias=True).double().to(device) #.to(self.device)\n",
        "#generator = Generator(self.z_dims, self.code_dim, dims=[self.data_variable_size, 10, 10, 1], bias=True).double().to(self.devic\n",
        "#DF modi: experiment with a different order_type\n",
        "dp_dag = ProbabilisticDAG(n_nodes=data_variable_size, order_type='topk', initial_adj=None, seed=seed).to(device) #.to(self.device)\n",
        "#dp_dag = ProbabilisticDAG(n_nodes=self.data_variable_size, order_type='sinkhorn', initial_adj=None, seed=self.seed).to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "6e28c906",
      "metadata": {
        "id": "6e28c906"
      },
      "outputs": [],
      "source": [
        "#optimizer = torch.optim.Adam([X], lr=1e-01)\n",
        "#optimizer.zero_grad()\n",
        "\n",
        "optimizerD   = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.9), weight_decay=1e-6)\n",
        "#DF16-01: change according to the suggestions by Hristo\n",
        "#optimizerG   = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "optimizerG   = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9), weight_decay=1e-6)\n",
        "optimizerDAG = torch.optim.Adam(dp_dag.parameters(), lr=lr*es)  #DF reduce lr for DAG 0.00001 #DF_11_01 use es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "602562a6",
      "metadata": {
        "id": "602562a6"
      },
      "outputs": [],
      "source": [
        "#DF16-01: add schedulers\n",
        "#schedulerG   = lr_scheduler.StepLR(optimizerG,   step_size=lr_decay, gamma=gamma)\n",
        "#schedulerD   = lr_scheduler.StepLR(optimizerD,   step_size=lr_decay, gamma=gamma)\n",
        "#schedulerDAG = lr_scheduler.StepLR(optimizerDAG, step_size=lr_decay, gamma=gamma)\n",
        "\n",
        "schedulerG   = lr_scheduler.CosineAnnealingLR(optimizerG,   200)\n",
        "schedulerD   = lr_scheduler.CosineAnnealingLR(optimizerD,   200)\n",
        "schedulerDAG = lr_scheduler.CosineAnnealingLR(optimizerDAG, 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e7cb4ae",
      "metadata": {
        "id": "2e7cb4ae"
      },
      "source": [
        "## Training <a class=\"anchor\" id=\"training\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674220e2",
      "metadata": {
        "id": "674220e2"
      },
      "source": [
        "* [Back to ToC](#toc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "6f6d845f",
      "metadata": {
        "id": "6f6d845f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f41cbcc-db90-4e5a-b928-4609ab6a4bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth -show before training- W\n",
            " [[0.  1.7 2.  0.  0.  0.7 0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.8 0.  0.  0.  0.  0.6 0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  1.5 0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  1.4 0.  0.  0. ]\n",
            " [0.  1.3 0.6 0.  0.  0.5 0.  0.  0.  1.8]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.7 0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  1.4 0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  1.1 0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  1.4 0.  0.8 0.  0.  1.8 0.  0.9 0. ]]\n",
            "X_order [8, 6, 7, 3, 2, 5, 1, 0, 9, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2919: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0000 D_loss: -74.3874754900 G_loss: 57.9678316785 Pen_loss: 42.0401331116 mse_train: 46.8831918392 shd_trian: 34.4285714286 time: 1.0025s\n",
            "Epoch: 0001 D_loss: -4.3052557979 G_loss: 8.8806572780 Pen_loss: 1.3133820319 mse_train: 5.4965956521 shd_trian: 35.8571428571 time: 0.6560s\n",
            "Epoch: 0002 D_loss: -1.4181615736 G_loss: 3.5357142061 Pen_loss: 0.5719662582 mse_train: 4.5815624867 shd_trian: 34.1428571429 time: 0.6608s\n",
            "Epoch: 0003 D_loss: -0.6274694314 G_loss: 1.2008886467 Pen_loss: 0.4704172098 mse_train: 3.8808841956 shd_trian: 34.0000000000 time: 0.7183s\n",
            "Epoch: 0004 D_loss: -1.4668658473 G_loss: -0.3531436747 Pen_loss: 0.5612154686 mse_train: 3.7715884004 shd_trian: 33.4285714286 time: 0.6628s\n",
            "Epoch: 0005 D_loss: -3.1279939199 G_loss: -0.8785236336 Pen_loss: 1.2475707173 mse_train: 3.9395672259 shd_trian: 33.0000000000 time: 0.6572s\n",
            "Epoch: 0006 D_loss: -2.1948241771 G_loss: -1.4170531876 Pen_loss: 0.6813878732 mse_train: 4.0501536236 shd_trian: 32.4285714286 time: 0.6616s\n",
            "Epoch: 0007 D_loss: -1.7053566480 G_loss: 0.4811968584 Pen_loss: 0.8105083950 mse_train: 4.3423615341 shd_trian: 33.1428571429 time: 0.6431s\n",
            "Epoch: 0008 D_loss: -2.2795907814 G_loss: 0.6548793414 Pen_loss: 0.7251487142 mse_train: 4.3484834050 shd_trian: 32.8571428571 time: 0.6622s\n",
            "Epoch: 0009 D_loss: -2.0447857052 G_loss: 0.1402551159 Pen_loss: 0.8496872323 mse_train: 3.9383755040 shd_trian: 33.4285714286 time: 0.6831s\n",
            "Epoch: 0010 D_loss: -1.6543565973 G_loss: 0.5959433811 Pen_loss: 0.6766792084 mse_train: 3.9760222982 shd_trian: 33.0000000000 time: 0.6591s\n",
            "Epoch: 0011 D_loss: -3.1713437790 G_loss: 0.9804763213 Pen_loss: 1.7900098496 mse_train: 5.3531133182 shd_trian: 33.5714285714 time: 0.8041s\n",
            "Epoch: 0012 D_loss: -2.6021771319 G_loss: 5.9049451104 Pen_loss: 1.1409632585 mse_train: 6.0091250461 shd_trian: 33.0000000000 time: 0.9661s\n",
            "Epoch: 0013 D_loss: -2.5645610794 G_loss: 0.0481023485 Pen_loss: 0.6946360838 mse_train: 3.8995061403 shd_trian: 33.0000000000 time: 0.7513s\n",
            "Epoch: 0014 D_loss: -2.3694383560 G_loss: -0.4705337581 Pen_loss: 0.9578966488 mse_train: 4.2769899061 shd_trian: 33.0000000000 time: 0.6596s\n",
            "Epoch: 0015 D_loss: -2.3533452620 G_loss: 0.2393535408 Pen_loss: 0.8921894423 mse_train: 4.7082701853 shd_trian: 33.0000000000 time: 0.6584s\n",
            "Epoch: 0016 D_loss: -1.8538307092 G_loss: 1.0012665969 Pen_loss: 0.8824035921 mse_train: 4.5511556445 shd_trian: 32.7142857143 time: 0.6504s\n",
            "Epoch: 0017 D_loss: -2.4641860735 G_loss: 1.9347317341 Pen_loss: 0.7614152702 mse_train: 5.6600122545 shd_trian: 31.2857142857 time: 0.6623s\n",
            "Epoch: 0018 D_loss: -1.8344772661 G_loss: 0.4837102335 Pen_loss: 0.8440798449 mse_train: 3.8990481978 shd_trian: 30.8571428571 time: 0.6720s\n",
            "Epoch: 0019 D_loss: -2.1505003967 G_loss: 2.4704447519 Pen_loss: 0.7247432915 mse_train: 6.0219400724 shd_trian: 29.7142857143 time: 0.6426s\n",
            "Epoch: 0020 D_loss: -2.5137196141 G_loss: -0.8581387839 Pen_loss: 0.7255372440 mse_train: 4.5383827125 shd_trian: 28.7142857143 time: 0.6797s\n",
            "Epoch: 0021 D_loss: -1.1404225824 G_loss: -0.3630564740 Pen_loss: 0.7294607335 mse_train: 4.2578665119 shd_trian: 29.4285714286 time: 0.6591s\n",
            "Epoch: 0022 D_loss: -2.1519501162 G_loss: 2.7132290234 Pen_loss: 0.8231089330 mse_train: 5.3681032334 shd_trian: 27.7142857143 time: 0.6615s\n",
            "Epoch: 0023 D_loss: -1.8802572574 G_loss: -0.1409059719 Pen_loss: 0.7630945735 mse_train: 4.1474525245 shd_trian: 28.7142857143 time: 0.6606s\n",
            "Epoch: 0024 D_loss: -1.2737168835 G_loss: -0.6257318138 Pen_loss: 0.6966413292 mse_train: 4.6929072978 shd_trian: 30.0000000000 time: 0.7019s\n",
            "Epoch: 0025 D_loss: -1.6353364066 G_loss: 0.7547133699 Pen_loss: 0.7082831672 mse_train: 4.6151700451 shd_trian: 30.0000000000 time: 0.6745s\n",
            "Epoch: 0026 D_loss: -1.8499741344 G_loss: -0.6669949476 Pen_loss: 0.6332714150 mse_train: 5.9533590405 shd_trian: 30.0000000000 time: 0.9653s\n",
            "Epoch: 0027 D_loss: -2.2368685792 G_loss: 4.0370381252 Pen_loss: 1.1839998604 mse_train: 4.8752585808 shd_trian: 29.8571428571 time: 1.1731s\n",
            "Epoch: 0028 D_loss: -2.2108261917 G_loss: 0.3993342271 Pen_loss: 0.7279962457 mse_train: 4.1597181331 shd_trian: 31.0000000000 time: 0.7147s\n",
            "Epoch: 0029 D_loss: -1.8217670770 G_loss: 1.1288949157 Pen_loss: 1.0237959939 mse_train: 4.1513060639 shd_trian: 32.0000000000 time: 0.6793s\n",
            "Epoch: 0030 D_loss: -1.1370613800 G_loss: 0.2178511383 Pen_loss: 0.6359408886 mse_train: 4.4017688132 shd_trian: 31.1428571429 time: 0.6747s\n",
            "Epoch: 0031 D_loss: -1.7729555604 G_loss: 2.9742820786 Pen_loss: 0.6970000060 mse_train: 5.0843488240 shd_trian: 30.0000000000 time: 0.6543s\n",
            "Epoch: 0032 D_loss: -1.9056459564 G_loss: 0.3071420603 Pen_loss: 0.8151136229 mse_train: 4.7471176487 shd_trian: 31.1428571429 time: 0.7264s\n",
            "Epoch: 0033 D_loss: -1.2221074710 G_loss: 2.4881362385 Pen_loss: 0.7504898316 mse_train: 4.5183475161 shd_trian: 31.7142857143 time: 0.7928s\n",
            "Epoch: 0034 D_loss: -1.9376169444 G_loss: 0.5080447433 Pen_loss: 0.6051527461 mse_train: 3.9605499000 shd_trian: 29.7142857143 time: 0.6684s\n",
            "Epoch: 0035 D_loss: -1.6526553506 G_loss: -0.0094557749 Pen_loss: 0.6505919435 mse_train: 4.5257980498 shd_trian: 29.0000000000 time: 0.6938s\n",
            "Epoch: 0036 D_loss: -1.2928404148 G_loss: 3.2828374835 Pen_loss: 0.8855158347 mse_train: 4.2768302343 shd_trian: 29.0000000000 time: 0.7199s\n",
            "Epoch: 0037 D_loss: -1.8661992998 G_loss: 1.9489568611 Pen_loss: 0.8165720214 mse_train: 3.7570385407 shd_trian: 30.0000000000 time: 0.7344s\n",
            "Epoch: 0038 D_loss: -1.3746321860 G_loss: -0.3422537137 Pen_loss: 0.6080187965 mse_train: 4.0885922388 shd_trian: 29.0000000000 time: 0.6443s\n",
            "Epoch: 0039 D_loss: -1.6033810141 G_loss: 2.3553791449 Pen_loss: 0.8527733864 mse_train: 5.5878225589 shd_trian: 29.0000000000 time: 0.9550s\n",
            "Epoch: 0040 D_loss: -1.6602672144 G_loss: 3.5374266973 Pen_loss: 0.7979953871 mse_train: 6.7631634060 shd_trian: 28.5714285714 time: 1.1124s\n",
            "Epoch: 0041 D_loss: -1.4345764561 G_loss: -1.0909418337 Pen_loss: 0.7623431513 mse_train: 3.9791024475 shd_trian: 27.7142857143 time: 0.6629s\n",
            "Epoch: 0042 D_loss: -1.8902427272 G_loss: -0.1547378559 Pen_loss: 0.7683220672 mse_train: 3.8314096557 shd_trian: 27.8571428571 time: 0.6547s\n",
            "Epoch: 0043 D_loss: -1.8094301553 G_loss: 0.2038989522 Pen_loss: 0.7652469814 mse_train: 4.3354693806 shd_trian: 28.0000000000 time: 0.6774s\n",
            "Epoch: 0044 D_loss: -1.1852317774 G_loss: 1.6897094619 Pen_loss: 0.5778793413 mse_train: 4.5227554832 shd_trian: 29.0000000000 time: 0.6524s\n",
            "Epoch: 0045 D_loss: -1.4351126978 G_loss: -0.0536929387 Pen_loss: 0.6246214109 mse_train: 4.3068140181 shd_trian: 30.0000000000 time: 0.6443s\n",
            "Epoch: 0046 D_loss: -2.1455733324 G_loss: 1.7100543676 Pen_loss: 0.9309949482 mse_train: 4.5543766102 shd_trian: 31.1428571429 time: 0.7348s\n",
            "Epoch: 0047 D_loss: -1.4720975802 G_loss: 1.5343397335 Pen_loss: 0.6478965125 mse_train: 4.3063486044 shd_trian: 31.2857142857 time: 0.7240s\n",
            "Epoch: 0048 D_loss: -1.5843741430 G_loss: 1.1472393568 Pen_loss: 0.7882753374 mse_train: 4.1671322431 shd_trian: 30.2857142857 time: 0.6564s\n",
            "Epoch: 0049 D_loss: -1.3075908617 G_loss: -0.1449632889 Pen_loss: 0.7524466132 mse_train: 3.9282963177 shd_trian: 29.0000000000 time: 0.6540s\n",
            "Epoch: 0050 D_loss: -0.8602473321 G_loss: 2.0306347939 Pen_loss: 0.6306593269 mse_train: 4.6193050747 shd_trian: 30.0000000000 time: 0.6446s\n",
            "Epoch: 0051 D_loss: -1.5204549232 G_loss: 1.5827845383 Pen_loss: 0.7890737076 mse_train: 4.9882234190 shd_trian: 29.7142857143 time: 0.9548s\n",
            "Epoch: 0052 D_loss: -1.4264003901 G_loss: 0.3032749232 Pen_loss: 0.6038041954 mse_train: 5.4450663483 shd_trian: 29.2857142857 time: 0.8019s\n",
            "Epoch: 0053 D_loss: -4.0772395603 G_loss: 5.8304722491 Pen_loss: 1.7194986270 mse_train: 6.3843205208 shd_trian: 28.8571428571 time: 0.6934s\n",
            "Epoch: 0054 D_loss: -1.9396502227 G_loss: 4.5516593528 Pen_loss: 0.7842674632 mse_train: 7.0368455457 shd_trian: 27.4285714286 time: 0.6563s\n",
            "Epoch: 0055 D_loss: -2.0010670095 G_loss: -0.1139662793 Pen_loss: 0.6057278673 mse_train: 4.3786480913 shd_trian: 29.4285714286 time: 0.7704s\n",
            "Epoch: 0056 D_loss: -2.0261800271 G_loss: 3.5228716635 Pen_loss: 0.9973917166 mse_train: 4.5327449538 shd_trian: 29.0000000000 time: 0.6506s\n",
            "Epoch: 0057 D_loss: -1.6691719006 G_loss: -0.6889505971 Pen_loss: 0.8269286017 mse_train: 3.8788494428 shd_trian: 29.4285714286 time: 0.6477s\n",
            "Epoch: 0058 D_loss: -1.3441892794 G_loss: 2.8990077762 Pen_loss: 0.6953916111 mse_train: 4.1028459159 shd_trian: 29.0000000000 time: 0.6675s\n",
            "Epoch: 0059 D_loss: -1.8303522396 G_loss: -0.6279956120 Pen_loss: 0.6893405730 mse_train: 3.9010771856 shd_trian: 28.2857142857 time: 0.6638s\n",
            "Epoch: 0060 D_loss: -0.8982581083 G_loss: 1.7175340441 Pen_loss: 0.6757508053 mse_train: 4.1805771515 shd_trian: 27.0000000000 time: 0.6710s\n",
            "Epoch: 0061 D_loss: -1.5425343755 G_loss: 2.0650966591 Pen_loss: 0.6181558695 mse_train: 6.6182916063 shd_trian: 27.0000000000 time: 0.6356s\n",
            "Epoch: 0062 D_loss: -0.9922395532 G_loss: -0.1498835143 Pen_loss: 0.6033416101 mse_train: 5.2734353849 shd_trian: 27.0000000000 time: 0.6566s\n",
            "Epoch: 0063 D_loss: -1.4512492202 G_loss: 3.8570019237 Pen_loss: 1.2657640142 mse_train: 4.7804444138 shd_trian: 27.0000000000 time: 0.6362s\n",
            "Epoch: 0064 D_loss: -1.1601012472 G_loss: 1.9856449395 Pen_loss: 0.5257491857 mse_train: 4.6186901658 shd_trian: 27.0000000000 time: 1.0299s\n",
            "Epoch: 0065 D_loss: -1.8361504233 G_loss: 0.0277777237 Pen_loss: 0.6972241433 mse_train: 3.7817497027 shd_trian: 25.8571428571 time: 0.9857s\n",
            "Epoch: 0066 D_loss: -1.9554901586 G_loss: 0.2655451935 Pen_loss: 0.9134798666 mse_train: 3.8656075185 shd_trian: 25.2857142857 time: 0.8041s\n",
            "Epoch: 0067 D_loss: -1.0331212773 G_loss: 0.9375241107 Pen_loss: 0.5619677741 mse_train: 4.5999353832 shd_trian: 26.0000000000 time: 0.6652s\n",
            "Epoch: 0068 D_loss: -0.7214682612 G_loss: 2.2708887608 Pen_loss: 0.7492408954 mse_train: 5.5152907726 shd_trian: 26.2857142857 time: 0.6649s\n",
            "Epoch: 0069 D_loss: -0.8093569906 G_loss: 1.7336259241 Pen_loss: 0.5136336936 mse_train: 4.6505539123 shd_trian: 27.0000000000 time: 0.6614s\n",
            "Epoch: 0070 D_loss: -0.8948728538 G_loss: 1.1653003319 Pen_loss: 0.5844382162 mse_train: 4.0365828065 shd_trian: 26.7142857143 time: 0.6638s\n",
            "Epoch: 0071 D_loss: -1.1918367026 G_loss: 0.6309477404 Pen_loss: 0.7320411244 mse_train: 4.3954414179 shd_trian: 27.1428571429 time: 0.6581s\n",
            "Epoch: 0072 D_loss: -1.2113468721 G_loss: 0.9497487220 Pen_loss: 0.5583185243 mse_train: 3.8163391480 shd_trian: 28.0000000000 time: 0.6758s\n",
            "Epoch: 0073 D_loss: -1.8423515505 G_loss: 1.4901069960 Pen_loss: 0.9124652853 mse_train: 5.3697147910 shd_trian: 27.8571428571 time: 0.6603s\n",
            "Epoch: 0074 D_loss: -1.5520954788 G_loss: 1.5934740070 Pen_loss: 0.7063702701 mse_train: 4.3163389979 shd_trian: 28.0000000000 time: 0.6574s\n",
            "Epoch: 0075 D_loss: -1.9731599512 G_loss: 1.3405320297 Pen_loss: 1.0828885785 mse_train: 3.8762546852 shd_trian: 28.4285714286 time: 0.6453s\n",
            "Epoch: 0076 D_loss: -2.1228252217 G_loss: 1.6183693364 Pen_loss: 0.6944004215 mse_train: 4.4935837441 shd_trian: 29.0000000000 time: 0.6909s\n",
            "Epoch: 0077 D_loss: -1.1614316169 G_loss: 0.1917240425 Pen_loss: 0.6138443694 mse_train: 3.9067000522 shd_trian: 29.0000000000 time: 0.6849s\n",
            "Epoch: 0078 D_loss: -1.1271999954 G_loss: -0.0371635276 Pen_loss: 0.6790039353 mse_train: 4.5222785584 shd_trian: 29.0000000000 time: 0.6500s\n",
            "Epoch: 0079 D_loss: -4.2566906859 G_loss: 2.6347016899 Pen_loss: 1.7766350505 mse_train: 7.1049571991 shd_trian: 29.4285714286 time: 0.9649s\n",
            "Epoch: 0080 D_loss: -1.6942073863 G_loss: 1.9113028298 Pen_loss: 0.9636744125 mse_train: 4.6700543628 shd_trian: 29.1428571429 time: 0.9651s\n",
            "Epoch: 0081 D_loss: -1.8157698268 G_loss: 1.1723554869 Pen_loss: 0.6044594850 mse_train: 4.7528587288 shd_trian: 29.2857142857 time: 0.6798s\n",
            "Epoch: 0082 D_loss: -1.3376704999 G_loss: 1.1755330399 Pen_loss: 0.5443712588 mse_train: 4.2707990613 shd_trian: 28.2857142857 time: 0.6513s\n",
            "Epoch: 0083 D_loss: -1.0243875462 G_loss: 1.5356325243 Pen_loss: 0.6155026924 mse_train: 4.8576558946 shd_trian: 28.0000000000 time: 0.6617s\n",
            "Epoch: 0084 D_loss: -1.1669472271 G_loss: 0.5255012038 Pen_loss: 0.5615313924 mse_train: 4.2181349351 shd_trian: 27.7142857143 time: 0.6713s\n",
            "Epoch: 0085 D_loss: -1.1642192426 G_loss: 0.3320116952 Pen_loss: 0.6289552002 mse_train: 4.6370581614 shd_trian: 27.0000000000 time: 0.6604s\n",
            "Epoch: 0086 D_loss: -0.7481121478 G_loss: 2.0897097429 Pen_loss: 0.6172344818 mse_train: 4.7484566818 shd_trian: 27.0000000000 time: 0.6629s\n",
            "Epoch: 0087 D_loss: -1.6779468201 G_loss: 2.9596659986 Pen_loss: 0.5931931036 mse_train: 5.0869687023 shd_trian: 27.0000000000 time: 0.6539s\n",
            "Epoch: 0088 D_loss: -1.3710228888 G_loss: -1.1355715090 Pen_loss: 0.7263306312 mse_train: 4.1676188200 shd_trian: 27.0000000000 time: 0.6666s\n",
            "Epoch: 0089 D_loss: -0.7476222305 G_loss: 1.7601552255 Pen_loss: 0.5991277674 mse_train: 3.9671590450 shd_trian: 27.0000000000 time: 0.6600s\n",
            "Epoch: 0090 D_loss: -1.4378211433 G_loss: -0.5543391622 Pen_loss: 0.5676193766 mse_train: 3.9223443085 shd_trian: 26.5714285714 time: 0.6441s\n",
            "Epoch: 0091 D_loss: -1.5299208322 G_loss: 0.1273724668 Pen_loss: 0.7019596150 mse_train: 4.4133612275 shd_trian: 26.0000000000 time: 0.9807s\n",
            "Epoch: 0092 D_loss: -1.2666011643 G_loss: 3.4514380708 Pen_loss: 1.1503501631 mse_train: 4.9156655004 shd_trian: 27.8571428571 time: 0.7775s\n",
            "Epoch: 0093 D_loss: -1.4526952934 G_loss: 0.4945799454 Pen_loss: 0.6913433142 mse_train: 4.2925577516 shd_trian: 29.0000000000 time: 0.6633s\n",
            "Epoch: 0094 D_loss: -1.6624468401 G_loss: -0.5369811710 Pen_loss: 0.6927627427 mse_train: 3.8205128794 shd_trian: 28.5714285714 time: 0.6614s\n",
            "Epoch: 0095 D_loss: -0.9855467106 G_loss: 0.6535893069 Pen_loss: 0.5847706417 mse_train: 3.9778456386 shd_trian: 29.0000000000 time: 0.6679s\n",
            "Epoch: 0096 D_loss: -1.0752921130 G_loss: 0.7858790516 Pen_loss: 0.6246796401 mse_train: 4.5527068811 shd_trian: 28.1428571429 time: 0.6565s\n",
            "Epoch: 0097 D_loss: -1.2395321650 G_loss: -0.3722094708 Pen_loss: 0.4827152557 mse_train: 4.1020295422 shd_trian: 28.0000000000 time: 0.6529s\n",
            "Epoch: 0098 D_loss: -1.3425532782 G_loss: 1.0614271882 Pen_loss: 0.6379489268 mse_train: 5.1847960327 shd_trian: 28.0000000000 time: 0.6568s\n",
            "Epoch: 0099 D_loss: -1.7333840988 G_loss: 2.3596396043 Pen_loss: 0.8617266223 mse_train: 4.0405952644 shd_trian: 27.8571428571 time: 0.6478s\n",
            "Epoch: 0100 D_loss: -2.0012777679 G_loss: -0.0459091476 Pen_loss: 0.6303391210 mse_train: 4.4766445282 shd_trian: 25.5714285714 time: 0.7078s\n",
            "Epoch: 0101 D_loss: -1.5955907009 G_loss: 0.4202403732 Pen_loss: 0.6386051406 mse_train: 4.1043974917 shd_trian: 25.1428571429 time: 0.9120s\n",
            "Epoch: 0102 D_loss: -1.6896449836 G_loss: 2.9220584513 Pen_loss: 0.7975440491 mse_train: 4.4929807776 shd_trian: 26.0000000000 time: 0.6638s\n",
            "Epoch: 0103 D_loss: -1.5979074958 G_loss: 2.6053270023 Pen_loss: 0.7788298505 mse_train: 4.1307631748 shd_trian: 26.0000000000 time: 0.6582s\n",
            "Epoch: 0104 D_loss: -1.3796767400 G_loss: 0.9163348959 Pen_loss: 0.6429165481 mse_train: 4.9816357382 shd_trian: 26.0000000000 time: 0.7993s\n",
            "Epoch: 0105 D_loss: -1.4869620635 G_loss: 2.3173315321 Pen_loss: 0.6127240219 mse_train: 5.6638193094 shd_trian: 26.0000000000 time: 0.9773s\n",
            "Epoch: 0106 D_loss: -1.5064429220 G_loss: 0.6051171082 Pen_loss: 1.1261253933 mse_train: 4.3552718261 shd_trian: 26.5714285714 time: 0.7954s\n",
            "Epoch: 0107 D_loss: -0.9727933470 G_loss: 3.1959279532 Pen_loss: 0.8490714147 mse_train: 6.0905377501 shd_trian: 26.8571428571 time: 0.6708s\n",
            "Epoch: 0108 D_loss: -0.6550891606 G_loss: 0.4555267838 Pen_loss: 0.6315869057 mse_train: 4.3909603279 shd_trian: 25.4285714286 time: 0.6677s\n",
            "Epoch: 0109 D_loss: -1.8524356607 G_loss: 6.9934017111 Pen_loss: 1.5430942340 mse_train: 7.7757144934 shd_trian: 23.7142857143 time: 0.6514s\n",
            "Epoch: 0110 D_loss: -1.6833253076 G_loss: -3.5529296788 Pen_loss: 0.6562377952 mse_train: 4.9751623912 shd_trian: 24.1428571429 time: 0.6740s\n",
            "Epoch: 0111 D_loss: -1.5427055133 G_loss: -1.3893616926 Pen_loss: 0.5524359598 mse_train: 5.0108798632 shd_trian: 23.0000000000 time: 0.6456s\n",
            "Epoch: 0112 D_loss: -0.5034134487 G_loss: 2.7042644934 Pen_loss: 0.5700384587 mse_train: 4.3430150854 shd_trian: 23.0000000000 time: 0.6629s\n",
            "Epoch: 0113 D_loss: -0.9154515859 G_loss: 0.2971487991 Pen_loss: 0.6453632333 mse_train: 5.1529082794 shd_trian: 23.0000000000 time: 0.6492s\n",
            "Epoch: 0114 D_loss: -1.4655619390 G_loss: -0.0964007855 Pen_loss: 0.5732875451 mse_train: 6.3248166037 shd_trian: 23.4285714286 time: 0.7001s\n",
            "Epoch: 0115 D_loss: -1.8775510955 G_loss: 3.3387142763 Pen_loss: 1.2279880402 mse_train: 4.3249770050 shd_trian: 23.4285714286 time: 0.6702s\n",
            "Epoch: 0116 D_loss: -0.9763651241 G_loss: 3.2559540730 Pen_loss: 0.4879331832 mse_train: 4.6033078637 shd_trian: 24.0000000000 time: 0.6383s\n",
            "Epoch: 0117 D_loss: -1.0399523679 G_loss: -0.2845760915 Pen_loss: 0.4988675732 mse_train: 7.1249804934 shd_trian: 24.2857142857 time: 0.6587s\n",
            "Epoch: 0118 D_loss: -1.0470551997 G_loss: 3.8357311669 Pen_loss: 0.8867708471 mse_train: 7.2005604135 shd_trian: 24.0000000000 time: 0.6624s\n",
            "Epoch: 0119 D_loss: -1.4852388035 G_loss: -0.3678107831 Pen_loss: 0.6156960031 mse_train: 4.7609466102 shd_trian: 23.0000000000 time: 1.2174s\n",
            "Epoch: 0120 D_loss: -1.1703460251 G_loss: 4.8163120014 Pen_loss: 0.7019465011 mse_train: 4.5693111531 shd_trian: 23.0000000000 time: 0.8310s\n",
            "Epoch: 0121 D_loss: -1.4415945033 G_loss: -0.0918747253 Pen_loss: 0.5871257954 mse_train: 4.5081580752 shd_trian: 23.1428571429 time: 0.6905s\n",
            "Epoch: 0122 D_loss: -1.7021539565 G_loss: -2.5594192084 Pen_loss: 0.5775651736 mse_train: 5.3005912352 shd_trian: 23.0000000000 time: 0.6465s\n",
            "Epoch: 0123 D_loss: -1.6306851281 G_loss: 4.9235313273 Pen_loss: 0.8556598150 mse_train: 5.4545351247 shd_trian: 24.0000000000 time: 0.6743s\n",
            "Epoch: 0124 D_loss: -1.6569622702 G_loss: 0.2268573423 Pen_loss: 0.5820630699 mse_train: 4.6047682028 shd_trian: 24.0000000000 time: 0.6657s\n",
            "Epoch: 0125 D_loss: -1.2629074151 G_loss: -0.8703652543 Pen_loss: 0.6275744640 mse_train: 5.1670097011 shd_trian: 25.0000000000 time: 0.6809s\n",
            "Epoch: 0126 D_loss: -1.3693629608 G_loss: 2.5124683828 Pen_loss: 0.6638481173 mse_train: 4.2073485970 shd_trian: 25.0000000000 time: 0.6609s\n",
            "Epoch: 0127 D_loss: -2.0232549775 G_loss: 2.2981420423 Pen_loss: 0.8022856729 mse_train: 4.6940278890 shd_trian: 25.8571428571 time: 0.6568s\n",
            "Epoch: 0128 D_loss: -1.2356783121 G_loss: 0.6895892685 Pen_loss: 0.5691882566 mse_train: 5.1092190905 shd_trian: 25.7142857143 time: 0.7148s\n",
            "Epoch: 0129 D_loss: -1.0537049565 G_loss: 0.0529122520 Pen_loss: 0.5480640731 mse_train: 4.6310029342 shd_trian: 24.5714285714 time: 0.6528s\n",
            "Epoch: 0130 D_loss: -1.4763047288 G_loss: 0.0899106666 Pen_loss: 0.6275024751 mse_train: 4.0137886272 shd_trian: 24.0000000000 time: 0.6487s\n",
            "Epoch: 0131 D_loss: -1.6367364291 G_loss: -1.2190266079 Pen_loss: 0.6322886079 mse_train: 3.9104292384 shd_trian: 22.8571428571 time: 0.9585s\n",
            "Epoch: 0132 D_loss: -1.4120717121 G_loss: -2.3824567717 Pen_loss: 0.6299439526 mse_train: 4.1615730945 shd_trian: 21.8571428571 time: 0.7258s\n",
            "Epoch: 0133 D_loss: -1.4355016743 G_loss: 8.1846103406 Pen_loss: 0.7890116405 mse_train: 5.9654287167 shd_trian: 21.5714285714 time: 0.6485s\n",
            "Epoch: 0134 D_loss: -1.8364970591 G_loss: -0.5719440595 Pen_loss: 0.6918950307 mse_train: 4.0886049454 shd_trian: 22.4285714286 time: 0.6475s\n",
            "Epoch: 0135 D_loss: -1.4414631834 G_loss: 1.1567869064 Pen_loss: 0.7384595602 mse_train: 4.0303218685 shd_trian: 24.8571428571 time: 0.6916s\n",
            "Epoch: 0136 D_loss: -1.1417184403 G_loss: -1.2603990251 Pen_loss: 0.7619958963 mse_train: 5.1724425299 shd_trian: 26.0000000000 time: 0.8024s\n",
            "Epoch: 0137 D_loss: -1.0834630959 G_loss: 4.0307287034 Pen_loss: 0.7258163881 mse_train: 4.9650657838 shd_trian: 25.4285714286 time: 0.6591s\n",
            "Epoch: 0138 D_loss: -1.5599821727 G_loss: -1.1401747124 Pen_loss: 0.5747825791 mse_train: 4.1027173444 shd_trian: 24.7142857143 time: 0.6571s\n",
            "Epoch: 0139 D_loss: -1.0999878371 G_loss: 0.4494362920 Pen_loss: 0.6841161508 mse_train: 5.0134145161 shd_trian: 24.0000000000 time: 0.6553s\n",
            "Epoch: 0140 D_loss: -1.5009080939 G_loss: 1.8497596469 Pen_loss: 0.8055095126 mse_train: 4.7004319125 shd_trian: 24.0000000000 time: 0.6494s\n",
            "Epoch: 0141 D_loss: -1.4541480141 G_loss: 2.4535278426 Pen_loss: 0.6957018693 mse_train: 4.2315604178 shd_trian: 23.7142857143 time: 0.6573s\n",
            "Epoch: 0142 D_loss: -0.8376127678 G_loss: 1.3136726369 Pen_loss: 0.5301475121 mse_train: 5.1143978257 shd_trian: 23.0000000000 time: 0.6490s\n",
            "Epoch: 0143 D_loss: -1.0385247436 G_loss: 1.7522695043 Pen_loss: 0.7348939904 mse_train: 4.4135788629 shd_trian: 24.7142857143 time: 0.6691s\n",
            "Epoch: 0144 D_loss: -1.4321908558 G_loss: 3.9745094199 Pen_loss: 0.6451034642 mse_train: 5.2564009353 shd_trian: 25.0000000000 time: 0.8604s\n",
            "Epoch: 0145 D_loss: -1.6178756410 G_loss: -0.7828826805 Pen_loss: 0.5554192205 mse_train: 3.9034064676 shd_trian: 25.0000000000 time: 0.9796s\n",
            "Epoch: 0146 D_loss: -1.6627327133 G_loss: 0.3920573184 Pen_loss: 0.7781472028 mse_train: 4.0826624629 shd_trian: 26.7142857143 time: 0.7578s\n",
            "Epoch: 0147 D_loss: -1.8244001382 G_loss: 0.2312084883 Pen_loss: 0.6180829264 mse_train: 4.0770632159 shd_trian: 26.0000000000 time: 0.6501s\n",
            "Epoch: 0148 D_loss: -1.2725638394 G_loss: 0.1983508909 Pen_loss: 0.6510125609 mse_train: 4.4959982335 shd_trian: 24.7142857143 time: 0.6590s\n",
            "Epoch: 0149 D_loss: -1.0018157481 G_loss: -2.6441274294 Pen_loss: 0.6753530443 mse_train: 3.8724129919 shd_trian: 24.0000000000 time: 0.6703s\n",
            "Epoch: 0150 D_loss: -1.3655294355 G_loss: -0.2652071129 Pen_loss: 0.7000965888 mse_train: 5.9682801365 shd_trian: 24.0000000000 time: 0.6449s\n",
            "Epoch: 0151 D_loss: -1.4956053750 G_loss: 0.3320411976 Pen_loss: 0.7353851659 mse_train: 5.0609599804 shd_trian: 24.0000000000 time: 0.6357s\n",
            "Epoch: 0152 D_loss: -1.6982012257 G_loss: 1.1190353349 Pen_loss: 0.7788514209 mse_train: 4.6476755583 shd_trian: 23.8571428571 time: 0.6533s\n",
            "Epoch: 0153 D_loss: -1.7811080327 G_loss: -0.7692414801 Pen_loss: 0.8280192481 mse_train: 5.8467072833 shd_trian: 25.4285714286 time: 0.6574s\n",
            "Epoch: 0154 D_loss: -1.5673308143 G_loss: 4.3682625731 Pen_loss: 0.8204010666 mse_train: 6.0282627999 shd_trian: 25.4285714286 time: 0.6638s\n",
            "Epoch: 0155 D_loss: -1.8491093511 G_loss: -0.0934659127 Pen_loss: 0.8129753203 mse_train: 4.1285918567 shd_trian: 25.0000000000 time: 0.6743s\n",
            "Epoch: 0156 D_loss: -1.4478414482 G_loss: -0.0242196590 Pen_loss: 0.5825687824 mse_train: 4.7312860392 shd_trian: 25.2857142857 time: 0.9313s\n",
            "Epoch: 0157 D_loss: -1.0340485165 G_loss: 1.0142985233 Pen_loss: 0.6803851127 mse_train: 10.5525168773 shd_trian: 26.2857142857 time: 0.6583s\n",
            "Epoch: 0158 D_loss: -4.7293564446 G_loss: 15.6602827729 Pen_loss: 2.0232423189 mse_train: 9.4275055826 shd_trian: 26.7142857143 time: 0.8006s\n",
            "Epoch: 0159 D_loss: -1.7982524244 G_loss: -2.0441334665 Pen_loss: 0.5482295740 mse_train: 4.6196701703 shd_trian: 24.0000000000 time: 1.0023s\n",
            "Epoch: 0160 D_loss: -1.7014416143 G_loss: 0.7698517080 Pen_loss: 0.6842767809 mse_train: 4.9389258630 shd_trian: 22.5714285714 time: 0.7782s\n",
            "Epoch: 0161 D_loss: -1.5609898027 G_loss: -2.1010232054 Pen_loss: 0.6316602934 mse_train: 5.5683259474 shd_trian: 21.8571428571 time: 0.6485s\n",
            "Epoch: 0162 D_loss: -1.1199690975 G_loss: 2.8252988444 Pen_loss: 0.5846742749 mse_train: 4.5533055920 shd_trian: 21.0000000000 time: 0.6521s\n",
            "Epoch: 0163 D_loss: -1.2892307595 G_loss: 0.3204562571 Pen_loss: 0.5885896015 mse_train: 4.2575461421 shd_trian: 21.0000000000 time: 0.6444s\n",
            "Epoch: 0164 D_loss: -1.3876947906 G_loss: 0.1678624152 Pen_loss: 0.6372966388 mse_train: 4.3241959488 shd_trian: 22.1428571429 time: 0.6425s\n",
            "Epoch: 0165 D_loss: -1.3853794906 G_loss: 0.4650798304 Pen_loss: 0.6869455037 mse_train: 4.6773961402 shd_trian: 23.0000000000 time: 0.6642s\n",
            "Epoch: 0166 D_loss: -1.2167947274 G_loss: 6.6959355470 Pen_loss: 0.6787135682 mse_train: 4.6885814598 shd_trian: 22.8571428571 time: 0.6506s\n",
            "Epoch: 0167 D_loss: -1.5489668226 G_loss: -2.4508228570 Pen_loss: 0.6083341932 mse_train: 4.1258299980 shd_trian: 21.2857142857 time: 0.6529s\n",
            "Epoch: 0168 D_loss: -1.0557202740 G_loss: 1.8392475360 Pen_loss: 0.6436894338 mse_train: 4.3605588106 shd_trian: 21.0000000000 time: 0.6937s\n",
            "Epoch: 0169 D_loss: -1.4601260427 G_loss: -0.4941733640 Pen_loss: 0.6248160776 mse_train: 3.9970692358 shd_trian: 20.8571428571 time: 0.6526s\n",
            "Epoch: 0170 D_loss: -2.3300362704 G_loss: 1.1913152908 Pen_loss: 1.2700208159 mse_train: 4.1032372906 shd_trian: 20.1428571429 time: 0.6626s\n",
            "Epoch: 0171 D_loss: -1.4729313075 G_loss: 1.1392953983 Pen_loss: 0.8013224538 mse_train: 4.8119085992 shd_trian: 21.7142857143 time: 0.9714s\n",
            "Epoch: 0172 D_loss: -1.5836817287 G_loss: 1.5441080167 Pen_loss: 0.7221402742 mse_train: 4.5028131947 shd_trian: 21.2857142857 time: 0.7367s\n",
            "Epoch: 0173 D_loss: -1.9507897531 G_loss: 1.4334249599 Pen_loss: 0.9108665459 mse_train: 4.8144371157 shd_trian: 21.0000000000 time: 0.6584s\n",
            "Epoch: 0174 D_loss: -1.2617669084 G_loss: 1.8707398418 Pen_loss: 0.8350683954 mse_train: 5.2559314358 shd_trian: 21.0000000000 time: 0.6654s\n",
            "Epoch: 0175 D_loss: -1.9669675828 G_loss: 0.4445008934 Pen_loss: 0.6876534418 mse_train: 5.8011547545 shd_trian: 21.4285714286 time: 0.6416s\n",
            "Epoch: 0176 D_loss: -1.6823071933 G_loss: -1.5187809558 Pen_loss: 0.6979164992 mse_train: 4.9108443428 shd_trian: 22.0000000000 time: 0.6563s\n",
            "Epoch: 0177 D_loss: -1.1212721073 G_loss: -1.8062474689 Pen_loss: 0.5457157892 mse_train: 4.2657401328 shd_trian: 22.0000000000 time: 0.7156s\n",
            "Epoch: 0178 D_loss: -1.4445232161 G_loss: 1.1321066075 Pen_loss: 0.6944480965 mse_train: 4.3092913477 shd_trian: 22.0000000000 time: 0.7333s\n",
            "Epoch: 0179 D_loss: -1.9170985236 G_loss: 0.9133309427 Pen_loss: 0.7059683996 mse_train: 4.8199159730 shd_trian: 22.0000000000 time: 0.6828s\n",
            "Epoch: 0180 D_loss: -1.2467034619 G_loss: 0.1567089176 Pen_loss: 0.9964878907 mse_train: 4.4411391806 shd_trian: 22.0000000000 time: 0.6799s\n",
            "Epoch: 0181 D_loss: -1.7158789998 G_loss: -0.6805480777 Pen_loss: 0.7177879396 mse_train: 4.2660002687 shd_trian: 22.0000000000 time: 0.6527s\n",
            "Epoch: 0182 D_loss: -1.4771246938 G_loss: 1.4141073946 Pen_loss: 0.7241777994 mse_train: 4.8986304007 shd_trian: 21.7142857143 time: 0.6787s\n",
            "Epoch: 0183 D_loss: -1.2796797212 G_loss: 1.1722653302 Pen_loss: 0.6452585114 mse_train: 4.2182118645 shd_trian: 21.0000000000 time: 0.7766s\n",
            "Epoch: 0184 D_loss: -1.1885451155 G_loss: 2.1065293195 Pen_loss: 0.5801570998 mse_train: 4.0709153400 shd_trian: 21.0000000000 time: 0.9956s\n",
            "Epoch: 0185 D_loss: -1.0809668003 G_loss: 1.2318432333 Pen_loss: 0.5994470277 mse_train: 4.1698997852 shd_trian: 21.0000000000 time: 0.9243s\n",
            "Epoch: 0186 D_loss: -1.3602652630 G_loss: 2.6118097637 Pen_loss: 0.8539592676 mse_train: 4.5392625460 shd_trian: 21.0000000000 time: 0.6773s\n",
            "Epoch: 0187 D_loss: -1.2257751262 G_loss: 5.1743416601 Pen_loss: 0.8224297157 mse_train: 3.8580958609 shd_trian: 21.0000000000 time: 0.6663s\n",
            "Epoch: 0188 D_loss: -1.1710786360 G_loss: -0.4292386664 Pen_loss: 0.4796701219 mse_train: 4.3146598785 shd_trian: 21.0000000000 time: 0.6520s\n",
            "Epoch: 0189 D_loss: -0.3804916922 G_loss: 6.6799213352 Pen_loss: 0.6933550241 mse_train: 13.3745280111 shd_trian: 21.7142857143 time: 0.6716s\n",
            "Epoch: 0190 D_loss: -1.1583486872 G_loss: 2.8676224084 Pen_loss: 0.6972626032 mse_train: 4.1396644159 shd_trian: 20.0000000000 time: 0.6631s\n",
            "Epoch: 0191 D_loss: -1.9425570192 G_loss: 6.1160856777 Pen_loss: 1.1383747267 mse_train: 5.2486136010 shd_trian: 20.1428571429 time: 0.9075s\n",
            "Epoch: 0192 D_loss: -1.7497200927 G_loss: 6.0243115884 Pen_loss: 0.6547018558 mse_train: 11.9544284610 shd_trian: 21.5714285714 time: 0.6993s\n",
            "Epoch: 0193 D_loss: -2.3214331778 G_loss: 0.0376424469 Pen_loss: 0.6297005174 mse_train: 3.3745024729 shd_trian: 21.0000000000 time: 0.6491s\n",
            "Epoch: 0194 D_loss: -2.5247427624 G_loss: -3.1951418878 Pen_loss: 0.6804301084 mse_train: 3.7930399784 shd_trian: 21.0000000000 time: 0.6696s\n",
            "Epoch: 0195 D_loss: -1.6024396680 G_loss: -2.1457031192 Pen_loss: 0.7138390159 mse_train: 3.6185899119 shd_trian: 21.0000000000 time: 0.6820s\n",
            "Epoch: 0196 D_loss: -2.1045959572 G_loss: -2.1746057859 Pen_loss: 0.6857321706 mse_train: 6.9790842277 shd_trian: 21.0000000000 time: 0.6438s\n",
            "Epoch: 0197 D_loss: -2.3893093825 G_loss: 2.8527253613 Pen_loss: 1.0013481239 mse_train: 14.0410055371 shd_trian: 21.8571428571 time: 0.6795s\n",
            "Epoch: 0198 D_loss: -2.9442212330 G_loss: 1.1560976698 Pen_loss: 1.0196376254 mse_train: 4.2089981017 shd_trian: 22.0000000000 time: 0.9831s\n",
            "Epoch: 0199 D_loss: -2.6333513700 G_loss: -2.8074446392 Pen_loss: 0.7454844818 mse_train: 3.4428859201 shd_trian: 21.2857142857 time: 0.9582s\n",
            "Epoch: 0200 D_loss: -1.9566445901 G_loss: -2.1156841996 Pen_loss: 0.7665130545 mse_train: 4.1341251474 shd_trian: 21.0000000000 time: 0.6801s\n",
            "Epoch: 0201 D_loss: -2.5896347146 G_loss: 0.5689682149 Pen_loss: 0.9879860734 mse_train: 5.5594346347 shd_trian: 21.1428571429 time: 0.7159s\n",
            "Epoch: 0202 D_loss: -2.2927768585 G_loss: 0.3086842271 Pen_loss: 0.8204685390 mse_train: 5.1722713116 shd_trian: 22.0000000000 time: 0.6546s\n",
            "Epoch: 0203 D_loss: -3.0127925151 G_loss: -0.6172447191 Pen_loss: 0.9698525988 mse_train: 3.8193085342 shd_trian: 22.0000000000 time: 0.6674s\n",
            "Epoch: 0204 D_loss: -2.6427113237 G_loss: -1.0838513724 Pen_loss: 0.7974202820 mse_train: 3.7036459450 shd_trian: 21.0000000000 time: 0.6853s\n",
            "Epoch: 0205 D_loss: -2.4207248852 G_loss: -0.6847177066 Pen_loss: 0.8737476150 mse_train: 3.9166886974 shd_trian: 21.0000000000 time: 0.6600s\n",
            "Epoch: 0206 D_loss: -2.8587969274 G_loss: -2.6339311766 Pen_loss: 1.0800818800 mse_train: 5.4710457366 shd_trian: 21.0000000000 time: 0.6728s\n",
            "Epoch: 0207 D_loss: -3.1414197979 G_loss: -2.3174641667 Pen_loss: 0.9202157277 mse_train: 5.7491764015 shd_trian: 20.7142857143 time: 0.6802s\n",
            "Epoch: 0208 D_loss: -2.6669452938 G_loss: -0.6056384346 Pen_loss: 0.9735084873 mse_train: 5.8733569421 shd_trian: 19.8571428571 time: 0.6513s\n",
            "Epoch: 0209 D_loss: -3.7804535854 G_loss: 6.4624963170 Pen_loss: 1.1410790157 mse_train: 13.7041934347 shd_trian: 19.8571428571 time: 0.6709s\n",
            "Epoch: 0210 D_loss: -2.5224788169 G_loss: 0.0626416602 Pen_loss: 0.8886554294 mse_train: 3.3169552481 shd_trian: 19.4285714286 time: 0.8517s\n",
            "Epoch: 0211 D_loss: -3.1051237853 G_loss: -1.7635871518 Pen_loss: 0.8101205893 mse_train: 3.5635562019 shd_trian: 21.0000000000 time: 0.7655s\n",
            "Epoch: 0212 D_loss: -3.2882646320 G_loss: -3.8297831619 Pen_loss: 1.0252380390 mse_train: 3.3559918352 shd_trian: 20.2857142857 time: 0.7420s\n",
            "Epoch: 0213 D_loss: -3.0468937046 G_loss: -1.3019644518 Pen_loss: 1.0673874882 mse_train: 6.5709438523 shd_trian: 21.0000000000 time: 0.6536s\n",
            "Epoch: 0214 D_loss: -3.4227414643 G_loss: -3.8106321377 Pen_loss: 0.9665494109 mse_train: 4.4646708223 shd_trian: 21.0000000000 time: 0.6580s\n",
            "Epoch: 0215 D_loss: -2.3211960129 G_loss: -0.1013328045 Pen_loss: 0.9053839312 mse_train: 11.3890495504 shd_trian: 21.0000000000 time: 0.6539s\n",
            "Epoch: 0216 D_loss: -2.8232073209 G_loss: 1.2525929845 Pen_loss: 0.9860116089 mse_train: 5.3632821845 shd_trian: 21.0000000000 time: 0.6600s\n",
            "Epoch: 0217 D_loss: -2.8689530431 G_loss: -0.1516564269 Pen_loss: 1.0133804718 mse_train: 11.1829555951 shd_trian: 20.1428571429 time: 0.6653s\n",
            "Epoch: 0218 D_loss: -2.6660859663 G_loss: 8.9701195773 Pen_loss: 1.4993535311 mse_train: 11.0646256621 shd_trian: 20.0000000000 time: 0.7213s\n",
            "Epoch: 0219 D_loss: -2.7580994086 G_loss: 3.1567383031 Pen_loss: 0.7761122856 mse_train: 4.5919004897 shd_trian: 20.0000000000 time: 0.6593s\n",
            "Epoch: 0220 D_loss: -2.8933729878 G_loss: 0.2239717961 Pen_loss: 1.0346966866 mse_train: 5.2397622025 shd_trian: 20.0000000000 time: 0.6440s\n",
            "Epoch: 0221 D_loss: -3.3224237940 G_loss: 2.7630965487 Pen_loss: 1.2104986976 mse_train: 4.8688825057 shd_trian: 19.8571428571 time: 0.6442s\n",
            "Epoch: 0222 D_loss: -3.0975412495 G_loss: -1.1220176042 Pen_loss: 1.0029894295 mse_train: 5.4773389021 shd_trian: 19.4285714286 time: 0.6361s\n",
            "Epoch: 0223 D_loss: -2.6113494361 G_loss: 0.0921123912 Pen_loss: 0.8400465296 mse_train: 4.7482307029 shd_trian: 20.0000000000 time: 0.8111s\n",
            "Epoch: 0224 D_loss: -3.1434690598 G_loss: -3.3405748690 Pen_loss: 0.9226874810 mse_train: 3.9265445368 shd_trian: 20.0000000000 time: 0.9732s\n",
            "Epoch: 0225 D_loss: -2.9321906971 G_loss: -3.1134136589 Pen_loss: 1.0567068604 mse_train: 3.7932558495 shd_trian: 20.2857142857 time: 0.7783s\n",
            "Epoch: 0226 D_loss: -3.1901048649 G_loss: -3.6543027272 Pen_loss: 0.9056967856 mse_train: 4.0218194855 shd_trian: 21.0000000000 time: 0.6589s\n",
            "Epoch: 0227 D_loss: -4.0948851848 G_loss: 0.2639078530 Pen_loss: 1.5425995679 mse_train: 3.9870500252 shd_trian: 21.0000000000 time: 0.6540s\n",
            "Epoch: 0228 D_loss: -3.7476415297 G_loss: 2.1064978420 Pen_loss: 1.0470255767 mse_train: 7.2658128733 shd_trian: 20.5714285714 time: 0.6624s\n",
            "Epoch: 0229 D_loss: -2.8698364035 G_loss: -3.4811395922 Pen_loss: 1.1206510046 mse_train: 5.4052589524 shd_trian: 20.2857142857 time: 0.6624s\n",
            "Epoch: 0230 D_loss: -2.5842550778 G_loss: -0.3308228471 Pen_loss: 0.8866225809 mse_train: 5.5346698239 shd_trian: 21.0000000000 time: 0.7756s\n",
            "Epoch: 0231 D_loss: -5.1349198181 G_loss: 7.0873205582 Pen_loss: 1.7852447548 mse_train: 5.2696487832 shd_trian: 21.1428571429 time: 0.6338s\n",
            "Epoch: 0232 D_loss: -3.1305816128 G_loss: -1.0372816464 Pen_loss: 0.9006185356 mse_train: 3.6744428314 shd_trian: 21.4285714286 time: 0.6525s\n",
            "Epoch: 0233 D_loss: -2.6930716822 G_loss: -1.2351752201 Pen_loss: 0.9147586026 mse_train: 3.7708106416 shd_trian: 20.7142857143 time: 0.6564s\n",
            "Epoch: 0234 D_loss: -3.3481944461 G_loss: -1.0870595246 Pen_loss: 0.9821606116 mse_train: 4.2395887425 shd_trian: 20.0000000000 time: 0.6460s\n",
            "Epoch: 0235 D_loss: -2.7475798651 G_loss: -2.1101127871 Pen_loss: 0.9085538567 mse_train: 4.2180912965 shd_trian: 20.0000000000 time: 0.6546s\n",
            "Epoch: 0236 D_loss: -2.5843257615 G_loss: -1.1164106548 Pen_loss: 0.9326805036 mse_train: 3.8393772874 shd_trian: 20.2857142857 time: 0.6565s\n",
            "Epoch: 0237 D_loss: -1.5311995326 G_loss: -1.0210423491 Pen_loss: 0.8050718956 mse_train: 4.2977878193 shd_trian: 21.0000000000 time: 0.7442s\n",
            "Epoch: 0238 D_loss: -1.2390977229 G_loss: 2.4191204308 Pen_loss: 0.7092642398 mse_train: 3.8699338236 shd_trian: 21.0000000000 time: 0.9530s\n",
            "Epoch: 0239 D_loss: -1.1673818218 G_loss: 2.0994943612 Pen_loss: 0.7642558380 mse_train: 6.3164366903 shd_trian: 21.0000000000 time: 0.8355s\n",
            "Epoch: 0240 D_loss: -1.8902709472 G_loss: 7.2687742931 Pen_loss: 0.9034079705 mse_train: 6.1828518201 shd_trian: 20.5714285714 time: 0.6846s\n",
            "Epoch: 0241 D_loss: -2.2114924793 G_loss: -1.9553821374 Pen_loss: 0.6847493152 mse_train: 3.3887704072 shd_trian: 19.0000000000 time: 0.6460s\n",
            "Epoch: 0242 D_loss: -1.9153416629 G_loss: -2.0047491502 Pen_loss: 0.7800639597 mse_train: 3.5214832388 shd_trian: 19.0000000000 time: 0.6581s\n",
            "Epoch: 0243 D_loss: -2.3241817862 G_loss: -1.5034774013 Pen_loss: 0.7726157838 mse_train: 3.7450586122 shd_trian: 19.2857142857 time: 0.6464s\n",
            "Epoch: 0244 D_loss: -3.1777770294 G_loss: -2.5294094409 Pen_loss: 0.9185499519 mse_train: 3.8172273605 shd_trian: 20.0000000000 time: 0.6494s\n",
            "Epoch: 0245 D_loss: -3.3911358304 G_loss: 2.2805452407 Pen_loss: 1.1275596490 mse_train: 4.1095030965 shd_trian: 20.0000000000 time: 0.6546s\n",
            "Epoch: 0246 D_loss: -2.5306189351 G_loss: 1.0539969897 Pen_loss: 0.8593535797 mse_train: 4.3042086740 shd_trian: 19.0000000000 time: 0.6571s\n",
            "Epoch: 0247 D_loss: -2.8276388749 G_loss: 0.2368064604 Pen_loss: 0.9559332899 mse_train: 6.9657885770 shd_trian: 19.1428571429 time: 1.0243s\n",
            "Epoch: 0248 D_loss: -2.7723894925 G_loss: 2.6373043402 Pen_loss: 1.0554929942 mse_train: 4.7647321593 shd_trian: 20.1428571429 time: 0.8172s\n",
            "Epoch: 0249 D_loss: -2.7322771705 G_loss: 5.2418642134 Pen_loss: 1.2036045828 mse_train: 4.1361633884 shd_trian: 20.0000000000 time: 0.6768s\n",
            "Epoch: 0250 D_loss: -2.8764518189 G_loss: -0.6986476392 Pen_loss: 0.9183844104 mse_train: 4.5306084276 shd_trian: 21.0000000000 time: 0.6610s\n",
            "Epoch: 0251 D_loss: -2.8780882777 G_loss: 0.5104252734 Pen_loss: 1.0195485667 mse_train: 3.9184480351 shd_trian: 21.2857142857 time: 0.6569s\n",
            "Epoch: 0252 D_loss: -3.6061235660 G_loss: 2.4250332032 Pen_loss: 1.2755732205 mse_train: 4.6010883140 shd_trian: 21.7142857143 time: 0.6662s\n",
            "Epoch: 0253 D_loss: -3.0832450531 G_loss: -0.2624052508 Pen_loss: 0.9646814762 mse_train: 4.9611163852 shd_trian: 21.8571428571 time: 0.6550s\n",
            "Epoch: 0254 D_loss: -2.9980000362 G_loss: -1.7439212268 Pen_loss: 0.9472757860 mse_train: 4.0540037624 shd_trian: 21.0000000000 time: 0.6548s\n",
            "Epoch: 0255 D_loss: -2.6554571700 G_loss: 1.9749528872 Pen_loss: 0.9863185408 mse_train: 4.0750550136 shd_trian: 20.5714285714 time: 0.7871s\n",
            "Epoch: 0256 D_loss: -3.3082371109 G_loss: -1.1555132540 Pen_loss: 0.9847436050 mse_train: 4.1054038939 shd_trian: 20.7142857143 time: 0.6509s\n",
            "Epoch: 0257 D_loss: -2.4477842676 G_loss: -0.3214685975 Pen_loss: 0.9792203238 mse_train: 3.8701855709 shd_trian: 21.0000000000 time: 0.6649s\n",
            "Epoch: 0258 D_loss: -3.1206288806 G_loss: -0.4375078603 Pen_loss: 0.9320175340 mse_train: 4.0092962329 shd_trian: 21.0000000000 time: 0.6794s\n",
            "Epoch: 0259 D_loss: -3.2664736134 G_loss: -0.7529056547 Pen_loss: 1.1604594794 mse_train: 7.4932083376 shd_trian: 20.2857142857 time: 0.6499s\n",
            "Epoch: 0260 D_loss: -4.4656772817 G_loss: 4.8236910007 Pen_loss: 2.3738814487 mse_train: 4.2233805032 shd_trian: 20.0000000000 time: 0.6986s\n",
            "Epoch: 0261 D_loss: -2.4946566866 G_loss: 3.5278504366 Pen_loss: 0.8778315616 mse_train: 6.9886280662 shd_trian: 20.0000000000 time: 0.6457s\n",
            "Epoch: 0262 D_loss: -1.7577765114 G_loss: 2.4954144460 Pen_loss: 0.8219998777 mse_train: 3.6895110384 shd_trian: 20.0000000000 time: 0.6669s\n",
            "Epoch: 0263 D_loss: -2.0326908225 G_loss: 2.4231955981 Pen_loss: 1.0658597559 mse_train: 5.6641209536 shd_trian: 20.0000000000 time: 0.9765s\n",
            "Epoch: 0264 D_loss: -2.5814271929 G_loss: 3.9342608778 Pen_loss: 0.9308459385 mse_train: 3.9902995099 shd_trian: 20.0000000000 time: 0.9210s\n",
            "Epoch: 0265 D_loss: -2.3594773599 G_loss: -0.9865581890 Pen_loss: 0.7366903448 mse_train: 4.3217113129 shd_trian: 20.0000000000 time: 0.6496s\n",
            "Epoch: 0266 D_loss: -2.9694522636 G_loss: 1.1726057740 Pen_loss: 1.2863557011 mse_train: 8.7500359564 shd_trian: 20.1428571429 time: 0.6589s\n",
            "Epoch: 0267 D_loss: -2.4059021368 G_loss: 6.7871665693 Pen_loss: 0.9265120643 mse_train: 3.7996960584 shd_trian: 21.0000000000 time: 0.6665s\n",
            "Epoch: 0268 D_loss: -3.3585865550 G_loss: 8.3296089139 Pen_loss: 1.1790957726 mse_train: 7.1755901996 shd_trian: 21.0000000000 time: 0.6588s\n",
            "Epoch: 0269 D_loss: -0.9082816858 G_loss: 4.3183114406 Pen_loss: 0.8428577007 mse_train: 4.4088434636 shd_trian: 21.2857142857 time: 0.6823s\n",
            "Epoch: 0270 D_loss: -0.7956668393 G_loss: 4.5051776096 Pen_loss: 0.4787010144 mse_train: 4.7978645594 shd_trian: 21.0000000000 time: 0.6736s\n",
            "Epoch: 0271 D_loss: -1.0665597277 G_loss: 4.0990351271 Pen_loss: 0.6060883916 mse_train: 4.9323310345 shd_trian: 20.5714285714 time: 0.6555s\n",
            "Epoch: 0272 D_loss: -1.6015186017 G_loss: -2.5643920587 Pen_loss: 0.5454288387 mse_train: 3.5823234758 shd_trian: 19.0000000000 time: 0.6617s\n",
            "Epoch: 0273 D_loss: -2.1146597075 G_loss: -1.8732489511 Pen_loss: 0.7415718726 mse_train: 3.1783530028 shd_trian: 19.0000000000 time: 0.6756s\n",
            "Epoch: 0274 D_loss: -2.9611839740 G_loss: -4.8179889652 Pen_loss: 0.8538447831 mse_train: 3.6631616668 shd_trian: 19.0000000000 time: 0.6589s\n",
            "Epoch: 0275 D_loss: -1.7525237221 G_loss: -0.8290506543 Pen_loss: 0.8010291888 mse_train: 4.3480163646 shd_trian: 19.8571428571 time: 0.6620s\n",
            "Epoch: 0276 D_loss: -1.3142505952 G_loss: 6.4955767280 Pen_loss: 0.7029750298 mse_train: 6.9764152711 shd_trian: 20.5714285714 time: 0.6624s\n",
            "Epoch: 0277 D_loss: -1.2823106348 G_loss: 0.1389855919 Pen_loss: 0.5781359707 mse_train: 3.8824382207 shd_trian: 20.7142857143 time: 1.0104s\n",
            "Epoch: 0278 D_loss: -0.9674888730 G_loss: -2.5784342545 Pen_loss: 0.5824006311 mse_train: 3.7118922779 shd_trian: 21.5714285714 time: 0.9459s\n",
            "Epoch: 0279 D_loss: -1.2004476224 G_loss: -1.4550517353 Pen_loss: 0.6121479870 mse_train: 4.4206386608 shd_trian: 22.0000000000 time: 0.6700s\n",
            "Epoch: 0280 D_loss: -1.4055676535 G_loss: 3.5579422220 Pen_loss: 0.7162364861 mse_train: 6.1576663649 shd_trian: 21.2857142857 time: 0.6633s\n",
            "Epoch: 0281 D_loss: -1.5935703103 G_loss: 1.6531232674 Pen_loss: 0.6123557581 mse_train: 4.6084424687 shd_trian: 21.5714285714 time: 0.6372s\n",
            "Epoch: 0282 D_loss: -1.4190977905 G_loss: -1.2063895187 Pen_loss: 0.7929030269 mse_train: 4.5826603641 shd_trian: 21.0000000000 time: 0.6344s\n",
            "Epoch: 0283 D_loss: -1.9574105864 G_loss: 1.8644375141 Pen_loss: 0.7012365320 mse_train: 4.8874611616 shd_trian: 21.0000000000 time: 0.6643s\n",
            "Epoch: 0284 D_loss: -1.8463528852 G_loss: -3.3584337058 Pen_loss: 0.6638616452 mse_train: 6.2032616090 shd_trian: 21.0000000000 time: 1.0680s\n",
            "Epoch: 0285 D_loss: -1.2080912958 G_loss: 1.4583032096 Pen_loss: 0.5898991460 mse_train: 6.1303826514 shd_trian: 21.0000000000 time: 0.6856s\n",
            "Epoch: 0286 D_loss: -0.8791599663 G_loss: 5.8046184037 Pen_loss: 1.0097913264 mse_train: 4.1589099687 shd_trian: 22.0000000000 time: 0.6719s\n",
            "Epoch: 0287 D_loss: -1.0610341320 G_loss: 5.2448081019 Pen_loss: 0.6070038448 mse_train: 6.9186984054 shd_trian: 22.0000000000 time: 0.6663s\n",
            "Epoch: 0288 D_loss: -1.8154163367 G_loss: 3.4671712384 Pen_loss: 0.7095347165 mse_train: 5.3950709248 shd_trian: 22.0000000000 time: 0.6731s\n",
            "Epoch: 0289 D_loss: -1.5271753438 G_loss: 0.3391618891 Pen_loss: 0.6198390176 mse_train: 4.6385863481 shd_trian: 22.0000000000 time: 0.6707s\n",
            "Epoch: 0290 D_loss: -5.5223887061 G_loss: 12.3934557561 Pen_loss: 1.6653360116 mse_train: 7.2077301710 shd_trian: 22.1428571429 time: 0.7023s\n",
            "Epoch: 0291 D_loss: -1.1036035135 G_loss: 1.6807228572 Pen_loss: 0.5950427036 mse_train: 4.2640871594 shd_trian: 22.0000000000 time: 0.6497s\n",
            "Epoch: 0292 D_loss: -2.5440915915 G_loss: -0.9628701196 Pen_loss: 1.0157577217 mse_train: 8.7909699486 shd_trian: 22.0000000000 time: 0.6529s\n",
            "Epoch: 0293 D_loss: -2.4202732602 G_loss: -1.6463360335 Pen_loss: 0.7569626314 mse_train: 4.3584885856 shd_trian: 22.0000000000 time: 0.6562s\n",
            "Epoch: 0294 D_loss: -3.4064222837 G_loss: 3.1060006009 Pen_loss: 1.2698970568 mse_train: 4.3481815201 shd_trian: 21.2857142857 time: 0.6616s\n",
            "Epoch: 0295 D_loss: -2.2208957351 G_loss: 2.8860577290 Pen_loss: 0.8231314687 mse_train: 4.5308217167 shd_trian: 20.1428571429 time: 0.6596s\n",
            "Epoch: 0296 D_loss: -1.9711756084 G_loss: 3.5932698016 Pen_loss: 0.8368933342 mse_train: 4.2699545302 shd_trian: 22.0000000000 time: 0.6783s\n",
            "Epoch: 0297 D_loss: -1.8759634034 G_loss: 7.7369823548 Pen_loss: 0.8234556965 mse_train: 5.0735731493 shd_trian: 22.4285714286 time: 0.6759s\n",
            "Epoch: 0298 D_loss: -1.1956146860 G_loss: 5.8518767841 Pen_loss: 0.7110143133 mse_train: 3.8032663634 shd_trian: 21.7142857143 time: 0.6600s\n",
            "Epoch: 0299 D_loss: -2.2783708724 G_loss: -0.4557626019 Pen_loss: 0.7162078484 mse_train: 4.4629148739 shd_trian: 21.0000000000 time: 0.6599s\n",
            "Epoch: 0300 D_loss: -1.7555999050 G_loss: 1.5748948259 Pen_loss: 0.7911171303 mse_train: 4.1575544773 shd_trian: 21.0000000000 time: 0.6681s\n",
            "Epoch: 0301 D_loss: -1.9241129916 G_loss: 0.4180166927 Pen_loss: 0.6744060969 mse_train: 3.6376587521 shd_trian: 21.0000000000 time: 0.6611s\n",
            "Epoch: 0302 D_loss: -1.2653624932 G_loss: 3.3929159842 Pen_loss: 0.5721844955 mse_train: 11.0585388693 shd_trian: 21.4285714286 time: 0.7787s\n",
            "Epoch: 0303 D_loss: -2.3274874547 G_loss: 1.1000471822 Pen_loss: 0.8026698031 mse_train: 4.0699161783 shd_trian: 22.0000000000 time: 1.0463s\n",
            "Epoch: 0304 D_loss: -1.7885667495 G_loss: 2.6347531982 Pen_loss: 0.6853887155 mse_train: 4.4298203089 shd_trian: 22.0000000000 time: 0.7734s\n",
            "Epoch: 0305 D_loss: -3.0834207131 G_loss: 5.9960576418 Pen_loss: 0.9839770263 mse_train: 14.0820575494 shd_trian: 21.4285714286 time: 0.6744s\n",
            "Epoch: 0306 D_loss: -2.4291622505 G_loss: -0.3514179471 Pen_loss: 0.7769944060 mse_train: 4.1451776232 shd_trian: 21.0000000000 time: 0.6609s\n",
            "Epoch: 0307 D_loss: -1.8958038763 G_loss: 0.9910935171 Pen_loss: 0.7052591201 mse_train: 3.6084553856 shd_trian: 21.0000000000 time: 0.6510s\n",
            "Epoch: 0308 D_loss: -1.7566409528 G_loss: 2.1855444572 Pen_loss: 0.9035419572 mse_train: 3.9163906559 shd_trian: 21.0000000000 time: 0.6764s\n",
            "Epoch: 0309 D_loss: -2.6352984156 G_loss: 0.2088000338 Pen_loss: 0.7057691143 mse_train: 4.5187347995 shd_trian: 21.0000000000 time: 0.6713s\n",
            "Epoch: 0310 D_loss: -2.5220752887 G_loss: -1.1188663727 Pen_loss: 0.7832323191 mse_train: 3.7849460328 shd_trian: 21.0000000000 time: 0.6560s\n",
            "Epoch: 0311 D_loss: -2.8764856702 G_loss: 0.6241509370 Pen_loss: 0.9130272488 mse_train: 3.5355265970 shd_trian: 21.0000000000 time: 0.6560s\n",
            "Epoch: 0312 D_loss: -2.9906914708 G_loss: -2.2437266883 Pen_loss: 0.8434646236 mse_train: 3.5790919166 shd_trian: 21.0000000000 time: 0.7054s\n",
            "Epoch: 0313 D_loss: -3.1185429323 G_loss: -0.7421430664 Pen_loss: 0.9394602579 mse_train: 3.7233182677 shd_trian: 21.0000000000 time: 0.6576s\n",
            "Epoch: 0314 D_loss: -2.4269927689 G_loss: 1.7106813839 Pen_loss: 0.8219786654 mse_train: 3.7821744181 shd_trian: 20.7142857143 time: 0.6736s\n",
            "Epoch: 0315 D_loss: -2.8020284656 G_loss: -1.1491789413 Pen_loss: 0.8240700528 mse_train: 5.8749044415 shd_trian: 20.0000000000 time: 0.7273s\n",
            "Epoch: 0316 D_loss: -1.4226536853 G_loss: 4.9232344550 Pen_loss: 2.0435552088 mse_train: 13.2692791483 shd_trian: 20.0000000000 time: 0.8192s\n",
            "Epoch: 0317 D_loss: -5.8914975182 G_loss: 18.9576617670 Pen_loss: 2.0985766294 mse_train: 14.5318834545 shd_trian: 19.7142857143 time: 0.9941s\n",
            "Epoch: 0318 D_loss: -1.5422133121 G_loss: 8.9347958636 Pen_loss: 0.6202226996 mse_train: 5.6965514688 shd_trian: 20.0000000000 time: 0.7628s\n",
            "Epoch: 0319 D_loss: -0.8066750813 G_loss: 3.7219456994 Pen_loss: 0.4770706971 mse_train: 3.5739775569 shd_trian: 20.0000000000 time: 0.6599s\n",
            "Epoch: 0320 D_loss: -1.9003580135 G_loss: 1.7556161729 Pen_loss: 0.5796947605 mse_train: 3.6456395732 shd_trian: 18.5714285714 time: 0.6616s\n",
            "Epoch: 0321 D_loss: -3.4657829437 G_loss: -4.0805276749 Pen_loss: 0.8787894566 mse_train: 4.0241654993 shd_trian: 18.5714285714 time: 0.9305s\n",
            "Epoch: 0322 D_loss: -2.2047655685 G_loss: 4.0547793134 Pen_loss: 0.8948950604 mse_train: 4.9095554621 shd_trian: 20.0000000000 time: 0.6931s\n",
            "Epoch: 0323 D_loss: -1.3074056095 G_loss: 1.6199676786 Pen_loss: 0.6756853998 mse_train: 4.2118753261 shd_trian: 20.0000000000 time: 0.6912s\n",
            "Epoch: 0324 D_loss: -2.0753760499 G_loss: -0.4201580433 Pen_loss: 0.6969818581 mse_train: 3.8430419965 shd_trian: 19.0000000000 time: 0.6827s\n",
            "Epoch: 0325 D_loss: -2.0854421013 G_loss: -0.7685209038 Pen_loss: 0.6489132099 mse_train: 4.4011777836 shd_trian: 19.0000000000 time: 0.6721s\n",
            "Epoch: 0326 D_loss: -2.1876422112 G_loss: -1.9561604507 Pen_loss: 0.7425253961 mse_train: 3.9344432090 shd_trian: 19.2857142857 time: 0.6840s\n",
            "Epoch: 0327 D_loss: -3.7583466029 G_loss: 5.6819504220 Pen_loss: 1.4427214252 mse_train: 7.2039676276 shd_trian: 20.0000000000 time: 0.6847s\n",
            "Epoch: 0328 D_loss: -2.6171373844 G_loss: 0.1477459873 Pen_loss: 0.7214356894 mse_train: 4.0507169843 shd_trian: 18.0000000000 time: 0.6718s\n",
            "Epoch: 0329 D_loss: -2.2896514180 G_loss: -2.0073401806 Pen_loss: 0.8351546379 mse_train: 4.0962514970 shd_trian: 18.0000000000 time: 0.6838s\n",
            "Epoch: 0330 D_loss: -1.7108778284 G_loss: 1.4865078044 Pen_loss: 0.7917961822 mse_train: 4.2370811887 shd_trian: 18.0000000000 time: 0.8931s\n",
            "Epoch: 0331 D_loss: -1.4711329181 G_loss: 1.2975426371 Pen_loss: 0.6402218112 mse_train: 4.7523063921 shd_trian: 18.0000000000 time: 0.6806s\n",
            "Epoch: 0332 D_loss: -2.6094083616 G_loss: 5.8405072250 Pen_loss: 0.9976670124 mse_train: 6.4568300879 shd_trian: 18.0000000000 time: 0.6754s\n",
            "Epoch: 0333 D_loss: -1.9060259645 G_loss: 1.6663392942 Pen_loss: 0.6217502397 mse_train: 4.1775592912 shd_trian: 18.0000000000 time: 0.6798s\n",
            "Epoch: 0334 D_loss: -1.1773236039 G_loss: 2.8585653867 Pen_loss: 0.8192228066 mse_train: 5.5664957265 shd_trian: 18.8571428571 time: 0.6626s\n",
            "Epoch: 0335 D_loss: -1.5511971975 G_loss: 7.1841800096 Pen_loss: 0.7449289895 mse_train: 5.6143700306 shd_trian: 20.0000000000 time: 0.6729s\n",
            "Epoch: 0336 D_loss: -1.5438979561 G_loss: 3.2024715103 Pen_loss: 0.5885147704 mse_train: 5.2720897177 shd_trian: 19.8571428571 time: 0.7030s\n",
            "Epoch: 0337 D_loss: -1.9284494103 G_loss: 0.3603596698 Pen_loss: 0.6577349202 mse_train: 3.5879878815 shd_trian: 21.0000000000 time: 0.6666s\n",
            "Epoch: 0338 D_loss: -1.5428174171 G_loss: -0.3731142288 Pen_loss: 0.6760441763 mse_train: 4.3256374194 shd_trian: 21.0000000000 time: 0.6632s\n",
            "Epoch: 0339 D_loss: -1.5452256725 G_loss: 0.4146150824 Pen_loss: 0.7124259572 mse_train: 3.7605164817 shd_trian: 21.0000000000 time: 0.8561s\n",
            "Epoch: 0340 D_loss: -2.0361951680 G_loss: 1.0648224441 Pen_loss: 0.6681735220 mse_train: 4.1065417929 shd_trian: 21.0000000000 time: 0.6587s\n",
            "Epoch: 0341 D_loss: -1.7436227804 G_loss: -0.7477137745 Pen_loss: 0.6416221782 mse_train: 4.0442178824 shd_trian: 21.0000000000 time: 0.6501s\n",
            "Epoch: 0342 D_loss: -1.5525701652 G_loss: 3.5457978672 Pen_loss: 0.7200203570 mse_train: 5.1674889669 shd_trian: 20.5714285714 time: 0.9449s\n",
            "Epoch: 0343 D_loss: -1.4103534162 G_loss: 2.2188562269 Pen_loss: 0.5993395897 mse_train: 4.6093265346 shd_trian: 20.2857142857 time: 0.9680s\n",
            "Epoch: 0344 D_loss: -2.1753423162 G_loss: -0.0268541920 Pen_loss: 0.7304498135 mse_train: 4.2320715872 shd_trian: 20.5714285714 time: 0.6768s\n",
            "Epoch: 0345 D_loss: -2.0870023687 G_loss: 2.2133597417 Pen_loss: 0.7812425963 mse_train: 4.8988227702 shd_trian: 21.0000000000 time: 0.6691s\n",
            "Epoch: 0346 D_loss: -1.2116844448 G_loss: 1.7779243973 Pen_loss: 0.7002581805 mse_train: 4.8828611527 shd_trian: 20.2857142857 time: 0.6687s\n",
            "Epoch: 0347 D_loss: -2.0399955815 G_loss: -0.7638896565 Pen_loss: 0.6531105016 mse_train: 4.0988109319 shd_trian: 20.0000000000 time: 0.6828s\n",
            "Epoch: 0348 D_loss: -2.1563969261 G_loss: 4.3078330309 Pen_loss: 1.1610817518 mse_train: 4.6192599328 shd_trian: 20.0000000000 time: 0.6985s\n",
            "Epoch: 0349 D_loss: -2.1500594171 G_loss: -0.0186520774 Pen_loss: 0.6390023123 mse_train: 3.8029336013 shd_trian: 19.7142857143 time: 0.6937s\n",
            "Epoch: 0350 D_loss: -2.2812856970 G_loss: 2.8880432819 Pen_loss: 0.8375048500 mse_train: 5.5515495226 shd_trian: 19.0000000000 time: 0.6837s\n",
            "Epoch: 0351 D_loss: -1.5060916502 G_loss: -0.3178890247 Pen_loss: 0.6699162862 mse_train: 3.8828950844 shd_trian: 19.7142857143 time: 0.6456s\n",
            "Epoch: 0352 D_loss: -1.7543219646 G_loss: 0.4761908758 Pen_loss: 0.6722946199 mse_train: 4.5443551830 shd_trian: 21.4285714286 time: 0.6741s\n",
            "Epoch: 0353 D_loss: -1.8539855308 G_loss: -0.1492196458 Pen_loss: 0.7816623696 mse_train: 4.4159110111 shd_trian: 22.0000000000 time: 0.6830s\n",
            "Epoch: 0354 D_loss: -2.1632705210 G_loss: -0.0328145976 Pen_loss: 0.7420879733 mse_train: 4.3947531543 shd_trian: 22.1428571429 time: 0.6899s\n",
            "Epoch: 0355 D_loss: -2.2000663859 G_loss: 0.8835972309 Pen_loss: 1.0876883078 mse_train: 5.5458848047 shd_trian: 23.0000000000 time: 0.6717s\n",
            "Epoch: 0356 D_loss: -1.7720795045 G_loss: 2.0780770344 Pen_loss: 0.6412860540 mse_train: 6.1134055617 shd_trian: 23.0000000000 time: 0.9834s\n",
            "Epoch: 0357 D_loss: -1.9379564774 G_loss: 1.8422335190 Pen_loss: 0.7188348185 mse_train: 4.4469205107 shd_trian: 23.0000000000 time: 0.9485s\n",
            "Epoch: 0358 D_loss: -2.1642256733 G_loss: -0.9349323706 Pen_loss: 0.7269610601 mse_train: 3.7931232249 shd_trian: 23.0000000000 time: 0.6911s\n",
            "Epoch: 0359 D_loss: -2.1530510919 G_loss: -2.5020065575 Pen_loss: 0.7826203635 mse_train: 3.8154530226 shd_trian: 21.1428571429 time: 0.6620s\n",
            "Epoch: 0360 D_loss: -2.0839791061 G_loss: -3.4515155316 Pen_loss: 0.8017865931 mse_train: 4.2746893900 shd_trian: 21.0000000000 time: 0.6959s\n",
            "Epoch: 0361 D_loss: -1.8450675481 G_loss: -0.0415492029 Pen_loss: 0.7730926739 mse_train: 4.0681617438 shd_trian: 21.0000000000 time: 0.6559s\n",
            "Epoch: 0362 D_loss: -2.6882139387 G_loss: -0.4305231219 Pen_loss: 0.8656112031 mse_train: 4.1875391319 shd_trian: 21.0000000000 time: 0.6992s\n",
            "Epoch: 0363 D_loss: -1.9934894990 G_loss: -1.2190618423 Pen_loss: 0.7899557973 mse_train: 3.7883372429 shd_trian: 21.0000000000 time: 0.6718s\n",
            "Epoch: 0364 D_loss: -1.9668268448 G_loss: -2.1323838426 Pen_loss: 0.7980559457 mse_train: 4.3296210334 shd_trian: 21.0000000000 time: 0.6673s\n",
            "Epoch: 0365 D_loss: -1.9382072019 G_loss: -1.6141483540 Pen_loss: 0.7217079970 mse_train: 5.4566060642 shd_trian: 21.1428571429 time: 0.6732s\n",
            "Epoch: 0366 D_loss: -1.9803916173 G_loss: -0.2015462460 Pen_loss: 0.7237971014 mse_train: 4.5414280070 shd_trian: 21.7142857143 time: 0.7011s\n",
            "Epoch: 0367 D_loss: -1.5456715143 G_loss: -1.2338367289 Pen_loss: 0.7367067537 mse_train: 4.1586731087 shd_trian: 20.1428571429 time: 0.6682s\n",
            "Epoch: 0368 D_loss: -1.3512990225 G_loss: 0.5848406721 Pen_loss: 0.6442236962 mse_train: 4.6755408960 shd_trian: 20.1428571429 time: 0.6742s\n",
            "Epoch: 0369 D_loss: -1.3152472646 G_loss: 0.4033402617 Pen_loss: 0.6912005829 mse_train: 6.3676416401 shd_trian: 21.4285714286 time: 0.6933s\n",
            "Epoch: 0370 D_loss: -1.0520675165 G_loss: 2.5893897752 Pen_loss: 0.6018180129 mse_train: 6.5750074414 shd_trian: 22.0000000000 time: 1.0503s\n",
            "Epoch: 0371 D_loss: -1.2306372838 G_loss: -0.7270966355 Pen_loss: 0.6556402773 mse_train: 4.6491825809 shd_trian: 21.4285714286 time: 0.6537s\n",
            "Epoch: 0372 D_loss: -1.9719874103 G_loss: 5.1874379358 Pen_loss: 0.7388347786 mse_train: 5.1945391698 shd_trian: 20.8571428571 time: 0.6753s\n",
            "Epoch: 0373 D_loss: -1.0565374777 G_loss: 1.1194682349 Pen_loss: 0.6288992721 mse_train: 3.9211357033 shd_trian: 20.2857142857 time: 0.6712s\n",
            "Epoch: 0374 D_loss: -1.2431178965 G_loss: -3.0528924476 Pen_loss: 0.5888559319 mse_train: 4.9406082337 shd_trian: 21.0000000000 time: 0.6671s\n",
            "Epoch: 0375 D_loss: -1.5527631253 G_loss: 0.4817976438 Pen_loss: 0.6271535913 mse_train: 5.3655502895 shd_trian: 20.0000000000 time: 0.9987s\n",
            "Epoch: 0376 D_loss: -1.1169897170 G_loss: 1.6849765591 Pen_loss: 0.6618983122 mse_train: 3.9182641973 shd_trian: 20.0000000000 time: 0.6906s\n",
            "Epoch: 0377 D_loss: -1.4253587850 G_loss: 1.5174776685 Pen_loss: 0.7252320018 mse_train: 4.8944214710 shd_trian: 20.0000000000 time: 0.6924s\n",
            "Epoch: 0378 D_loss: -1.2629790741 G_loss: 0.1391028250 Pen_loss: 0.6785321004 mse_train: 5.7933649792 shd_trian: 20.2857142857 time: 0.6777s\n",
            "Epoch: 0379 D_loss: -1.4870087950 G_loss: -0.5156630706 Pen_loss: 0.6766572614 mse_train: 4.8766518562 shd_trian: 21.0000000000 time: 0.7256s\n",
            "Epoch: 0380 D_loss: -1.5666737348 G_loss: 2.9828556720 Pen_loss: 0.7260630498 mse_train: 5.0881644548 shd_trian: 21.4285714286 time: 0.7496s\n",
            "Epoch: 0381 D_loss: -1.1229675278 G_loss: 1.1666246915 Pen_loss: 0.5542250665 mse_train: 5.0293817508 shd_trian: 22.0000000000 time: 1.0045s\n",
            "Epoch: 0382 D_loss: -1.3900865471 G_loss: 1.6559645912 Pen_loss: 0.6564355690 mse_train: 4.1465348699 shd_trian: 22.0000000000 time: 0.9416s\n",
            "Epoch: 0383 D_loss: -1.1060626629 G_loss: 0.6635532548 Pen_loss: 0.5201427396 mse_train: 5.4015581736 shd_trian: 22.0000000000 time: 0.6518s\n",
            "Epoch: 0384 D_loss: -1.4445136243 G_loss: 0.1417526818 Pen_loss: 0.6265650079 mse_train: 5.0107410318 shd_trian: 22.0000000000 time: 0.6592s\n",
            "Epoch: 0385 D_loss: -1.9425261939 G_loss: 3.3155361895 Pen_loss: 0.8370596142 mse_train: 5.2092644437 shd_trian: 22.0000000000 time: 0.6747s\n",
            "Epoch: 0386 D_loss: -2.0198056144 G_loss: -0.1575056362 Pen_loss: 0.6141971717 mse_train: 4.0913479986 shd_trian: 21.5714285714 time: 0.6705s\n",
            "Epoch: 0387 D_loss: -2.0529560679 G_loss: 0.0932626101 Pen_loss: 0.7316071407 mse_train: 4.6124262554 shd_trian: 22.2857142857 time: 0.6732s\n",
            "Epoch: 0388 D_loss: -1.3956375813 G_loss: 1.6811727956 Pen_loss: 0.6873716935 mse_train: 4.8652352882 shd_trian: 22.4285714286 time: 0.6758s\n",
            "Epoch: 0389 D_loss: -1.5572746935 G_loss: -0.2604951574 Pen_loss: 0.6171652711 mse_train: 3.8964048549 shd_trian: 22.0000000000 time: 0.6606s\n",
            "Epoch: 0390 D_loss: -1.9229133375 G_loss: 5.9045223065 Pen_loss: 0.8214908233 mse_train: 5.2759024877 shd_trian: 22.0000000000 time: 0.6751s\n",
            "Epoch: 0391 D_loss: -1.3766989202 G_loss: -1.1036213791 Pen_loss: 0.6276712833 mse_train: 3.9420929044 shd_trian: 22.8571428571 time: 0.6734s\n",
            "Epoch: 0392 D_loss: -2.3089926895 G_loss: -1.8213813178 Pen_loss: 0.8522485953 mse_train: 3.8027578725 shd_trian: 23.0000000000 time: 0.6674s\n",
            "Epoch: 0393 D_loss: -2.4159441384 G_loss: 0.0319390666 Pen_loss: 0.8279376262 mse_train: 4.0442423646 shd_trian: 22.2857142857 time: 0.8184s\n",
            "Epoch: 0394 D_loss: -1.7421916854 G_loss: 0.6236197593 Pen_loss: 0.7195744141 mse_train: 4.4380833773 shd_trian: 22.0000000000 time: 0.6772s\n",
            "Epoch: 0395 D_loss: -2.0202190450 G_loss: -0.3330928975 Pen_loss: 0.7512199345 mse_train: 4.0914579639 shd_trian: 22.4285714286 time: 1.0090s\n",
            "Epoch: 0396 D_loss: -1.7239568403 G_loss: -0.9227616171 Pen_loss: 0.8539653983 mse_train: 4.9530990789 shd_trian: 23.8571428571 time: 0.9184s\n",
            "Epoch: 0397 D_loss: -2.1869177328 G_loss: -0.8506826148 Pen_loss: 0.6414375085 mse_train: 4.7925980413 shd_trian: 23.1428571429 time: 0.6902s\n",
            "Epoch: 0398 D_loss: -1.8196670999 G_loss: 1.0042495730 Pen_loss: 0.7608178086 mse_train: 4.3676415918 shd_trian: 21.4285714286 time: 0.6696s\n",
            "Epoch: 0399 D_loss: -2.1002518530 G_loss: -1.0857150820 Pen_loss: 0.7621962543 mse_train: 4.2602728813 shd_trian: 21.0000000000 time: 0.6672s\n",
            "Epoch: 0400 D_loss: -0.7585911219 G_loss: 0.2720264739 Pen_loss: 0.6378296419 mse_train: 4.6907055690 shd_trian: 21.0000000000 time: 0.6653s\n",
            "Epoch: 0401 D_loss: -1.4970442607 G_loss: 2.8195755268 Pen_loss: 0.5730856411 mse_train: 3.6561430441 shd_trian: 21.0000000000 time: 0.6575s\n",
            "Epoch: 0402 D_loss: -0.8078215717 G_loss: 7.8408761108 Pen_loss: 1.0541107941 mse_train: 3.7686279834 shd_trian: 21.0000000000 time: 0.6789s\n",
            "Epoch: 0403 D_loss: -1.5842372666 G_loss: 5.9881425992 Pen_loss: 0.7336334219 mse_train: 5.1356178942 shd_trian: 21.0000000000 time: 0.6650s\n",
            "Epoch: 0404 D_loss: -1.3586353864 G_loss: -3.3675069346 Pen_loss: 0.5761447188 mse_train: 3.7626010664 shd_trian: 21.1428571429 time: 0.6788s\n",
            "Epoch: 0405 D_loss: -2.0049646213 G_loss: 0.5217187892 Pen_loss: 0.8097308063 mse_train: 5.0282190541 shd_trian: 21.0000000000 time: 0.6730s\n",
            "Epoch: 0406 D_loss: -1.6806872486 G_loss: -0.9946451873 Pen_loss: 0.6324450040 mse_train: 4.1768360362 shd_trian: 21.4285714286 time: 0.6675s\n",
            "Epoch: 0407 D_loss: -1.2007069866 G_loss: 1.4600578935 Pen_loss: 0.6434259392 mse_train: 4.6131413957 shd_trian: 22.0000000000 time: 0.6757s\n",
            "Epoch: 0408 D_loss: -1.7873442863 G_loss: -2.4796788691 Pen_loss: 0.6342651989 mse_train: 4.2146709636 shd_trian: 22.0000000000 time: 0.7486s\n",
            "Epoch: 0409 D_loss: -1.4773782801 G_loss: 0.2909692720 Pen_loss: 0.7013937081 mse_train: 3.8589861916 shd_trian: 22.0000000000 time: 1.0008s\n",
            "Epoch: 0410 D_loss: -2.0915544262 G_loss: -2.1451803315 Pen_loss: 0.6053264758 mse_train: 4.0332557482 shd_trian: 22.0000000000 time: 0.8565s\n",
            "Epoch: 0411 D_loss: -1.6451676961 G_loss: -1.7339448987 Pen_loss: 0.6782495360 mse_train: 4.6479043469 shd_trian: 22.0000000000 time: 0.9469s\n",
            "Epoch: 0412 D_loss: -1.8294067523 G_loss: -1.4627819812 Pen_loss: 0.7057377559 mse_train: 4.2738560079 shd_trian: 22.0000000000 time: 0.6988s\n",
            "Epoch: 0413 D_loss: -1.7426712392 G_loss: -2.5387777866 Pen_loss: 0.6464344937 mse_train: 4.3928221814 shd_trian: 22.0000000000 time: 0.7035s\n",
            "Epoch: 0414 D_loss: -1.5521496558 G_loss: -0.0931410062 Pen_loss: 0.5901517733 mse_train: 4.0904842437 shd_trian: 22.4285714286 time: 0.6830s\n",
            "Epoch: 0415 D_loss: -2.2695128132 G_loss: 0.1832016450 Pen_loss: 0.7269516187 mse_train: 3.9009365668 shd_trian: 23.0000000000 time: 0.6850s\n",
            "Epoch: 0416 D_loss: -1.9741478897 G_loss: -1.1089114984 Pen_loss: 0.8294841649 mse_train: 3.7647541135 shd_trian: 23.0000000000 time: 0.7048s\n",
            "Epoch: 0417 D_loss: -2.4107756463 G_loss: -1.7165495881 Pen_loss: 0.7797648270 mse_train: 3.8246639267 shd_trian: 23.0000000000 time: 0.6862s\n",
            "Epoch: 0418 D_loss: -1.3784659657 G_loss: -3.0148602699 Pen_loss: 0.6973619335 mse_train: 4.2386030945 shd_trian: 23.0000000000 time: 0.6968s\n",
            "Epoch: 0419 D_loss: -1.3301717884 G_loss: 1.1723004594 Pen_loss: 0.6780281820 mse_train: 4.0792355297 shd_trian: 23.0000000000 time: 0.6961s\n",
            "Epoch: 0420 D_loss: -1.5512315957 G_loss: -1.7892495564 Pen_loss: 0.7159165417 mse_train: 4.2281051824 shd_trian: 22.5714285714 time: 0.6858s\n",
            "Epoch: 0421 D_loss: -1.5957632903 G_loss: -1.9187617428 Pen_loss: 0.6262504623 mse_train: 3.9172735701 shd_trian: 22.0000000000 time: 0.9207s\n",
            "Epoch: 0422 D_loss: -1.5233481088 G_loss: -2.0819205635 Pen_loss: 0.6909016862 mse_train: 7.4151894110 shd_trian: 22.0000000000 time: 0.6809s\n",
            "Epoch: 0423 D_loss: -1.7610218964 G_loss: 19.5695699782 Pen_loss: 0.8694001923 mse_train: 23.3408451977 shd_trian: 23.0000000000 time: 0.6779s\n",
            "Epoch: 0424 D_loss: -2.2109150154 G_loss: 1.3199345220 Pen_loss: 0.6830346146 mse_train: 3.6039843876 shd_trian: 22.0000000000 time: 0.7018s\n",
            "Epoch: 0425 D_loss: -1.8219350016 G_loss: -1.4592496673 Pen_loss: 0.6595325302 mse_train: 3.9748607273 shd_trian: 21.0000000000 time: 0.6751s\n",
            "Epoch: 0426 D_loss: -2.3339697382 G_loss: -2.7552729150 Pen_loss: 0.6783297652 mse_train: 3.9411932301 shd_trian: 21.8571428571 time: 0.6942s\n",
            "Epoch: 0427 D_loss: -2.1027813990 G_loss: -0.7274245219 Pen_loss: 0.7667593471 mse_train: 4.2670606520 shd_trian: 23.0000000000 time: 0.6969s\n",
            "Epoch: 0428 D_loss: -1.7179480942 G_loss: 0.4930166271 Pen_loss: 0.6864803639 mse_train: 3.8108926851 shd_trian: 24.0000000000 time: 0.6750s\n",
            "Epoch: 0429 D_loss: -2.1238234978 G_loss: 1.0565377708 Pen_loss: 0.7349031979 mse_train: 4.2145731207 shd_trian: 23.4285714286 time: 0.8751s\n",
            "Epoch: 0430 D_loss: -2.3895115357 G_loss: 0.2919253994 Pen_loss: 0.7767360234 mse_train: 4.2528377321 shd_trian: 23.0000000000 time: 0.6948s\n",
            "Epoch: 0431 D_loss: -2.1022261255 G_loss: -2.1561028132 Pen_loss: 0.6971483299 mse_train: 4.3424832347 shd_trian: 22.8571428571 time: 0.6597s\n",
            "Epoch: 0432 D_loss: -1.9362162378 G_loss: 0.2586977826 Pen_loss: 0.6772136965 mse_train: 4.9705065382 shd_trian: 22.4285714286 time: 0.6885s\n",
            "Epoch: 0433 D_loss: -2.0587761326 G_loss: 0.3824549129 Pen_loss: 0.7464162396 mse_train: 4.1117706216 shd_trian: 22.0000000000 time: 0.8224s\n",
            "Epoch: 0434 D_loss: -1.6493726653 G_loss: -2.1504713322 Pen_loss: 0.6315643170 mse_train: 4.0344477640 shd_trian: 22.0000000000 time: 0.9885s\n",
            "Epoch: 0435 D_loss: -2.0657260910 G_loss: -1.2070795262 Pen_loss: 0.6902153464 mse_train: 4.2777382990 shd_trian: 22.0000000000 time: 0.8400s\n",
            "Epoch: 0436 D_loss: -2.2850840304 G_loss: 0.1951390469 Pen_loss: 0.7581164785 mse_train: 4.3503576053 shd_trian: 21.7142857143 time: 0.6707s\n",
            "Epoch: 0437 D_loss: -2.0764110807 G_loss: 0.6386518473 Pen_loss: 0.7503579423 mse_train: 4.6956727497 shd_trian: 21.0000000000 time: 0.6751s\n",
            "Epoch: 0438 D_loss: -1.7926966048 G_loss: 0.1842451080 Pen_loss: 0.6791012268 mse_train: 4.5394982138 shd_trian: 21.0000000000 time: 0.6844s\n",
            "Epoch: 0439 D_loss: -1.1545259189 G_loss: -1.0732217827 Pen_loss: 0.6062487942 mse_train: 4.1251609371 shd_trian: 20.4285714286 time: 0.6981s\n",
            "Epoch: 0440 D_loss: -1.4046233180 G_loss: -2.1823016324 Pen_loss: 0.7007650582 mse_train: 3.7606842304 shd_trian: 20.0000000000 time: 0.7036s\n",
            "Epoch: 0441 D_loss: -2.0827391799 G_loss: -3.3332306384 Pen_loss: 0.6492606384 mse_train: 4.0721620467 shd_trian: 20.0000000000 time: 0.6595s\n",
            "Epoch: 0442 D_loss: -1.7356022606 G_loss: -2.2498331841 Pen_loss: 0.7749966033 mse_train: 4.3418712804 shd_trian: 20.0000000000 time: 0.6886s\n",
            "Epoch: 0443 D_loss: -2.0976098845 G_loss: -2.7954739976 Pen_loss: 0.6961827265 mse_train: 3.8561757938 shd_trian: 20.0000000000 time: 0.6786s\n",
            "Epoch: 0444 D_loss: -2.3206400519 G_loss: -1.7436551466 Pen_loss: 0.7937082973 mse_train: 4.4961288600 shd_trian: 20.0000000000 time: 0.6800s\n",
            "Epoch: 0445 D_loss: -1.9300662552 G_loss: 0.1525511496 Pen_loss: 0.7689728789 mse_train: 4.1853829081 shd_trian: 20.8571428571 time: 0.6662s\n",
            "Epoch: 0446 D_loss: -2.2381232237 G_loss: -1.1612855763 Pen_loss: 0.7336824811 mse_train: 4.1045256308 shd_trian: 20.2857142857 time: 0.7236s\n",
            "Epoch: 0447 D_loss: -1.5990449318 G_loss: -1.7258340321 Pen_loss: 0.6484856561 mse_train: 4.4573865508 shd_trian: 20.0000000000 time: 0.9272s\n",
            "Epoch: 0448 D_loss: -1.6491140545 G_loss: -0.3632429400 Pen_loss: 0.6806925627 mse_train: 5.1858542651 shd_trian: 20.0000000000 time: 1.0128s\n",
            "Epoch: 0449 D_loss: -1.5032922268 G_loss: -0.0819575611 Pen_loss: 0.6774928498 mse_train: 4.8189522537 shd_trian: 20.0000000000 time: 0.7113s\n",
            "Epoch: 0450 D_loss: -1.6400340316 G_loss: -0.2643014053 Pen_loss: 0.6985531828 mse_train: 4.7535344893 shd_trian: 20.0000000000 time: 0.6721s\n",
            "Epoch: 0451 D_loss: -1.9345564424 G_loss: -2.2152301736 Pen_loss: 0.7225042666 mse_train: 4.2613664416 shd_trian: 19.8571428571 time: 0.6662s\n",
            "Epoch: 0452 D_loss: -1.6482791968 G_loss: -2.2939088274 Pen_loss: 0.7522149445 mse_train: 4.2458325555 shd_trian: 19.0000000000 time: 0.6999s\n",
            "Epoch: 0453 D_loss: -2.1296512739 G_loss: 2.0540853144 Pen_loss: 0.7992388136 mse_train: 5.3217119080 shd_trian: 20.0000000000 time: 0.6766s\n",
            "Epoch: 0454 D_loss: -1.7094157806 G_loss: -0.5704531262 Pen_loss: 0.7372909229 mse_train: 4.4865376352 shd_trian: 20.0000000000 time: 0.6740s\n",
            "Epoch: 0455 D_loss: -1.7205577878 G_loss: 0.3178329089 Pen_loss: 0.6662057994 mse_train: 4.6575668667 shd_trian: 20.0000000000 time: 0.6729s\n",
            "Epoch: 0456 D_loss: -1.7275482598 G_loss: 0.0387994319 Pen_loss: 0.7051130327 mse_train: 4.3243001946 shd_trian: 20.5714285714 time: 0.6696s\n",
            "Epoch: 0457 D_loss: -1.5794732525 G_loss: 0.8810968868 Pen_loss: 0.7715072437 mse_train: 4.3008080802 shd_trian: 21.0000000000 time: 0.7060s\n",
            "Epoch: 0458 D_loss: -1.7929527809 G_loss: -0.4234045280 Pen_loss: 0.7197740902 mse_train: 4.3058446181 shd_trian: 21.0000000000 time: 0.7125s\n",
            "Epoch: 0459 D_loss: -1.8057826187 G_loss: -0.7691946704 Pen_loss: 0.7581312796 mse_train: 4.0277951434 shd_trian: 21.0000000000 time: 0.6995s\n",
            "Epoch: 0460 D_loss: -1.9700385560 G_loss: -1.6050891919 Pen_loss: 0.8335432667 mse_train: 4.2913530336 shd_trian: 21.0000000000 time: 0.6813s\n",
            "Epoch: 0461 D_loss: -1.9069838287 G_loss: 1.3362091827 Pen_loss: 0.7983922646 mse_train: 4.3432149842 shd_trian: 21.0000000000 time: 0.7278s\n",
            "Epoch: 0462 D_loss: -1.8875846400 G_loss: 0.1231614089 Pen_loss: 0.7146592746 mse_train: 4.1671047096 shd_trian: 21.2857142857 time: 0.7222s\n",
            "Epoch: 0463 D_loss: -1.0945231109 G_loss: -1.6553705113 Pen_loss: 0.5710309523 mse_train: 4.4346628034 shd_trian: 22.0000000000 time: 0.6918s\n",
            "Epoch: 0464 D_loss: -1.6566023951 G_loss: -2.2393925934 Pen_loss: 0.7339000775 mse_train: 4.4085562422 shd_trian: 21.2857142857 time: 0.6873s\n",
            "Epoch: 0465 D_loss: -2.0407149563 G_loss: -0.8861607857 Pen_loss: 0.7341781866 mse_train: 4.5200013206 shd_trian: 21.8571428571 time: 0.6898s\n",
            "Epoch: 0466 D_loss: -1.2868767413 G_loss: -0.7718078201 Pen_loss: 0.6868013552 mse_train: 4.5152732173 shd_trian: 21.7142857143 time: 0.6779s\n",
            "Epoch: 0467 D_loss: -1.6651197725 G_loss: -1.0861935181 Pen_loss: 0.6674489912 mse_train: 4.6139317464 shd_trian: 21.5714285714 time: 0.9589s\n",
            "Epoch: 0468 D_loss: -1.3289344006 G_loss: 3.4331752090 Pen_loss: 0.8100420828 mse_train: 4.4733777833 shd_trian: 22.7142857143 time: 0.6990s\n",
            "Epoch: 0469 D_loss: -1.6405445922 G_loss: -1.4327136934 Pen_loss: 0.6491060756 mse_train: 4.3028076707 shd_trian: 23.0000000000 time: 0.7153s\n",
            "Epoch: 0470 D_loss: -1.8048765479 G_loss: -0.0010258930 Pen_loss: 0.6951290411 mse_train: 4.2679883445 shd_trian: 22.7142857143 time: 0.7838s\n",
            "Epoch: 0471 D_loss: -2.0255451485 G_loss: -2.2799909706 Pen_loss: 0.7173236311 mse_train: 4.1344253820 shd_trian: 23.2857142857 time: 0.7614s\n",
            "Epoch: 0472 D_loss: -0.8435219671 G_loss: 1.5664604915 Pen_loss: 0.6586775905 mse_train: 4.1440140395 shd_trian: 23.0000000000 time: 1.0576s\n",
            "Epoch: 0473 D_loss: -1.3298253471 G_loss: 0.4900949128 Pen_loss: 0.6229885886 mse_train: 4.9484413881 shd_trian: 23.0000000000 time: 0.8386s\n",
            "Epoch: 0474 D_loss: -1.9864908396 G_loss: -0.3537850071 Pen_loss: 0.7130809726 mse_train: 4.2775353115 shd_trian: 22.8571428571 time: 0.6877s\n",
            "Epoch: 0475 D_loss: -0.9577173585 G_loss: 1.1057498148 Pen_loss: 0.6686306561 mse_train: 4.3150929772 shd_trian: 22.0000000000 time: 0.6952s\n",
            "Epoch: 0476 D_loss: -1.7165761402 G_loss: -2.5013489252 Pen_loss: 0.6820135001 mse_train: 4.5717888643 shd_trian: 22.0000000000 time: 0.7084s\n",
            "Epoch: 0477 D_loss: -2.4065480974 G_loss: 5.5227731128 Pen_loss: 1.0672871798 mse_train: 7.2956150868 shd_trian: 21.8571428571 time: 0.7236s\n",
            "Epoch: 0478 D_loss: -1.2034503853 G_loss: -0.8249990917 Pen_loss: 0.6164594405 mse_train: 3.7457671148 shd_trian: 22.0000000000 time: 0.6861s\n",
            "Epoch: 0479 D_loss: -1.6553494669 G_loss: -2.4802971839 Pen_loss: 0.6264782762 mse_train: 4.2827138284 shd_trian: 22.0000000000 time: 0.7114s\n",
            "Epoch: 0480 D_loss: -1.8422288178 G_loss: -2.1960442426 Pen_loss: 0.6683129378 mse_train: 4.2992837154 shd_trian: 22.0000000000 time: 0.7408s\n",
            "Epoch: 0481 D_loss: -1.6116495620 G_loss: -2.6614369083 Pen_loss: 0.7456817697 mse_train: 4.2692557983 shd_trian: 22.0000000000 time: 0.6932s\n",
            "Epoch: 0482 D_loss: -1.4566478170 G_loss: 1.1977992821 Pen_loss: 0.5801545507 mse_train: 4.3180802929 shd_trian: 22.0000000000 time: 0.7110s\n",
            "Epoch: 0483 D_loss: -1.5617959914 G_loss: 2.2638962348 Pen_loss: 0.8561398193 mse_train: 4.6928096409 shd_trian: 22.8571428571 time: 0.6686s\n",
            "Epoch: 0484 D_loss: -1.5776482173 G_loss: 0.1776746536 Pen_loss: 0.6139865260 mse_train: 4.8990214890 shd_trian: 22.0000000000 time: 0.6767s\n",
            "Epoch: 0485 D_loss: -1.2182861708 G_loss: -1.1862189069 Pen_loss: 0.6732823809 mse_train: 3.9655108928 shd_trian: 21.2857142857 time: 0.9936s\n",
            "Epoch: 0486 D_loss: -1.2469765543 G_loss: -2.2438956575 Pen_loss: 0.6950391189 mse_train: 4.7931621762 shd_trian: 21.0000000000 time: 0.9626s\n",
            "Epoch: 0487 D_loss: -1.7769710363 G_loss: -1.8235417305 Pen_loss: 0.7924236651 mse_train: 5.8325240130 shd_trian: 21.0000000000 time: 0.6951s\n",
            "Epoch: 0488 D_loss: -0.9098832646 G_loss: 0.3662823557 Pen_loss: 0.5953048196 mse_train: 5.6574872417 shd_trian: 21.0000000000 time: 0.6851s\n",
            "Epoch: 0489 D_loss: -0.7267286654 G_loss: 4.0454413747 Pen_loss: 0.5673638858 mse_train: 6.3140401947 shd_trian: 21.0000000000 time: 0.6857s\n",
            "Epoch: 0490 D_loss: -1.4832779219 G_loss: 2.0548655305 Pen_loss: 0.6347552259 mse_train: 3.7758950091 shd_trian: 21.8571428571 time: 0.6918s\n",
            "Epoch: 0491 D_loss: -1.4310699675 G_loss: -0.3891276035 Pen_loss: 0.6922584980 mse_train: 4.5007262935 shd_trian: 22.0000000000 time: 0.6783s\n",
            "Epoch: 0492 D_loss: -1.6347108382 G_loss: 1.2483587618 Pen_loss: 0.6434775625 mse_train: 4.8062927995 shd_trian: 23.0000000000 time: 0.6904s\n",
            "Epoch: 0493 D_loss: -1.6728350466 G_loss: -0.2557638725 Pen_loss: 0.6308977419 mse_train: 4.2143432497 shd_trian: 23.0000000000 time: 0.6910s\n",
            "Epoch: 0494 D_loss: -1.8433878453 G_loss: -0.2551837656 Pen_loss: 0.6618453408 mse_train: 4.3253201694 shd_trian: 23.0000000000 time: 0.6899s\n",
            "Epoch: 0495 D_loss: -1.1915472475 G_loss: 0.4592357928 Pen_loss: 0.6827485362 mse_train: 4.3366486776 shd_trian: 23.0000000000 time: 0.7048s\n",
            "Epoch: 0496 D_loss: -2.1421636211 G_loss: -1.8037595855 Pen_loss: 0.7410647666 mse_train: 4.2425006884 shd_trian: 23.0000000000 time: 0.7121s\n",
            "Epoch: 0497 D_loss: -0.6897595489 G_loss: -0.7980821961 Pen_loss: 0.5714253944 mse_train: 3.8529377688 shd_trian: 23.0000000000 time: 0.6996s\n",
            "Epoch: 0498 D_loss: -1.2055763999 G_loss: -1.7800061348 Pen_loss: 0.6332929546 mse_train: 4.0626658629 shd_trian: 23.0000000000 time: 0.8301s\n",
            "Epoch: 0499 D_loss: -1.4799689199 G_loss: 0.1580913492 Pen_loss: 0.6478053195 mse_train: 4.3685713535 shd_trian: 23.0000000000 time: 1.0096s\n",
            "Epoch: 0500 D_loss: -1.5962472508 G_loss: -2.1543201220 Pen_loss: 0.6316887703 mse_train: 4.0117253593 shd_trian: 23.2857142857 time: 0.8129s\n",
            "Epoch: 0501 D_loss: -1.5920071207 G_loss: -1.1119514859 Pen_loss: 0.7321609583 mse_train: 4.2024570075 shd_trian: 24.0000000000 time: 0.6819s\n",
            "Epoch: 0502 D_loss: -1.9202245398 G_loss: -1.4437551291 Pen_loss: 0.6651895627 mse_train: 4.2784175998 shd_trian: 24.0000000000 time: 0.6895s\n",
            "Epoch: 0503 D_loss: -1.9985411470 G_loss: -0.9347879056 Pen_loss: 0.7538574651 mse_train: 4.1552010290 shd_trian: 24.0000000000 time: 0.7114s\n",
            "Epoch: 0504 D_loss: -0.6965939139 G_loss: 0.9021501217 Pen_loss: 0.5666827396 mse_train: 4.1593156780 shd_trian: 24.0000000000 time: 0.9775s\n",
            "Epoch: 0505 D_loss: -1.4357929022 G_loss: -1.2532616198 Pen_loss: 0.6065088942 mse_train: 3.9821692532 shd_trian: 24.0000000000 time: 0.6940s\n",
            "Epoch: 0506 D_loss: -1.4805877658 G_loss: -0.4603034676 Pen_loss: 0.7380833336 mse_train: 4.1854627117 shd_trian: 23.5714285714 time: 0.7046s\n",
            "Epoch: 0507 D_loss: -1.1909076175 G_loss: 2.1368641600 Pen_loss: 0.5734199787 mse_train: 4.1581191108 shd_trian: 23.0000000000 time: 0.7583s\n",
            "Epoch: 0508 D_loss: -1.5979795023 G_loss: -0.7935831129 Pen_loss: 0.5767483039 mse_train: 4.0915671521 shd_trian: 23.0000000000 time: 0.7111s\n",
            "Epoch: 0509 D_loss: -1.6131950503 G_loss: 0.2564742903 Pen_loss: 0.6403398117 mse_train: 4.5409176409 shd_trian: 23.0000000000 time: 0.7046s\n",
            "Epoch: 0510 D_loss: -1.6654145083 G_loss: -0.4945407809 Pen_loss: 0.6725193199 mse_train: 4.0546470799 shd_trian: 22.2857142857 time: 0.7433s\n",
            "Epoch: 0511 D_loss: -1.1234150726 G_loss: -1.4759563712 Pen_loss: 0.6713443621 mse_train: 4.0840372885 shd_trian: 23.0000000000 time: 0.7573s\n",
            "Epoch: 0512 D_loss: -1.1043282459 G_loss: -0.2005306211 Pen_loss: 0.5946625746 mse_train: 4.5352253502 shd_trian: 22.2857142857 time: 0.7017s\n",
            "Epoch: 0513 D_loss: -1.3557327416 G_loss: -2.0911457123 Pen_loss: 0.6093991957 mse_train: 3.8287424019 shd_trian: 22.0000000000 time: 0.6907s\n",
            "Epoch: 0514 D_loss: -0.9950964367 G_loss: -2.4962048145 Pen_loss: 0.5227343669 mse_train: 4.6845775126 shd_trian: 22.0000000000 time: 0.7022s\n",
            "Epoch: 0515 D_loss: -1.5594836856 G_loss: 0.5033408991 Pen_loss: 0.6453600546 mse_train: 4.8234809949 shd_trian: 22.1428571429 time: 0.7129s\n",
            "Epoch: 0516 D_loss: -1.9287398342 G_loss: 0.3385486788 Pen_loss: 0.6628903651 mse_train: 4.2270532024 shd_trian: 23.0000000000 time: 0.6897s\n",
            "Epoch: 0517 D_loss: -1.4547739479 G_loss: -0.0861435702 Pen_loss: 0.6425947394 mse_train: 4.0557221497 shd_trian: 23.0000000000 time: 0.6997s\n",
            "Epoch: 0518 D_loss: -1.4294389953 G_loss: 0.0759659910 Pen_loss: 0.5796431691 mse_train: 4.1754834696 shd_trian: 23.0000000000 time: 0.7102s\n",
            "Epoch: 0519 D_loss: -1.2095078665 G_loss: -1.7353628208 Pen_loss: 0.6366916652 mse_train: 4.6069775124 shd_trian: 23.0000000000 time: 0.6975s\n",
            "Epoch: 0520 D_loss: -2.0787766415 G_loss: 0.8702073834 Pen_loss: 0.7461988089 mse_train: 4.7644839886 shd_trian: 23.2857142857 time: 0.7040s\n",
            "Epoch: 0521 D_loss: -1.2164063470 G_loss: -0.8084379328 Pen_loss: 0.6850532526 mse_train: 4.1492778372 shd_trian: 23.0000000000 time: 0.7064s\n",
            "Epoch: 0522 D_loss: -1.5320213902 G_loss: -1.2882929555 Pen_loss: 0.5926222157 mse_train: 4.0117923398 shd_trian: 23.0000000000 time: 0.7523s\n",
            "Epoch: 0523 D_loss: -1.5172627542 G_loss: -2.8380018246 Pen_loss: 0.6234712102 mse_train: 4.6804319579 shd_trian: 23.7142857143 time: 1.0206s\n",
            "Epoch: 0524 D_loss: -1.1302657537 G_loss: -0.2540843471 Pen_loss: 0.6033631338 mse_train: 4.0468031828 shd_trian: 23.0000000000 time: 0.9646s\n",
            "Epoch: 0525 D_loss: -1.4190728067 G_loss: -0.7879485503 Pen_loss: 0.5710460826 mse_train: 4.0403711665 shd_trian: 22.7142857143 time: 0.7044s\n",
            "Epoch: 0526 D_loss: -1.6274832024 G_loss: 1.7563661460 Pen_loss: 0.7794718792 mse_train: 6.2790192117 shd_trian: 23.0000000000 time: 0.6955s\n",
            "Epoch: 0527 D_loss: -1.3806782455 G_loss: -1.9245216595 Pen_loss: 0.6122246091 mse_train: 10.6649647098 shd_trian: 22.2857142857 time: 0.6762s\n",
            "Epoch: 0528 D_loss: -8.0945808877 G_loss: 16.5936207373 Pen_loss: 4.4444513861 mse_train: 8.1465889289 shd_trian: 21.8571428571 time: 0.7032s\n",
            "Epoch: 0529 D_loss: -2.3046437675 G_loss: 3.6389326768 Pen_loss: 0.6446332038 mse_train: 3.6307467554 shd_trian: 21.4285714286 time: 0.6917s\n",
            "Epoch: 0530 D_loss: -1.7534554007 G_loss: -1.2488459821 Pen_loss: 0.5529605915 mse_train: 3.6609120353 shd_trian: 22.8571428571 time: 0.6932s\n",
            "Epoch: 0531 D_loss: -1.7633418349 G_loss: -2.7846654568 Pen_loss: 0.7353972180 mse_train: 4.2473094255 shd_trian: 23.0000000000 time: 0.6830s\n",
            "Epoch: 0532 D_loss: -1.3738740475 G_loss: 0.1770521346 Pen_loss: 0.6439731733 mse_train: 4.6573678381 shd_trian: 23.0000000000 time: 0.6927s\n",
            "Epoch: 0533 D_loss: -1.6887397128 G_loss: 1.7577159625 Pen_loss: 0.6806255472 mse_train: 4.6264176194 shd_trian: 23.0000000000 time: 0.6899s\n",
            "Epoch: 0534 D_loss: -1.3592321272 G_loss: -0.4822302446 Pen_loss: 0.6202712305 mse_train: 4.3267769443 shd_trian: 23.4285714286 time: 0.7019s\n",
            "Epoch: 0535 D_loss: -1.6196088823 G_loss: -1.1292862333 Pen_loss: 0.6324174329 mse_train: 4.3628318963 shd_trian: 23.2857142857 time: 0.7040s\n",
            "Epoch: 0536 D_loss: -1.5893411808 G_loss: -3.0219704253 Pen_loss: 0.6838386068 mse_train: 4.3825494238 shd_trian: 22.8571428571 time: 0.8937s\n",
            "Epoch: 0537 D_loss: -1.4123920961 G_loss: 0.5521152466 Pen_loss: 0.6766342709 mse_train: 4.2816804079 shd_trian: 22.0000000000 time: 1.0117s\n",
            "Epoch: 0538 D_loss: -1.4845066053 G_loss: -1.4317642908 Pen_loss: 0.5607412682 mse_train: 4.2723359081 shd_trian: 22.0000000000 time: 0.7081s\n",
            "Epoch: 0539 D_loss: -1.5679315950 G_loss: -1.1159068131 Pen_loss: 0.6230536133 mse_train: 4.5632609554 shd_trian: 22.1428571429 time: 0.7049s\n",
            "Epoch: 0540 D_loss: -1.6651101365 G_loss: -0.2031991845 Pen_loss: 0.6814693179 mse_train: 4.4097177571 shd_trian: 23.0000000000 time: 0.7063s\n",
            "Epoch: 0541 D_loss: -1.4784069173 G_loss: -0.4377064534 Pen_loss: 0.6455387066 mse_train: 4.1759060672 shd_trian: 23.0000000000 time: 0.9650s\n",
            "Epoch: 0542 D_loss: -1.5253986999 G_loss: -0.3570047750 Pen_loss: 0.6826547013 mse_train: 4.4991442848 shd_trian: 23.0000000000 time: 0.7255s\n",
            "Epoch: 0543 D_loss: -0.9336312086 G_loss: -0.2303526775 Pen_loss: 0.5162864550 mse_train: 4.1585119134 shd_trian: 23.0000000000 time: 0.6952s\n",
            "Epoch: 0544 D_loss: -1.5198661861 G_loss: -0.7627876475 Pen_loss: 0.6477434486 mse_train: 4.4244206853 shd_trian: 23.0000000000 time: 0.7135s\n",
            "Epoch: 0545 D_loss: -0.8740009107 G_loss: -0.2706516244 Pen_loss: 0.5534647413 mse_train: 4.3188705211 shd_trian: 22.8571428571 time: 0.7048s\n",
            "Epoch: 0546 D_loss: -1.7571959541 G_loss: -0.0520630614 Pen_loss: 0.6194276766 mse_train: 4.2061298940 shd_trian: 23.0000000000 time: 0.6751s\n",
            "Epoch: 0547 D_loss: -1.5632098852 G_loss: -0.1817329638 Pen_loss: 0.7193619766 mse_train: 6.5922150052 shd_trian: 23.5714285714 time: 0.7032s\n",
            "Epoch: 0548 D_loss: -1.2482317519 G_loss: -0.0427564598 Pen_loss: 0.6161083867 mse_train: 4.3228233368 shd_trian: 24.0000000000 time: 0.7841s\n",
            "Epoch: 0549 D_loss: -1.5078331365 G_loss: -0.7612212522 Pen_loss: 0.6461066734 mse_train: 4.2242344313 shd_trian: 24.0000000000 time: 0.8276s\n",
            "Epoch: 0550 D_loss: -1.1856558159 G_loss: -1.6597117615 Pen_loss: 0.6031448131 mse_train: 4.2686713752 shd_trian: 24.0000000000 time: 1.0199s\n",
            "Epoch: 0551 D_loss: -1.4204782868 G_loss: 0.1517966099 Pen_loss: 0.6585313399 mse_train: 4.3950282756 shd_trian: 24.0000000000 time: 0.6865s\n",
            "Epoch: 0552 D_loss: -1.9390542584 G_loss: 0.8652716558 Pen_loss: 0.7216831446 mse_train: 4.3722573780 shd_trian: 24.0000000000 time: 0.6995s\n",
            "Epoch: 0553 D_loss: -1.2272940357 G_loss: -0.5539680262 Pen_loss: 0.6260731124 mse_train: 4.5564560882 shd_trian: 24.0000000000 time: 0.7150s\n",
            "Epoch: 0554 D_loss: -1.3580150373 G_loss: -1.8742697329 Pen_loss: 0.6419462657 mse_train: 4.2511849231 shd_trian: 24.0000000000 time: 0.6911s\n",
            "Epoch: 0555 D_loss: -1.4730680905 G_loss: 0.3340895444 Pen_loss: 0.6328802819 mse_train: 4.3562895466 shd_trian: 24.0000000000 time: 0.6806s\n",
            "Epoch: 0556 D_loss: -1.2845979300 G_loss: -1.7884991731 Pen_loss: 0.5948157524 mse_train: 4.2459021604 shd_trian: 24.0000000000 time: 0.6919s\n",
            "Epoch: 0557 D_loss: -1.1934789349 G_loss: -1.9195145531 Pen_loss: 0.5829834703 mse_train: 4.1595107079 shd_trian: 24.0000000000 time: 0.6912s\n",
            "Epoch: 0558 D_loss: -1.2342997487 G_loss: -1.0022137201 Pen_loss: 0.6816550973 mse_train: 4.0578549222 shd_trian: 24.0000000000 time: 0.6900s\n",
            "Epoch: 0559 D_loss: -1.3426315425 G_loss: -1.4358423462 Pen_loss: 0.5525298183 mse_train: 4.3985423809 shd_trian: 24.0000000000 time: 0.6854s\n",
            "Epoch: 0560 D_loss: -1.2740313617 G_loss: -0.4632148086 Pen_loss: 0.6202259644 mse_train: 4.2254431383 shd_trian: 24.0000000000 time: 0.9080s\n",
            "Epoch: 0561 D_loss: -1.3519502566 G_loss: -0.4539760602 Pen_loss: 0.6268175216 mse_train: 4.4055359333 shd_trian: 24.0000000000 time: 1.0118s\n",
            "Epoch: 0562 D_loss: -1.4628603607 G_loss: -0.3234727013 Pen_loss: 0.6865747643 mse_train: 4.0832987095 shd_trian: 24.0000000000 time: 0.8856s\n",
            "Epoch: 0563 D_loss: -1.6510524366 G_loss: -0.2187975358 Pen_loss: 0.7562734337 mse_train: 4.1017581538 shd_trian: 24.0000000000 time: 0.6624s\n",
            "Epoch: 0564 D_loss: -1.2081241203 G_loss: -0.4465441835 Pen_loss: 0.6050550905 mse_train: 4.0716428317 shd_trian: 23.7142857143 time: 0.7020s\n",
            "Epoch: 0565 D_loss: -1.6613365910 G_loss: -1.6401925263 Pen_loss: 0.6659019002 mse_train: 4.4338731595 shd_trian: 22.1428571429 time: 0.6949s\n",
            "Epoch: 0566 D_loss: -1.0690114104 G_loss: 0.1292632764 Pen_loss: 0.6132850927 mse_train: 4.1303478599 shd_trian: 22.0000000000 time: 0.6863s\n",
            "Epoch: 0567 D_loss: -1.3483758915 G_loss: -0.0795209049 Pen_loss: 0.7489816556 mse_train: 4.2048392111 shd_trian: 21.1428571429 time: 0.6932s\n",
            "Epoch: 0568 D_loss: -1.2551558627 G_loss: -0.8019788548 Pen_loss: 0.7619021902 mse_train: 4.0048553918 shd_trian: 21.0000000000 time: 0.6958s\n",
            "Epoch: 0569 D_loss: -1.3483409858 G_loss: 0.3067465072 Pen_loss: 0.7155110697 mse_train: 4.1480061287 shd_trian: 21.0000000000 time: 0.6772s\n",
            "Epoch: 0570 D_loss: -1.2286130224 G_loss: 0.5430694958 Pen_loss: 0.7195932341 mse_train: 4.4087903304 shd_trian: 21.0000000000 time: 0.7002s\n",
            "Epoch: 0571 D_loss: -1.2662199639 G_loss: -1.8759986344 Pen_loss: 0.6613588995 mse_train: 4.1794817911 shd_trian: 20.2857142857 time: 0.6979s\n",
            "Epoch: 0572 D_loss: -1.4187781600 G_loss: 0.8068001681 Pen_loss: 0.5883167113 mse_train: 4.1341336156 shd_trian: 20.0000000000 time: 0.7073s\n",
            "Epoch: 0573 D_loss: -1.3418592610 G_loss: -1.1849112369 Pen_loss: 0.6516507530 mse_train: 4.1479703932 shd_trian: 20.0000000000 time: 0.6946s\n",
            "Epoch: 0574 D_loss: -1.6126862857 G_loss: 0.9984662371 Pen_loss: 0.6808909159 mse_train: 4.5878419460 shd_trian: 20.8571428571 time: 0.8739s\n",
            "Epoch: 0575 D_loss: -1.9973934726 G_loss: -0.7292665627 Pen_loss: 0.7960684644 mse_train: 4.3397484648 shd_trian: 22.0000000000 time: 1.0215s\n",
            "Epoch: 0576 D_loss: -0.9195975782 G_loss: -0.9249439887 Pen_loss: 0.5580519598 mse_train: 4.1815571849 shd_trian: 22.0000000000 time: 0.7321s\n",
            "Epoch: 0577 D_loss: -1.5105787649 G_loss: -0.7001580481 Pen_loss: 0.6229423344 mse_train: 4.3457884270 shd_trian: 22.0000000000 time: 0.6944s\n",
            "Epoch: 0578 D_loss: -1.5818738985 G_loss: -1.4904931985 Pen_loss: 0.6313775187 mse_train: 4.0949551243 shd_trian: 22.0000000000 time: 0.7041s\n",
            "Epoch: 0579 D_loss: -2.2284545478 G_loss: -0.3293262187 Pen_loss: 0.7676306921 mse_train: 4.1478124769 shd_trian: 22.0000000000 time: 0.6902s\n",
            "Epoch: 0580 D_loss: -1.6812056670 G_loss: 0.5918731890 Pen_loss: 0.7195863667 mse_train: 4.5649406604 shd_trian: 22.0000000000 time: 0.6979s\n",
            "Epoch: 0581 D_loss: -1.6796284076 G_loss: -0.8435347798 Pen_loss: 0.6863634425 mse_train: 4.0256768663 shd_trian: 22.0000000000 time: 0.6729s\n",
            "Epoch: 0582 D_loss: -1.0459403935 G_loss: 0.5275707717 Pen_loss: 0.6774147655 mse_train: 4.5811662247 shd_trian: 22.0000000000 time: 0.6991s\n",
            "Epoch: 0583 D_loss: -2.2063890841 G_loss: -0.4736411831 Pen_loss: 0.7061318740 mse_train: 4.4785911828 shd_trian: 21.7142857143 time: 0.6970s\n",
            "Epoch: 0584 D_loss: -1.0898056562 G_loss: -1.8345931927 Pen_loss: 0.6598107447 mse_train: 3.9636056688 shd_trian: 21.1428571429 time: 0.7104s\n",
            "Epoch: 0585 D_loss: -0.8435984247 G_loss: 0.4835580142 Pen_loss: 0.5934552405 mse_train: 4.2727774603 shd_trian: 21.0000000000 time: 0.7023s\n",
            "Epoch: 0586 D_loss: -1.7946289485 G_loss: -1.9897540930 Pen_loss: 0.6543775033 mse_train: 3.9679040762 shd_trian: 20.0000000000 time: 0.7078s\n",
            "Epoch: 0587 D_loss: -1.5208429542 G_loss: -4.0177953209 Pen_loss: 0.7377318563 mse_train: 4.0619399208 shd_trian: 20.0000000000 time: 0.7864s\n",
            "Epoch: 0588 D_loss: -2.6269399429 G_loss: 1.5949840154 Pen_loss: 0.7160539496 mse_train: 4.2426870295 shd_trian: 20.0000000000 time: 1.0964s\n",
            "Epoch: 0589 D_loss: -1.0630905950 G_loss: 0.8189042017 Pen_loss: 0.7064636347 mse_train: 4.3032836998 shd_trian: 20.7142857143 time: 0.8432s\n",
            "Epoch: 0590 D_loss: -1.5673467273 G_loss: -3.5085633521 Pen_loss: 0.7129080525 mse_train: 4.4644501048 shd_trian: 21.0000000000 time: 0.6956s\n",
            "Epoch: 0591 D_loss: -2.0620927254 G_loss: 1.8561344597 Pen_loss: 0.7663231493 mse_train: 4.3729880272 shd_trian: 21.0000000000 time: 0.7153s\n",
            "Epoch: 0592 D_loss: -1.3917643138 G_loss: 1.6591344076 Pen_loss: 0.6504809672 mse_train: 4.3237721112 shd_trian: 20.4285714286 time: 0.7188s\n",
            "Epoch: 0593 D_loss: -1.7055467795 G_loss: -1.4487600710 Pen_loss: 0.7402529464 mse_train: 3.9017857790 shd_trian: 20.0000000000 time: 0.7648s\n",
            "Epoch: 0594 D_loss: -1.2072157914 G_loss: -0.5588266726 Pen_loss: 0.6471052571 mse_train: 4.3537769891 shd_trian: 20.7142857143 time: 0.7211s\n",
            "Epoch: 0595 D_loss: -1.9529510176 G_loss: -0.8719283065 Pen_loss: 0.7454514938 mse_train: 4.5000025763 shd_trian: 20.5714285714 time: 0.7194s\n",
            "Epoch: 0596 D_loss: -1.6246793792 G_loss: -1.2033582817 Pen_loss: 0.7349041330 mse_train: 3.9953495324 shd_trian: 20.4285714286 time: 0.9837s\n",
            "Epoch: 0597 D_loss: -1.9410811236 G_loss: -0.6436775348 Pen_loss: 0.6945546784 mse_train: 4.0186737608 shd_trian: 20.7142857143 time: 0.7367s\n",
            "Epoch: 0598 D_loss: -2.1816257538 G_loss: 0.3861064141 Pen_loss: 0.7881010980 mse_train: 4.0453085102 shd_trian: 20.0000000000 time: 0.7276s\n",
            "Epoch: 0599 D_loss: -1.5548101486 G_loss: -1.2281476572 Pen_loss: 0.7837953259 mse_train: 4.5875535352 shd_trian: 20.0000000000 time: 0.7631s\n",
            "Epoch: 0600 D_loss: -0.8469622823 G_loss: 0.8286716576 Pen_loss: 0.6390178996 mse_train: 4.6974173770 shd_trian: 21.0000000000 time: 0.9343s\n",
            "Epoch: 0601 D_loss: -1.0790914292 G_loss: 1.6382821359 Pen_loss: 0.6675040465 mse_train: 4.9042186365 shd_trian: 21.0000000000 time: 0.6975s\n",
            "Epoch: 0602 D_loss: -0.5026015009 G_loss: 0.6984200263 Pen_loss: 0.5473249893 mse_train: 4.4926203212 shd_trian: 20.0000000000 time: 0.7132s\n",
            "Epoch: 0603 D_loss: -1.4567708865 G_loss: 1.3912576057 Pen_loss: 0.6317007077 mse_train: 4.1616042274 shd_trian: 20.8571428571 time: 0.7034s\n",
            "Epoch: 0604 D_loss: -1.1236910534 G_loss: 0.1550730354 Pen_loss: 0.6448789105 mse_train: 4.1796034161 shd_trian: 20.0000000000 time: 0.7187s\n",
            "Epoch: 0605 D_loss: -1.7755060536 G_loss: -2.0476006112 Pen_loss: 0.7211231465 mse_train: 4.4062314000 shd_trian: 20.0000000000 time: 0.7662s\n",
            "Epoch: 0606 D_loss: -1.0475853550 G_loss: -0.1236164534 Pen_loss: 0.6387038975 mse_train: 4.3013221522 shd_trian: 20.4285714286 time: 0.7065s\n",
            "Epoch: 0607 D_loss: -1.8317718346 G_loss: -0.7519569050 Pen_loss: 0.6816285875 mse_train: 4.4653130940 shd_trian: 20.4285714286 time: 0.6921s\n",
            "Epoch: 0608 D_loss: -1.3615496154 G_loss: -0.2943215816 Pen_loss: 0.6350410281 mse_train: 4.2657185785 shd_trian: 20.0000000000 time: 0.7035s\n",
            "Epoch: 0609 D_loss: -1.4350095113 G_loss: -2.5950533786 Pen_loss: 0.7086412710 mse_train: 4.2339509253 shd_trian: 20.0000000000 time: 0.7235s\n",
            "Epoch: 0610 D_loss: -0.8263943177 G_loss: 1.1344278112 Pen_loss: 0.6412086728 mse_train: 5.0990738514 shd_trian: 20.0000000000 time: 0.7227s\n",
            "Epoch: 0611 D_loss: -0.9713857064 G_loss: 1.4136676231 Pen_loss: 0.6485668988 mse_train: 5.7803229549 shd_trian: 20.2857142857 time: 0.8950s\n",
            "Epoch: 0612 D_loss: -1.7206056671 G_loss: -2.3693929859 Pen_loss: 0.6476676710 mse_train: 4.0910201307 shd_trian: 21.1428571429 time: 1.0445s\n",
            "Epoch: 0613 D_loss: -1.1714263561 G_loss: 0.4667829962 Pen_loss: 0.6751997957 mse_train: 4.3122791243 shd_trian: 21.0000000000 time: 0.7699s\n",
            "Epoch: 0614 D_loss: -1.2329221410 G_loss: -2.6930050292 Pen_loss: 0.7686468971 mse_train: 4.3778387424 shd_trian: 21.7142857143 time: 0.6996s\n",
            "Epoch: 0615 D_loss: -1.2948646873 G_loss: 0.9616789988 Pen_loss: 0.6879711711 mse_train: 4.3929136659 shd_trian: 22.0000000000 time: 0.7183s\n",
            "Epoch: 0616 D_loss: -1.3715366889 G_loss: 1.9382220193 Pen_loss: 0.6930958577 mse_train: 3.8573262001 shd_trian: 22.0000000000 time: 0.7032s\n",
            "Epoch: 0617 D_loss: -1.0086725691 G_loss: 0.4675863238 Pen_loss: 0.5872950446 mse_train: 3.8068087819 shd_trian: 22.0000000000 time: 0.6904s\n",
            "Epoch: 0618 D_loss: -1.0397215296 G_loss: -1.4266199371 Pen_loss: 0.5978721829 mse_train: 3.8365780703 shd_trian: 22.0000000000 time: 0.6974s\n",
            "Epoch: 0619 D_loss: -0.6703094899 G_loss: -1.2048809660 Pen_loss: 0.5521930791 mse_train: 4.1376039879 shd_trian: 21.1428571429 time: 0.7242s\n",
            "Epoch: 0620 D_loss: -1.5994775656 G_loss: 1.2456134459 Pen_loss: 0.7226811777 mse_train: 4.5151775809 shd_trian: 21.0000000000 time: 0.6869s\n",
            "Epoch: 0621 D_loss: -0.8382447679 G_loss: -2.7606061525 Pen_loss: 0.6188057358 mse_train: 4.3037226088 shd_trian: 22.0000000000 time: 0.7022s\n",
            "Epoch: 0622 D_loss: -1.0400915939 G_loss: -0.4126017391 Pen_loss: 0.5863578693 mse_train: 4.1071491655 shd_trian: 22.0000000000 time: 0.7199s\n",
            "Epoch: 0623 D_loss: -1.7580790351 G_loss: 1.4467419636 Pen_loss: 0.6657148449 mse_train: 4.0529122030 shd_trian: 22.0000000000 time: 0.7487s\n",
            "Epoch: 0624 D_loss: -1.4281306297 G_loss: -0.1178094221 Pen_loss: 0.5993952890 mse_train: 4.0986683832 shd_trian: 22.0000000000 time: 0.8656s\n",
            "Epoch: 0625 D_loss: -1.0193597797 G_loss: 0.3028221356 Pen_loss: 0.6355053056 mse_train: 4.1475254360 shd_trian: 22.0000000000 time: 1.0688s\n",
            "Epoch: 0626 D_loss: -1.1591883435 G_loss: -0.4478660021 Pen_loss: 0.5977958606 mse_train: 4.1554370673 shd_trian: 22.0000000000 time: 0.8007s\n",
            "Epoch: 0627 D_loss: -1.7608303094 G_loss: -2.0464107260 Pen_loss: 0.6785322472 mse_train: 4.2863027281 shd_trian: 22.0000000000 time: 0.7144s\n",
            "Epoch: 0628 D_loss: -1.8483773347 G_loss: 0.3659562635 Pen_loss: 0.6420962042 mse_train: 4.4833790141 shd_trian: 21.0000000000 time: 0.7020s\n",
            "Epoch: 0629 D_loss: -1.2093613986 G_loss: -1.6145710203 Pen_loss: 0.6382881657 mse_train: 4.2278822876 shd_trian: 21.0000000000 time: 0.7438s\n",
            "Epoch: 0630 D_loss: -1.0509261949 G_loss: -2.7793119235 Pen_loss: 0.6526288253 mse_train: 4.2294454427 shd_trian: 21.0000000000 time: 0.7030s\n",
            "Epoch: 0631 D_loss: -1.2145926012 G_loss: -1.4055198697 Pen_loss: 0.6071540936 mse_train: 4.4725455719 shd_trian: 21.0000000000 time: 0.6825s\n",
            "Epoch: 0632 D_loss: -1.5388559558 G_loss: 0.5149165457 Pen_loss: 0.6887568682 mse_train: 4.9931582230 shd_trian: 21.0000000000 time: 1.0058s\n",
            "Epoch: 0633 D_loss: -1.4555198813 G_loss: 1.3401908211 Pen_loss: 0.6794890627 mse_train: 4.4271498682 shd_trian: 21.4285714286 time: 0.7203s\n",
            "Epoch: 0634 D_loss: -0.6275052098 G_loss: 1.6836890479 Pen_loss: 0.5813878853 mse_train: 4.0782162442 shd_trian: 22.0000000000 time: 0.7271s\n",
            "Epoch: 0635 D_loss: -1.1646808873 G_loss: -1.5041354267 Pen_loss: 0.5758945652 mse_train: 4.0103787476 shd_trian: 22.0000000000 time: 0.7245s\n",
            "Epoch: 0636 D_loss: -0.9720699671 G_loss: -0.2865660178 Pen_loss: 0.6342820241 mse_train: 4.2698355424 shd_trian: 22.0000000000 time: 0.7498s\n",
            "Epoch: 0637 D_loss: -0.8935873693 G_loss: -0.3628278973 Pen_loss: 0.5050018012 mse_train: 4.1959213103 shd_trian: 21.8571428571 time: 0.9092s\n",
            "Epoch: 0638 D_loss: -1.1691985550 G_loss: 0.3503928753 Pen_loss: 0.6300901875 mse_train: 3.9274021771 shd_trian: 21.0000000000 time: 1.0451s\n",
            "Epoch: 0639 D_loss: -0.5559843543 G_loss: -0.2803538791 Pen_loss: 0.5707853531 mse_train: 4.3446418244 shd_trian: 21.0000000000 time: 0.7559s\n",
            "Epoch: 0640 D_loss: -1.6223155214 G_loss: 1.4208703621 Pen_loss: 0.6279564351 mse_train: 3.9863270969 shd_trian: 22.0000000000 time: 0.7160s\n",
            "Epoch: 0641 D_loss: -1.5340348436 G_loss: -1.8208638003 Pen_loss: 0.6518770589 mse_train: 3.9463055314 shd_trian: 21.1428571429 time: 0.6806s\n",
            "Epoch: 0642 D_loss: -0.6385751750 G_loss: -0.6981792500 Pen_loss: 0.6019613669 mse_train: 4.6170530240 shd_trian: 21.1428571429 time: 0.7008s\n",
            "Epoch: 0643 D_loss: -1.9603401517 G_loss: 1.8320200174 Pen_loss: 0.7284828702 mse_train: 4.2241555744 shd_trian: 22.5714285714 time: 0.7155s\n",
            "Epoch: 0644 D_loss: -1.4603595096 G_loss: 0.3504206171 Pen_loss: 0.6391606396 mse_train: 4.0327728939 shd_trian: 22.8571428571 time: 0.6987s\n",
            "Epoch: 0645 D_loss: -1.0606561876 G_loss: -0.6075368555 Pen_loss: 0.5935186577 mse_train: 4.2712129454 shd_trian: 22.0000000000 time: 0.7118s\n",
            "Epoch: 0646 D_loss: -1.1392437799 G_loss: -1.6199458354 Pen_loss: 0.6331503744 mse_train: 4.3119445462 shd_trian: 22.0000000000 time: 0.6886s\n",
            "Epoch: 0647 D_loss: -1.1908762245 G_loss: -2.6280314092 Pen_loss: 0.5818697873 mse_train: 4.1959839240 shd_trian: 22.4285714286 time: 0.6881s\n",
            "Epoch: 0648 D_loss: -0.9579157804 G_loss: 0.0912008880 Pen_loss: 0.6032088818 mse_train: 4.2515390220 shd_trian: 23.0000000000 time: 0.7165s\n",
            "Epoch: 0649 D_loss: -1.7926043784 G_loss: 0.5318366158 Pen_loss: 0.6625668248 mse_train: 4.1896030823 shd_trian: 22.2857142857 time: 0.7099s\n",
            "Epoch: 0650 D_loss: -1.9203091372 G_loss: -0.5741256055 Pen_loss: 0.6543952736 mse_train: 4.2256441408 shd_trian: 22.0000000000 time: 0.9954s\n",
            "Epoch: 0651 D_loss: -2.2706398615 G_loss: -2.3899280197 Pen_loss: 0.7533394275 mse_train: 4.3367866027 shd_trian: 21.5714285714 time: 0.7111s\n",
            "Epoch: 0652 D_loss: -1.2454572190 G_loss: -0.7452832903 Pen_loss: 0.6170653947 mse_train: 4.2214227385 shd_trian: 21.0000000000 time: 0.7026s\n",
            "Epoch: 0653 D_loss: -1.0433051773 G_loss: 0.3471401706 Pen_loss: 0.5731936213 mse_train: 4.7334598071 shd_trian: 21.0000000000 time: 0.7152s\n",
            "Epoch: 0654 D_loss: -1.3631109524 G_loss: 1.6084732917 Pen_loss: 0.5426948216 mse_train: 4.5269215631 shd_trian: 21.0000000000 time: 0.7021s\n",
            "Epoch: 0655 D_loss: -1.4071611375 G_loss: 0.0362090763 Pen_loss: 0.7112124038 mse_train: 4.1407712901 shd_trian: 21.0000000000 time: 0.7041s\n",
            "Epoch: 0656 D_loss: -1.4504563759 G_loss: -0.3787525794 Pen_loss: 0.6131609751 mse_train: 4.6521571539 shd_trian: 21.0000000000 time: 0.7053s\n",
            "Epoch: 0657 D_loss: -1.4835956158 G_loss: 1.6031305380 Pen_loss: 0.7073946383 mse_train: 4.3795501465 shd_trian: 21.0000000000 time: 0.7521s\n",
            "Epoch: 0658 D_loss: -1.1049832742 G_loss: -1.1388861739 Pen_loss: 0.5231671138 mse_train: 4.1719854198 shd_trian: 22.0000000000 time: 0.7033s\n",
            "Epoch: 0659 D_loss: -1.4323902816 G_loss: -0.4341489800 Pen_loss: 0.6506483762 mse_train: 4.2350853972 shd_trian: 22.5714285714 time: 0.6911s\n",
            "Epoch: 0660 D_loss: -2.0366541151 G_loss: 0.2990713808 Pen_loss: 0.6282295972 mse_train: 4.5783951532 shd_trian: 23.0000000000 time: 0.7843s\n",
            "Epoch: 0661 D_loss: -1.7888948787 G_loss: -0.0502898585 Pen_loss: 0.7577809292 mse_train: 4.2488201090 shd_trian: 23.0000000000 time: 0.8534s\n",
            "Epoch: 0662 D_loss: -1.6353841674 G_loss: 0.8224194986 Pen_loss: 0.6707462607 mse_train: 4.0098439511 shd_trian: 23.0000000000 time: 1.0272s\n",
            "Epoch: 0663 D_loss: -1.5911355350 G_loss: 2.1189644742 Pen_loss: 0.7223530012 mse_train: 4.0788011368 shd_trian: 23.0000000000 time: 0.7774s\n",
            "Epoch: 0664 D_loss: -1.6961183790 G_loss: -1.3034761786 Pen_loss: 0.6334622712 mse_train: 4.2580513260 shd_trian: 23.0000000000 time: 0.7020s\n",
            "Epoch: 0665 D_loss: -1.7222450092 G_loss: -0.2799736786 Pen_loss: 0.7065443847 mse_train: 3.8986000150 shd_trian: 23.0000000000 time: 0.7886s\n",
            "Epoch: 0666 D_loss: -1.7843669997 G_loss: -2.8812340062 Pen_loss: 0.6318270576 mse_train: 4.2822736855 shd_trian: 22.2857142857 time: 0.7008s\n",
            "Epoch: 0667 D_loss: -2.2582205748 G_loss: -1.1833425809 Pen_loss: 0.7935993951 mse_train: 4.9543925317 shd_trian: 22.2857142857 time: 0.7061s\n",
            "Epoch: 0668 D_loss: -0.9027851093 G_loss: 1.0701105688 Pen_loss: 0.6923882115 mse_train: 4.6552848052 shd_trian: 23.0000000000 time: 0.7056s\n",
            "Epoch: 0669 D_loss: -3.1825007484 G_loss: -1.2408555717 Pen_loss: 0.8034066801 mse_train: 4.2620792735 shd_trian: 23.0000000000 time: 0.6850s\n",
            "Epoch: 0670 D_loss: -1.4892580231 G_loss: 0.8301106050 Pen_loss: 0.8511645905 mse_train: 4.4361534000 shd_trian: 23.0000000000 time: 0.7122s\n",
            "Epoch: 0671 D_loss: -1.3428189685 G_loss: -0.5446826660 Pen_loss: 0.7012220003 mse_train: 4.4323715279 shd_trian: 23.0000000000 time: 0.6809s\n",
            "Epoch: 0672 D_loss: -1.3457786829 G_loss: 2.7673560216 Pen_loss: 0.7441412803 mse_train: 4.6224837337 shd_trian: 23.0000000000 time: 0.7033s\n",
            "Epoch: 0673 D_loss: -1.6422629455 G_loss: 0.1886643660 Pen_loss: 0.6956488977 mse_train: 4.1999095820 shd_trian: 21.7142857143 time: 0.7126s\n",
            "Epoch: 0674 D_loss: -1.3637351123 G_loss: 0.3188684024 Pen_loss: 0.7118159462 mse_train: 4.2107304356 shd_trian: 21.0000000000 time: 0.7717s\n",
            "Epoch: 0675 D_loss: -1.1731722878 G_loss: -3.5278145207 Pen_loss: 0.6911746122 mse_train: 4.1289624960 shd_trian: 21.0000000000 time: 1.0126s\n",
            "Epoch: 0676 D_loss: -1.2396934244 G_loss: -1.4074979344 Pen_loss: 0.6837648964 mse_train: 4.3432931652 shd_trian: 21.0000000000 time: 0.8602s\n",
            "Epoch: 0677 D_loss: -1.4255842316 G_loss: -2.7242566299 Pen_loss: 0.6125445424 mse_train: 4.3911545391 shd_trian: 21.0000000000 time: 0.7083s\n",
            "Epoch: 0678 D_loss: -1.0345470026 G_loss: 0.5922348252 Pen_loss: 0.6522813173 mse_train: 4.1850740386 shd_trian: 21.2857142857 time: 0.6870s\n",
            "Epoch: 0679 D_loss: -1.2500625115 G_loss: 1.9758414915 Pen_loss: 0.6415626157 mse_train: 4.5730731499 shd_trian: 22.0000000000 time: 0.7010s\n",
            "Epoch: 0680 D_loss: -1.4749518023 G_loss: 0.2903548594 Pen_loss: 0.6607491988 mse_train: 4.3451496422 shd_trian: 22.0000000000 time: 0.6912s\n",
            "Epoch: 0681 D_loss: -0.8683090170 G_loss: -0.7655953634 Pen_loss: 0.6813704972 mse_train: 4.8616389352 shd_trian: 22.0000000000 time: 0.6735s\n",
            "Epoch: 0682 D_loss: -1.5843336546 G_loss: 1.7207153368 Pen_loss: 0.6822869223 mse_train: 4.3822081714 shd_trian: 22.0000000000 time: 0.7035s\n",
            "Epoch: 0683 D_loss: -1.4879162619 G_loss: -1.6630693031 Pen_loss: 0.6397880083 mse_train: 3.9776222968 shd_trian: 23.0000000000 time: 0.7099s\n",
            "Epoch: 0684 D_loss: -1.1073097852 G_loss: -2.8511055761 Pen_loss: 0.6603737609 mse_train: 3.9629463042 shd_trian: 23.0000000000 time: 0.6876s\n",
            "Epoch: 0685 D_loss: -1.4388530502 G_loss: -1.5943932268 Pen_loss: 0.5920961613 mse_train: 4.2992727099 shd_trian: 22.2857142857 time: 0.6914s\n",
            "Epoch: 0686 D_loss: -0.8047980555 G_loss: -3.3865434936 Pen_loss: 0.5829426214 mse_train: 4.2451967859 shd_trian: 21.8571428571 time: 0.6918s\n",
            "Epoch: 0687 D_loss: -1.6048280990 G_loss: 2.3345695942 Pen_loss: 0.8096969526 mse_train: 4.6865855513 shd_trian: 22.2857142857 time: 0.6798s\n",
            "Epoch: 0688 D_loss: -1.4172821353 G_loss: -0.3733258282 Pen_loss: 0.5962454334 mse_train: 4.0919534393 shd_trian: 21.8571428571 time: 1.2597s\n",
            "Epoch: 0689 D_loss: -1.1917061910 G_loss: -2.4222536233 Pen_loss: 0.6259228222 mse_train: 4.0538792062 shd_trian: 22.0000000000 time: 1.0014s\n",
            "Epoch: 0690 D_loss: -2.3387761802 G_loss: 1.6181791176 Pen_loss: 0.8029636860 mse_train: 4.4985171643 shd_trian: 22.1428571429 time: 0.7611s\n",
            "Epoch: 0691 D_loss: -0.8354205890 G_loss: -0.4247622070 Pen_loss: 0.5836565129 mse_train: 4.1382703429 shd_trian: 21.7142857143 time: 0.6579s\n",
            "Epoch: 0692 D_loss: -1.2210246064 G_loss: 0.8201443521 Pen_loss: 0.5721637809 mse_train: 4.4161550855 shd_trian: 21.4285714286 time: 0.6864s\n",
            "Epoch: 0693 D_loss: -0.5917197440 G_loss: -2.0157528500 Pen_loss: 0.5727612961 mse_train: 4.0741960297 shd_trian: 21.0000000000 time: 0.6764s\n",
            "Epoch: 0694 D_loss: -1.0367570322 G_loss: -0.2725309054 Pen_loss: 0.6402012909 mse_train: 5.1668513467 shd_trian: 22.4285714286 time: 0.6717s\n",
            "Epoch: 0695 D_loss: -1.3026800458 G_loss: 1.3791261562 Pen_loss: 0.5508626795 mse_train: 5.0735337503 shd_trian: 22.8571428571 time: 0.6958s\n",
            "Epoch: 0696 D_loss: -1.4285921758 G_loss: -0.8402538564 Pen_loss: 0.6551060146 mse_train: 4.2045066992 shd_trian: 21.5714285714 time: 0.6788s\n",
            "Epoch: 0697 D_loss: -1.7961824901 G_loss: 1.6543362154 Pen_loss: 0.5801214556 mse_train: 4.2936032796 shd_trian: 21.0000000000 time: 0.6877s\n",
            "Epoch: 0698 D_loss: -1.3340132298 G_loss: -1.9309963444 Pen_loss: 0.6798266175 mse_train: 4.0176963315 shd_trian: 21.0000000000 time: 0.6879s\n",
            "Epoch: 0699 D_loss: -1.9210242701 G_loss: 0.2993636594 Pen_loss: 0.6684487371 mse_train: 3.9915207202 shd_trian: 21.0000000000 time: 0.6978s\n",
            "Epoch: 0700 D_loss: -1.4964748476 G_loss: -1.1714154733 Pen_loss: 0.6797494228 mse_train: 3.8954868624 shd_trian: 20.4285714286 time: 0.6842s\n",
            "Epoch: 0701 D_loss: -1.4063853865 G_loss: -3.5950782638 Pen_loss: 0.6627678061 mse_train: 4.5658606060 shd_trian: 20.0000000000 time: 0.7139s\n",
            "Epoch: 0702 D_loss: -2.0002314449 G_loss: 1.8778334591 Pen_loss: 0.8433802814 mse_train: 4.3271176121 shd_trian: 20.0000000000 time: 0.6965s\n",
            "Epoch: 0703 D_loss: -1.3469897599 G_loss: 1.8719568483 Pen_loss: 0.5816588362 mse_train: 4.1950025451 shd_trian: 18.8571428571 time: 0.6751s\n",
            "Epoch: 0704 D_loss: -1.5673908448 G_loss: 1.5697858846 Pen_loss: 0.5749027578 mse_train: 4.7867653852 shd_trian: 18.0000000000 time: 0.7425s\n",
            "Epoch: 0705 D_loss: -1.3089688760 G_loss: 1.3334095059 Pen_loss: 0.6985529040 mse_train: 4.2146345381 shd_trian: 18.0000000000 time: 0.7125s\n",
            "Epoch: 0706 D_loss: -1.6713690386 G_loss: -1.6448380733 Pen_loss: 0.6710760686 mse_train: 3.7311513669 shd_trian: 18.0000000000 time: 0.7647s\n",
            "Epoch: 0707 D_loss: -1.7863079135 G_loss: 0.3869241397 Pen_loss: 0.7279469197 mse_train: 3.8364583197 shd_trian: 18.4285714286 time: 0.6849s\n",
            "Epoch: 0708 D_loss: -1.6532562043 G_loss: -0.9838834353 Pen_loss: 0.7258540632 mse_train: 3.8878899457 shd_trian: 20.0000000000 time: 0.6733s\n",
            "Epoch: 0709 D_loss: -1.9448817587 G_loss: -0.1596471846 Pen_loss: 0.7330748121 mse_train: 4.3040342164 shd_trian: 20.7142857143 time: 0.6951s\n",
            "Epoch: 0710 D_loss: -1.9232559464 G_loss: 2.4221067187 Pen_loss: 0.7337305514 mse_train: 4.5057723222 shd_trian: 21.0000000000 time: 0.6704s\n",
            "Epoch: 0711 D_loss: -1.3937245106 G_loss: 0.2979199955 Pen_loss: 0.7469081199 mse_train: 3.9338551238 shd_trian: 20.1428571429 time: 0.6850s\n",
            "Epoch: 0712 D_loss: -1.3440514226 G_loss: 2.3348863677 Pen_loss: 0.6751855087 mse_train: 3.9133094337 shd_trian: 20.0000000000 time: 0.7826s\n",
            "Epoch: 0713 D_loss: -1.3035816035 G_loss: -1.4188245508 Pen_loss: 0.6998498494 mse_train: 4.6354218246 shd_trian: 20.0000000000 time: 1.0115s\n",
            "Epoch: 0714 D_loss: -1.4899411455 G_loss: -1.2636299136 Pen_loss: 0.6177362388 mse_train: 3.9763076000 shd_trian: 20.8571428571 time: 0.8476s\n",
            "Epoch: 0715 D_loss: -1.4384106621 G_loss: -1.4829797433 Pen_loss: 0.6578820720 mse_train: 4.0169668583 shd_trian: 21.0000000000 time: 0.6767s\n",
            "Epoch: 0716 D_loss: -1.5066275337 G_loss: 3.1423738953 Pen_loss: 0.8053481412 mse_train: 4.0291791791 shd_trian: 21.0000000000 time: 0.6804s\n",
            "Epoch: 0717 D_loss: -1.9096619231 G_loss: -0.2573853060 Pen_loss: 0.6566689152 mse_train: 4.0355346112 shd_trian: 21.0000000000 time: 0.6929s\n",
            "Epoch: 0718 D_loss: -1.9395926305 G_loss: -0.6630974640 Pen_loss: 0.7694476318 mse_train: 4.3432000904 shd_trian: 20.0000000000 time: 0.6745s\n",
            "Epoch: 0719 D_loss: -0.7813638875 G_loss: -0.1320313527 Pen_loss: 0.5705576639 mse_train: 4.9269073495 shd_trian: 20.7142857143 time: 0.7226s\n",
            "Epoch: 0720 D_loss: -1.5416750709 G_loss: 2.2725868249 Pen_loss: 0.6432489104 mse_train: 4.5202426516 shd_trian: 21.0000000000 time: 0.7263s\n",
            "Epoch: 0721 D_loss: -1.7014840904 G_loss: 3.2491780057 Pen_loss: 0.7051775268 mse_train: 4.4934191847 shd_trian: 21.0000000000 time: 0.6981s\n",
            "Epoch: 0722 D_loss: -0.4652981081 G_loss: -0.2863787743 Pen_loss: 0.5948524126 mse_train: 4.5154227202 shd_trian: 21.0000000000 time: 0.7115s\n",
            "Epoch: 0723 D_loss: -1.7052255243 G_loss: -1.6815436924 Pen_loss: 0.6026151944 mse_train: 3.7443429143 shd_trian: 21.0000000000 time: 0.9584s\n",
            "Epoch: 0724 D_loss: -1.5010601855 G_loss: 0.4420770629 Pen_loss: 0.7242730779 mse_train: 3.9825260343 shd_trian: 21.0000000000 time: 0.7580s\n",
            "Epoch: 0725 D_loss: -0.8697064041 G_loss: -3.9951508915 Pen_loss: 0.5677854342 mse_train: 4.5422014827 shd_trian: 20.7142857143 time: 0.7188s\n",
            "Epoch: 0726 D_loss: -1.3128717288 G_loss: 1.2891373435 Pen_loss: 0.6248302567 mse_train: 4.4329709470 shd_trian: 20.0000000000 time: 0.9983s\n",
            "Epoch: 0727 D_loss: -1.3798815676 G_loss: -2.2870961687 Pen_loss: 0.5843240894 mse_train: 4.0677882931 shd_trian: 20.0000000000 time: 0.9680s\n",
            "Epoch: 0728 D_loss: -1.3061636657 G_loss: 0.7823313524 Pen_loss: 0.5861370610 mse_train: 3.8446638356 shd_trian: 20.0000000000 time: 0.7032s\n",
            "Epoch: 0729 D_loss: -1.8952837532 G_loss: -2.6020565844 Pen_loss: 0.7393763698 mse_train: 3.8685745453 shd_trian: 20.0000000000 time: 0.7169s\n",
            "Epoch: 0730 D_loss: -1.2633941719 G_loss: -2.5315222808 Pen_loss: 0.6267082840 mse_train: 4.3131390506 shd_trian: 20.0000000000 time: 0.7100s\n",
            "Epoch: 0731 D_loss: -1.4700509007 G_loss: 0.4245183525 Pen_loss: 0.6298048919 mse_train: 3.9602844355 shd_trian: 20.0000000000 time: 0.6639s\n",
            "Epoch: 0732 D_loss: -1.3065473939 G_loss: -1.5816992526 Pen_loss: 0.6866192084 mse_train: 4.3844243680 shd_trian: 20.0000000000 time: 0.6881s\n",
            "Epoch: 0733 D_loss: -1.9758564289 G_loss: 0.0373740848 Pen_loss: 0.7221241582 mse_train: 3.9540262576 shd_trian: 19.4285714286 time: 0.6893s\n",
            "Epoch: 0734 D_loss: -0.9851570807 G_loss: 2.1137571786 Pen_loss: 0.6213723130 mse_train: 4.2627775469 shd_trian: 19.0000000000 time: 0.7519s\n",
            "Epoch: 0735 D_loss: -1.1885036576 G_loss: 0.0171790152 Pen_loss: 0.6024109953 mse_train: 4.4225367787 shd_trian: 18.0000000000 time: 0.6961s\n",
            "Epoch: 0736 D_loss: -1.4504314785 G_loss: -0.0809213469 Pen_loss: 0.7167611953 mse_train: 4.7516117546 shd_trian: 18.2857142857 time: 0.7191s\n",
            "Epoch: 0737 D_loss: -1.2518916503 G_loss: 0.4593928244 Pen_loss: 0.5381856997 mse_train: 7.7357700378 shd_trian: 19.0000000000 time: 0.6879s\n",
            "Epoch: 0738 D_loss: -1.9712019429 G_loss: -3.2835988424 Pen_loss: 0.7172759296 mse_train: 4.2988493994 shd_trian: 19.0000000000 time: 0.6980s\n",
            "Epoch: 0739 D_loss: -1.8712999473 G_loss: -0.9787516836 Pen_loss: 0.7481892750 mse_train: 5.3804428933 shd_trian: 19.0000000000 time: 0.7852s\n",
            "Epoch: 0740 D_loss: -1.2644182196 G_loss: 3.2064718105 Pen_loss: 0.6583383891 mse_train: 4.7877778071 shd_trian: 19.1428571429 time: 1.0081s\n",
            "Epoch: 0741 D_loss: -2.0971739576 G_loss: 4.9886153706 Pen_loss: 0.9078991215 mse_train: 4.6309359013 shd_trian: 20.0000000000 time: 0.6947s\n",
            "Epoch: 0742 D_loss: -1.6546095367 G_loss: 0.9517406392 Pen_loss: 0.6211386306 mse_train: 4.2233795675 shd_trian: 20.0000000000 time: 0.6807s\n",
            "Epoch: 0743 D_loss: -1.7167144265 G_loss: 0.4604303190 Pen_loss: 0.6464043562 mse_train: 4.3813233943 shd_trian: 19.2857142857 time: 0.6933s\n",
            "Epoch: 0744 D_loss: -1.7525707037 G_loss: -2.5305498736 Pen_loss: 0.6723752697 mse_train: 3.8357680781 shd_trian: 18.8571428571 time: 0.7057s\n",
            "Epoch: 0745 D_loss: -1.3604909814 G_loss: -1.3835129935 Pen_loss: 0.6270495111 mse_train: 3.7739699543 shd_trian: 19.5714285714 time: 0.7140s\n",
            "Epoch: 0746 D_loss: -1.3022184724 G_loss: -1.0261086853 Pen_loss: 0.6555849385 mse_train: 4.9656206531 shd_trian: 19.5714285714 time: 0.6783s\n",
            "Epoch: 0747 D_loss: -2.1802490025 G_loss: 2.3694992245 Pen_loss: 0.7009142557 mse_train: 4.9381867674 shd_trian: 20.0000000000 time: 0.6904s\n",
            "Epoch: 0748 D_loss: -1.2040631130 G_loss: 1.7444282852 Pen_loss: 0.6095591521 mse_train: 4.1595551497 shd_trian: 20.0000000000 time: 0.6991s\n",
            "Epoch: 0749 D_loss: -1.1036081465 G_loss: -0.3708907623 Pen_loss: 0.6607210265 mse_train: 4.4129543038 shd_trian: 20.0000000000 time: 0.6710s\n",
            "Epoch: 0750 D_loss: -1.1287878781 G_loss: 0.5026758939 Pen_loss: 0.6399550890 mse_train: 4.0117274563 shd_trian: 20.0000000000 time: 0.6863s\n",
            "Epoch: 0751 D_loss: -1.3028641493 G_loss: 0.4189066571 Pen_loss: 0.6182101278 mse_train: 4.1183729833 shd_trian: 20.0000000000 time: 0.9923s\n",
            "Epoch: 0752 D_loss: -0.9486203830 G_loss: 1.0314938118 Pen_loss: 0.5760760546 mse_train: 5.1362180669 shd_trian: 19.7142857143 time: 0.8858s\n",
            "Epoch: 0753 D_loss: -1.4900642471 G_loss: -2.5277679460 Pen_loss: 0.7134111420 mse_train: 4.1897870431 shd_trian: 19.0000000000 time: 0.6777s\n",
            "Epoch: 0754 D_loss: -1.6298594777 G_loss: -0.4638150793 Pen_loss: 0.7119002211 mse_train: 4.0278620919 shd_trian: 19.0000000000 time: 0.6976s\n",
            "Epoch: 0755 D_loss: -1.5161545722 G_loss: -0.7384242059 Pen_loss: 0.6227091336 mse_train: 4.1327469129 shd_trian: 19.0000000000 time: 0.6929s\n",
            "Epoch: 0756 D_loss: -1.2483896682 G_loss: 1.6223408671 Pen_loss: 0.6996439121 mse_train: 3.7836467242 shd_trian: 19.8571428571 time: 0.6736s\n",
            "Epoch: 0757 D_loss: -1.2275362537 G_loss: 3.1030175302 Pen_loss: 0.6740693023 mse_train: 3.7048274807 shd_trian: 20.0000000000 time: 0.6818s\n",
            "Epoch: 0758 D_loss: -1.6264656897 G_loss: 3.6870048359 Pen_loss: 0.6331401157 mse_train: 4.0917638080 shd_trian: 20.0000000000 time: 0.7022s\n",
            "Epoch: 0759 D_loss: -1.4331782745 G_loss: -0.3186450165 Pen_loss: 0.6194660351 mse_train: 4.0154765885 shd_trian: 20.2857142857 time: 0.6854s\n",
            "Epoch: 0760 D_loss: -1.8026035548 G_loss: 0.2521528248 Pen_loss: 0.7502926523 mse_train: 3.6374920311 shd_trian: 20.7142857143 time: 0.7035s\n",
            "Epoch: 0761 D_loss: -1.5253741715 G_loss: 0.7966153911 Pen_loss: 0.6822641708 mse_train: 4.5500777837 shd_trian: 19.8571428571 time: 0.9762s\n",
            "Epoch: 0762 D_loss: -1.6747936835 G_loss: -1.4488120221 Pen_loss: 0.7135346166 mse_train: 4.7344344462 shd_trian: 19.2857142857 time: 0.6771s\n",
            "Epoch: 0763 D_loss: -1.6120965193 G_loss: -1.0151592072 Pen_loss: 0.5862226440 mse_train: 3.7056417139 shd_trian: 19.0000000000 time: 0.6849s\n",
            "Epoch: 0764 D_loss: -1.0385681892 G_loss: -0.5620986994 Pen_loss: 0.5795934312 mse_train: 4.9887985421 shd_trian: 19.2857142857 time: 0.8987s\n",
            "Epoch: 0765 D_loss: -1.2289881398 G_loss: -1.6118318590 Pen_loss: 0.5579813930 mse_train: 4.6685011253 shd_trian: 19.0000000000 time: 1.0923s\n",
            "Epoch: 0766 D_loss: -0.8998009790 G_loss: 2.2994212200 Pen_loss: 0.6286818245 mse_train: 4.6392901418 shd_trian: 18.2857142857 time: 0.7485s\n",
            "Epoch: 0767 D_loss: -1.3519673380 G_loss: -0.4957037339 Pen_loss: 0.5720768981 mse_train: 4.3624222999 shd_trian: 17.7142857143 time: 0.6926s\n",
            "Epoch: 0768 D_loss: -1.5467214744 G_loss: -1.3493965735 Pen_loss: 0.6432896405 mse_train: 3.7265299722 shd_trian: 17.0000000000 time: 0.7033s\n",
            "Epoch: 0769 D_loss: -1.3857104233 G_loss: -1.7808790008 Pen_loss: 0.6305861894 mse_train: 5.6620572230 shd_trian: 17.4285714286 time: 0.7044s\n",
            "Epoch: 0770 D_loss: -0.9309578430 G_loss: 2.2195821762 Pen_loss: 0.5527056272 mse_train: 3.7887286390 shd_trian: 18.0000000000 time: 0.6975s\n",
            "Epoch: 0771 D_loss: -1.3802217995 G_loss: 5.2371317432 Pen_loss: 0.7467559284 mse_train: 4.4200367138 shd_trian: 18.0000000000 time: 0.6744s\n",
            "Epoch: 0772 D_loss: -2.0514404224 G_loss: 3.2029997990 Pen_loss: 0.7816997553 mse_train: 3.5432158046 shd_trian: 17.1428571429 time: 0.7098s\n",
            "Epoch: 0773 D_loss: -2.1474533909 G_loss: -4.0115289317 Pen_loss: 0.7258215175 mse_train: 3.5021488739 shd_trian: 16.5714285714 time: 0.6884s\n",
            "Epoch: 0774 D_loss: -2.1386637847 G_loss: -2.4430051761 Pen_loss: 0.6869456579 mse_train: 3.7754925565 shd_trian: 17.0000000000 time: 0.6954s\n",
            "Epoch: 0775 D_loss: -1.5906796922 G_loss: 0.4423347483 Pen_loss: 0.6626015664 mse_train: 4.3852928660 shd_trian: 17.0000000000 time: 0.6703s\n",
            "Epoch: 0776 D_loss: -0.7271385942 G_loss: 0.7371225640 Pen_loss: 0.6600876408 mse_train: 5.6902235439 shd_trian: 18.0000000000 time: 0.7044s\n",
            "Epoch: 0777 D_loss: -0.9904217230 G_loss: 2.2790230690 Pen_loss: 0.6253352535 mse_train: 6.6319283810 shd_trian: 18.0000000000 time: 0.6931s\n",
            "Epoch: 0778 D_loss: -2.2679460215 G_loss: 1.3088211444 Pen_loss: 0.6875801828 mse_train: 4.6669769942 shd_trian: 19.0000000000 time: 1.0017s\n",
            "Epoch: 0779 D_loss: -1.6845491930 G_loss: -0.8863014998 Pen_loss: 0.6422432567 mse_train: 4.7524130846 shd_trian: 19.0000000000 time: 1.1218s\n",
            "Epoch: 0780 D_loss: -2.5682293280 G_loss: 0.1548691219 Pen_loss: 0.8108362472 mse_train: 4.3408187264 shd_trian: 19.0000000000 time: 0.6792s\n",
            "Epoch: 0781 D_loss: -1.4325011778 G_loss: 1.6221535567 Pen_loss: 0.7239989487 mse_train: 4.2433154364 shd_trian: 18.7142857143 time: 0.6843s\n",
            "Epoch: 0782 D_loss: -2.4977335773 G_loss: -2.8685757846 Pen_loss: 0.8377540761 mse_train: 4.6799654408 shd_trian: 18.0000000000 time: 0.6992s\n",
            "Epoch: 0783 D_loss: -1.0161265872 G_loss: 1.2927201943 Pen_loss: 0.6402367837 mse_train: 4.0476076763 shd_trian: 18.0000000000 time: 0.6813s\n",
            "Epoch: 0784 D_loss: -2.0839257679 G_loss: 2.3221643371 Pen_loss: 0.7955245010 mse_train: 6.4511393306 shd_trian: 19.0000000000 time: 0.6847s\n",
            "Epoch: 0785 D_loss: -1.1975577257 G_loss: 5.3114580648 Pen_loss: 0.6980507150 mse_train: 9.2219920571 shd_trian: 18.4285714286 time: 0.6899s\n",
            "Epoch: 0786 D_loss: -1.5163754159 G_loss: -0.8987268606 Pen_loss: 0.6608430359 mse_train: 4.0379675195 shd_trian: 18.8571428571 time: 0.7025s\n",
            "Epoch: 0787 D_loss: -1.7026905696 G_loss: -0.8605214616 Pen_loss: 0.6589002052 mse_train: 4.8025133663 shd_trian: 18.5714285714 time: 0.6910s\n",
            "Epoch: 0788 D_loss: -2.3997008860 G_loss: -0.4942579373 Pen_loss: 0.7929549074 mse_train: 4.0494126267 shd_trian: 20.0000000000 time: 0.7105s\n",
            "Epoch: 0789 D_loss: -2.6983616433 G_loss: -1.4377802591 Pen_loss: 0.8295747429 mse_train: 4.1420313876 shd_trian: 20.0000000000 time: 0.7067s\n",
            "Epoch: 0790 D_loss: -2.5106288330 G_loss: -1.6708721357 Pen_loss: 0.8573417871 mse_train: 3.8779163977 shd_trian: 20.0000000000 time: 0.7491s\n",
            "Epoch: 0791 D_loss: -2.5764035942 G_loss: -2.0645794324 Pen_loss: 0.8394380383 mse_train: 4.1246784606 shd_trian: 20.0000000000 time: 0.6810s\n",
            "Epoch: 0792 D_loss: -2.6605185898 G_loss: -3.2014295837 Pen_loss: 0.8289371299 mse_train: 4.0356078491 shd_trian: 19.1428571429 time: 0.6899s\n",
            "Epoch: 0793 D_loss: -1.9277682068 G_loss: -0.3243885630 Pen_loss: 0.8292240582 mse_train: 4.0374104274 shd_trian: 19.0000000000 time: 0.6950s\n",
            "Epoch: 0794 D_loss: -2.4508726209 G_loss: -3.1602503171 Pen_loss: 0.7671791292 mse_train: 3.8234660745 shd_trian: 19.2857142857 time: 0.6991s\n",
            "Epoch: 0795 D_loss: -1.9969834991 G_loss: -4.3120059086 Pen_loss: 0.7959417525 mse_train: 3.9945825172 shd_trian: 20.0000000000 time: 0.6881s\n",
            "Epoch: 0796 D_loss: -1.7488262104 G_loss: -3.1243759110 Pen_loss: 0.6464994842 mse_train: 4.1925638167 shd_trian: 19.2857142857 time: 0.6969s\n",
            "Epoch: 0797 D_loss: -1.8085200044 G_loss: -0.0436635005 Pen_loss: 0.7135861209 mse_train: 4.2332066218 shd_trian: 19.0000000000 time: 0.6958s\n",
            "Epoch: 0798 D_loss: -2.3064520774 G_loss: -2.1708190117 Pen_loss: 0.7679888068 mse_train: 3.8607067492 shd_trian: 18.2857142857 time: 0.7091s\n",
            "Epoch: 0799 D_loss: -1.1950113527 G_loss: 2.6378624944 Pen_loss: 0.7674230991 mse_train: 3.9855443617 shd_trian: 18.0000000000 time: 0.7047s\n",
            "GW [[0. 1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 1. 0. 0. 1. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 1. 0. 0. 1. 0. 1. 0.]]\n",
            "graph [[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  1.  1.  1.  0.  0.  0.5 1. ]\n",
            " [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.1 0.  1.  0.  0.  0.  0.  0. ]\n",
            " [0.6 0.  0.  0.  0.  1.  0.  0.  0.  1. ]\n",
            " [0.  1.  1.  0.  0.  0.  0.  0.  1.  0. ]\n",
            " [0.  0.  0.3 0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]]\n",
            "graph threshold 0.1 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
            " [0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "threshold 0.1, Accuracy: fdr 0.7222222222222222  tpr  0.2777777777777778  fpr  0.48148148148148145 shd 20 nnz 18\n",
            "graph threshold 0.2 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
            " [0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "threshold 0.2, Accuracy: fdr 0.7058823529411765  tpr  0.2777777777777778  fpr  0.4444444444444444 shd 19 nnz 17\n",
            "graph threshold 0.3 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
            " [0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "threshold 0.3, Accuracy: fdr 0.6875  tpr  0.2777777777777778  fpr  0.4074074074074074 shd 18 nnz 16\n"
          ]
        }
      ],
      "source": [
        "def fake_data_generation(size):\n",
        "    #DF18-01: add to device for GPU\n",
        "    #z = Variable(torch.FloatTensor(np.random.normal(0, 1, (self.batch_size, self.data_variable_size, self.z_dims)))).double().cuda()\n",
        "    z = Variable(torch.FloatTensor(np.random.normal(0, 1, (size, data_variable_size, z_dims)))).double().to(device)\n",
        "    A, P_inv = dp_dag.sample()\n",
        "\n",
        "    fake_data = generator(z, size, data_variable_size, A, P_inv)\n",
        "    return fake_data\n",
        "\n",
        "#DF: this is the my implementation \"train\", where I do not repeat the same data with self.discriminator_steps\n",
        "'''training algorithm for a single epoch'''\n",
        "def train_DF(train_loader, epoch, ground_truth_G, optimizerG, optimizerD, optimizerDAG):\n",
        "\n",
        "    t = time.time()\n",
        "    D_loss = []\n",
        "    G_loss = []\n",
        "    Pen_loss = []\n",
        "    #MMD_loss = [] #DF remove\n",
        "    mse_train = []\n",
        "    shd_trian = []\n",
        "\n",
        "    # update optimizer\n",
        "    #optimizerG, lr = self.update_optimizer(optimizerG, self.lr, c_A)\n",
        "    #optimizerD, lr = self.update_optimizer(optimizerD, self.lr, c_A)\n",
        "\n",
        "    N_Dag_updated = 0                            #DF added\n",
        "\n",
        "    for batch_idx, (data, relations) in enumerate(train_loader):\n",
        "        ###################################################################\n",
        "        # (1) Update D network: maximize D(x)) - D(G(z)))\n",
        "        ###################################################################\n",
        "\n",
        "        data, relations = Variable(data.to(device)).double(), Variable(relations.to(device)).double()\n",
        "\n",
        "        #DF07-01: Added visualization of real data at the first batch of certain epoches\n",
        "        #if batch_idx==0 and epoch%10==0:\n",
        "        #    Visualize_data(data, data_variable_size, sampling=0, fname=\"results/real\"+str(epoch))\n",
        "\n",
        "        optimizerD.zero_grad()\n",
        "\n",
        "        #DF07-01: modi added batch_size\n",
        "        fake = fake_data_generation(batch_size)\n",
        "\n",
        "        y_fake = discriminator(fake)\n",
        "        y_real = discriminator(data)\n",
        "\n",
        "        if x_dims > 1:\n",
        "            #vector case\n",
        "            pen = discriminator.calc_gradient_penalty(\n",
        "                data.view(-1, data.size(1) * data.size(2)), fake.view(-1, fake.size(1) * fake.size(2)), device)\n",
        "            loss_d = -(torch.mean(F.softplus(y_real)) - torch.mean(F.softplus(y_fake)))\n",
        "        else:\n",
        "            #normal continious and discrete data case\n",
        "            pen = discriminator.calc_gradient_penalty(\n",
        "                    data, fake, device)\n",
        "            #DF modi: NO solftplus\n",
        "            #loss_d = -(torch.mean(F.softplus(y_real)) - torch.mean(F.softplus(y_fake)))\n",
        "            loss_d = -(torch.mean(y_real) - torch.mean(y_fake))\n",
        "\n",
        "        Pen_loss.append(pen.item())\n",
        "        pen.backward(retain_graph=True)\n",
        "\n",
        "        D_loss.append(loss_d.item())\n",
        "        loss_d.backward()\n",
        "        loss_d = optimizerD.step()\n",
        "\n",
        "        ###############################################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###############################################\n",
        "        if batch_idx % discriminator_steps == 0:\n",
        "\n",
        "            optimizerG.zero_grad()\n",
        "            optimizerDAG.zero_grad()\n",
        "\n",
        "            #DF07-01: modi added batch_size\n",
        "            fake = fake_data_generation(batch_size)\n",
        "            y_fake = discriminator(fake)\n",
        "\n",
        "            #DF remove\n",
        "            #loss_mmd = compute_mmd(data.squeeze(), fake_data)\n",
        "\n",
        "            #DF modi: add regularation\n",
        "            #loss_g = -torch.mean(F.softplus(y_fake)) #+ loss_mmd\n",
        "            kl_loss = torch.nn.KLDivLoss(reduction='mean')\n",
        "            regularizer = kl_loss(dp_dag.edge_log_params, 0.01 * torch.ones_like(dp_dag.edge_log_params))\n",
        "            #DF modi: NO solftplus\n",
        "            #loss_g = -torch.mean(F.softplus(y_fake))+0.01*regularizer\n",
        "            loss_g = -torch.mean(y_fake)+0.1*regularizer               #DF: was 0.01\n",
        "\n",
        "            #print(\"-torch.mean(y_fake)\",-torch.mean(y_fake))\n",
        "            #print(\"regularizer\", regularizer)\n",
        "\n",
        "            G_loss.append(loss_g.item())\n",
        "            #MMD_loss.append(loss_mmd.item())  #DF remove\n",
        "            loss_g.backward()\n",
        "            optimizerG.step()\n",
        "\n",
        "            #DF modi: learn optimizerDAG less\n",
        "            #optimizerDAG.step()\n",
        "            NN = discriminator_steps * 1    #1 means the Dag and generators are updated together\n",
        "            if batch_idx % NN == 0:\n",
        "                optimizerDAG.step()\n",
        "\n",
        "            ###############################################\n",
        "            # (3) Update DAG network: maximize log(D(G(z)))\n",
        "            ###############################################\n",
        "\n",
        "            #DF remove\n",
        "            #self.schedulerG.step()\n",
        "            #self.schedulerD.step()\n",
        "            #self.schedulerDAG.step()\n",
        "\n",
        "            #print(self.dp_dag.weight.grad)\n",
        "\n",
        "            graph = dp_dag.get_prob_mask().detach().cpu().numpy()\n",
        "            graph[np.abs(graph) < graph_threshold] = 0\n",
        "\n",
        "            if ground_truth_G != None:\n",
        "                GAA = nx.adjacency_matrix(ground_truth_G)\n",
        "                GAA = np.abs(GAA)       #DF: for GAA, we do not really use any negative entries\n",
        "                GAA[GAA>0.01] = 1        #DF: binarises GAA\n",
        "                #graph[np.abs(graph) >= self.graph_threshold] = 1  #DF: binarises the graph\n",
        "                graph[graph >=  graph_threshold] =  1\n",
        "                graph[graph <= -graph_threshold] = -1\n",
        "                #fdr, tpr, fpr, shd, nnz = count_accuracy(ground_truth_G, nx.DiGraph(graph))\n",
        "                fdr, tpr, fpr, shd, nnz = count_accuracy(nx.DiGraph(GAA), nx.DiGraph(graph.T))\n",
        "\n",
        "                shd_trian.append(shd)   #shd is stored\n",
        "\n",
        "            mse_train.append(F.mse_loss(fake, data.squeeze()).item())\n",
        "\n",
        "    print('Epoch: {:04d}'.format(epoch),\n",
        "              'D_loss: {:.10f}'.format(np.mean(D_loss)),\n",
        "              'G_loss: {:.10f}'.format(np.mean(G_loss)),\n",
        "              'Pen_loss: {:.10f}'.format(np.mean(Pen_loss)),\n",
        "              #'MMD_loss: {:.10f}'.format(np.mean(MMD_loss)), #DF remove\n",
        "              'mse_train: {:.10f}'.format(np.mean(mse_train)),\n",
        "              'shd_trian: {:.10f}'.format(np.mean(shd_trian)),\n",
        "              'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "    #DF10-1: add return of shd_train\n",
        "    return np.mean(D_loss), np.mean(G_loss), np.mean(Pen_loss), np.mean(mse_train), np.mean(shd_trian), graph\n",
        "\n",
        "def count_accuracy(G_true: nx.DiGraph,\n",
        "                   G: nx.DiGraph,\n",
        "                   G_und: nx.DiGraph = None) -> tuple:\n",
        "    \"\"\"Compute FDR, TPR, and FPR for B, or optionally for CPDAG B + B_und.\n",
        "    Args:\n",
        "        G_true: ground truth graph\n",
        "        G: predicted graph\n",
        "        G_und: predicted undirected edges in CPDAG, asymmetric\n",
        "    Returns:\n",
        "        fdr: (reverse + false positive) / prediction positive\n",
        "        tpr: (true positive) / condition positive\n",
        "        fpr: (reverse + false positive) / condition negative\n",
        "        shd: undirected extra + undirected missing + reverse\n",
        "        nnz: prediction positive\n",
        "    \"\"\"\n",
        "    B_true = nx.to_numpy_array(G_true) != 0\n",
        "    B = nx.to_numpy_array(G) != 0\n",
        "    B_und = None if G_und is None else nx.to_numpy_array(G_und)\n",
        "    d = B.shape[0]\n",
        "    # linear index of nonzeros\n",
        "    if B_und is not None:\n",
        "        pred_und = np.flatnonzero(B_und)\n",
        "    pred = np.flatnonzero(B)\n",
        "    cond = np.flatnonzero(B_true)\n",
        "    cond_reversed = np.flatnonzero(B_true.T)\n",
        "    cond_skeleton = np.concatenate([cond, cond_reversed])\n",
        "    # true pos\n",
        "    true_pos = np.intersect1d(pred, cond, assume_unique=True)\n",
        "    if B_und is not None:\n",
        "        # treat undirected edge favorably\n",
        "        true_pos_und = np.intersect1d(pred_und, cond_skeleton, assume_unique=True)\n",
        "        true_pos = np.concatenate([true_pos, true_pos_und])\n",
        "    # false pos\n",
        "    false_pos = np.setdiff1d(pred, cond_skeleton, assume_unique=True)\n",
        "    if B_und is not None:\n",
        "        false_pos_und = np.setdiff1d(pred_und, cond_skeleton, assume_unique=True)\n",
        "        false_pos = np.concatenate([false_pos, false_pos_und])\n",
        "    # reverse\n",
        "    extra = np.setdiff1d(pred, cond, assume_unique=True)\n",
        "    reverse = np.intersect1d(extra, cond_reversed, assume_unique=True)\n",
        "    # compute ratio\n",
        "    pred_size = len(pred)\n",
        "    if B_und is not None:\n",
        "        pred_size += len(pred_und)\n",
        "    cond_neg_size = 0.5 * d * (d - 1) - len(cond)\n",
        "    fdr = float(len(reverse) + len(false_pos)) / max(pred_size, 1)\n",
        "    tpr = float(len(true_pos)) / max(len(cond), 1)\n",
        "    fpr = float(len(reverse) + len(false_pos)) / max(cond_neg_size, 1)\n",
        "    # structural hamming distance\n",
        "    B_lower = np.tril(B + B.T)\n",
        "    if B_und is not None:\n",
        "        B_lower += np.tril(B_und + B_und.T)\n",
        "    pred_lower = np.flatnonzero(B_lower)\n",
        "    cond_lower = np.flatnonzero(np.tril(B_true + B_true.T))\n",
        "    extra_lower = np.setdiff1d(pred_lower, cond_lower, assume_unique=True)\n",
        "    missing_lower = np.setdiff1d(cond_lower, pred_lower, assume_unique=True)\n",
        "    shd = len(extra_lower) + len(missing_lower) + len(reverse)\n",
        "    return fdr, tpr, fpr, shd, pred_size\n",
        "\n",
        "def Visulize_results(epoch):\n",
        "    #DF18-01: correction add cpu() for GPU\n",
        "    fake = fake_data_generation(5000).detach().cpu().numpy()\n",
        "    fake = fake[..., np.newaxis]\n",
        "    Visualize_data(fake, data_variable_size, sampling=0, fname=\"results/fake\"+str(epoch))\n",
        "\n",
        "def print_results():\n",
        "\n",
        "    graph = dp_dag.get_prob_mask().detach().cpu().numpy()\n",
        "    GW = nx.to_numpy_array(ground_truth_G)\n",
        "    GW = np.abs(GW)       #DF: for GAA, we do not really use any negative entries\n",
        "    GW[GW>0.01] = 1        #DF: binarises GAA\n",
        "    print(\"GW\", np.around(GW.T,1))\n",
        "    print(\"graph\", np.around(graph,1))\n",
        "\n",
        "    graph_th1 = np.array(graph)\n",
        "    graph_th1[np.abs(graph) < 0.1] = 0\n",
        "    #graph[np.abs(graph) >= 0.1] = 1  #DF: binarises the graph\n",
        "    graph_th1[graph >=  0.1] =  1\n",
        "    graph_th1[graph <= -0.1] = -1\n",
        "    # print(graph)\n",
        "    #fdr, tpr, fpr, shd, nnz = count_accuracy(ground_truth_G, nx.DiGraph(graph))\n",
        "    fdr, tpr, fpr, shd, nnz = count_accuracy(nx.DiGraph(GW), nx.DiGraph(graph_th1.T))\n",
        "    print(\"graph threshold 0.1\", np.around(graph_th1,1))\n",
        "    print('threshold 0.1, Accuracy: fdr', fdr, ' tpr ', tpr, ' fpr ', fpr, 'shd', shd, 'nnz', nnz)\n",
        "\n",
        "    graph_th2 = np.array(graph)\n",
        "    graph_th2[np.abs(graph) < 0.2] = 0\n",
        "    #graph[np.abs(graph) >= 0.2] = 1  #DF: binarises the graph\n",
        "    graph_th2[graph >=  0.2] =  1\n",
        "    graph_th2[graph <= -0.2] = -1\n",
        "    # print(graph)\n",
        "    #fdr, tpr, fpr, shd, nnz = count_accuracy(ground_truth_G, nx.DiGraph(graph))\n",
        "    fdr, tpr, fpr, shd, nnz = count_accuracy(nx.DiGraph(GW), nx.DiGraph(graph_th2.T))\n",
        "    print(\"graph threshold 0.2\", np.around(graph_th2,1))\n",
        "    print('threshold 0.2, Accuracy: fdr', fdr, ' tpr ', tpr, ' fpr ', fpr, 'shd', shd, 'nnz', nnz)\n",
        "\n",
        "    graph_th3 = np.array(graph)\n",
        "    graph_th3[np.abs(graph) < 0.3] = 0\n",
        "    #graph[np.abs(graph) >= 0.3] = 1  #DF: binarises the graph\n",
        "    graph_th3[graph >=  0.3] =  1\n",
        "    graph_th3[graph <= -0.3] = -1\n",
        "    # print(graph)\n",
        "    #fdr, tpr, fpr, shd, nnz = count_accuracy(ground_truth_G, nx.DiGraph(graph))\n",
        "    fdr, tpr, fpr, shd, nnz = count_accuracy(nx.DiGraph(GW), nx.DiGraph(graph_th3.T))\n",
        "    print(\"graph threshold 0.3\", np.around(graph_th3,1))\n",
        "    print('threshold 0.3, Accuracy: fdr', fdr, ' tpr ', tpr, ' fpr ', fpr, 'shd', shd, 'nnz', nnz)\n",
        "\n",
        "#######\n",
        "##GET the training started !!!\n",
        "D_Loss = []\n",
        "G_Loss = []\n",
        "P_Loss = []\n",
        "M_Loss = []\n",
        "S_Loss = []\n",
        "\n",
        "try:\n",
        "    #print before start training\n",
        "    W = nx.to_numpy_array(ground_truth_G)\n",
        "    W = np.abs(W.T)                   #DF: nx is colum based, hence we need to change it to row based, also remove negative\n",
        "    print(\"Ground Truth -show before training- W\\n\", np.around(W,1))\n",
        "    print(\"X_order\",X_order)          #DF06-01: added\n",
        "\n",
        "    #DF07-01: see fake data before training\n",
        "    #Visulize_results(-1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        #DF10-1: add shd_loss\n",
        "        D_loss, G_loss, Pen_loss, mse_loss, shd_loss, graph = train_DF(train_loader,\n",
        "                        epoch, ground_truth_G, optimizerG, optimizerD, optimizerDAG)\n",
        "\n",
        "        #DF10-01: save the loss for visualization\n",
        "        D_Loss.append(D_loss.item())\n",
        "        G_Loss.append(G_loss.item())\n",
        "        P_Loss.append(Pen_loss.item())\n",
        "        M_Loss.append(mse_loss.item())\n",
        "        S_Loss.append(shd_loss.item())\n",
        "\n",
        "        if epoch%10==0:\n",
        "            Visulize_results(epoch)\n",
        "\n",
        "        #DF16-01: add learning schedular\n",
        "        #schedulerG.step()\n",
        "        #schedulerD.step()\n",
        "        #schedulerDAG.step()\n",
        "\n",
        "    print_results()\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "6e0eb23c",
      "metadata": {
        "id": "6e0eb23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "37132f04-0282-411d-a819-d2b47d7c7ce1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#DF10-01: visulize the training loss curve\n",
        "\n",
        "# Generate a sequence of integers to represent the epoch numbers\n",
        "epo = range(0, epochs)\n",
        "\n",
        "#print(\"epoch\", epochs.shape)\n",
        "#print(\"D_Loss\", D_Loss.shape, D_Loss)\n",
        "\n",
        "# Plot and label the training and validation loss values\n",
        "plt.plot(epo, D_Loss, label='D Loss')\n",
        "plt.plot(epo, G_Loss, label='G Loss')\n",
        "plt.plot(epo, S_Loss, label='SHD')\n",
        "\n",
        "# Add in a title and axes labels\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Set the tick locations\n",
        "plt.xticks(np.arange(0, 21, 2))\n",
        "\n",
        "# Display the plot\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(D_Loss, label='Discriminator Loss')\n",
        "plt.plot(G_Loss, label='Generator Loss')\n",
        "plt.plot(P_Loss, label='Penalty Loss')\n",
        "plt.plot(M_Loss, label='MSE Loss')\n",
        "plt.plot(S_Loss, label='SHD Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training Losses')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "JbQxAzekqaQp",
        "outputId": "6a2494ac-8a76-4428-97c9-4b5d5a959bd2"
      },
      "id": "JbQxAzekqaQp",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1d3f83b",
      "metadata": {
        "id": "a1d3f83b"
      },
      "source": [
        "## End <a class=\"anchor\" id=\"end\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbbc8657",
      "metadata": {
        "id": "dbbc8657"
      },
      "source": [
        "* [Back to ToC](#toc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "49fac4e5",
      "metadata": {
        "id": "49fac4e5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}